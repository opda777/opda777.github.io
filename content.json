{"pages":[],"posts":[{"title":"2019年---小记","text":"总结​ 在三维动画，交互设计等等的课程实训，我掐指一算已经有两个月没有更新自己的笔记了，没办法，我也不知道为什么我这个专业的实训特别特别得多….其实早就放假啦，自己也摸鱼了一个星期恢复下元气。 ​ 对于2019我感觉还行，虽然没有参加什么比赛，但是在实训课程的过程中还是学到了很多东西，做出来的成品也让我感到满意，所以希望下一年也再接再厉，希望寒假没有摸鱼，能找到实习就最好了，哈哈哈。 ​ 加油！！！奥利给！！！","link":"/2020/08/23/2019%E5%B9%B4---%E5%B0%8F%E8%AE%B0/"},{"title":"UE4--材质大师课程笔记","text":"压缩和内存一般来说纹理导入UE4都是经过压缩的，压缩方式有BC(Block Compression块压缩)/DXTC(Directx Texture Compression DirectX纹理压缩)两种，其实都是用于PC的Directx平台的格式。但是法线贴图有点特殊，是无法通过这两种方式进行压缩的。 ​ 如下图所示就是贴图导入UE4后所选择的压缩方式。 压缩方式后面所带的数字表明是不同的压缩格式，例如BC3(DXTC5)表示带透明度的纹理，BC1(DXTC1)表示不带透明度的纹理。 法线贴图的压缩方式是通过剔除蓝色通道的方式进行压缩，这样可以存储更多的数据，同时对红色和绿色通道进行轻度压缩。最后通过对红绿色进行蓝色通道的复原，这些都是UE4内部自己调用的，不用我们去调整。如下图只是进行蓝色通道复原的演示。 注意的是，法线贴图的导入方式必须是选择NormalMap。 为什么要对纹理进行压缩最主要是因为受限于内存和带宽，如果不对纹理进行压缩，可能导致卡顿。但帧率过低一般和纹理压缩没有什么关系。可以通过查看统计数据，来查看场景中哪些纹理在内存中的大小。 多级渐进纹理 纹理尺寸和纹理池纹理池UE4在计算机内存中，会为纹理暴保留一定的空间，这个空间就是纹理池，我们可以手动调整纹理池的大小，当纹理池大小不够用的时候，会导致贴图的分辨率降低，效果下降。 打开控制台，输入r.Streaming.PoolSize查看纹理池大小，并且可以进行修改。 Mipmaps(多级渐进纹理)Mipmaps为原始纹理的副本，大小为1/4左右,使用Mipmaps的原因是为了减少噪点的生成。 左侧是使用了Mipmaps，右边没有使用，可以看出右边的噪点非常多，所以Mipmaps可以看成我们手动进行模糊 UE4会对远处使用不同的Mipmaps来模拟模糊的效果，如下图离镜头最近的就使用Mipmaps0原始纹理，然后随着离镜头越来越远，使用不同的Mipmaps。 可以在贴图的LOD选择中进行Mipmaps的设置 注意纹理尺寸使用Mipmaps可以提高我们的性能，加快渲染速度和减少纹理锯齿，但注意不适于2的幂数的纹理无法生成Mipmaps，但是UI纹理可以是任意分辨率，因为UI纹理不会从远处到近处，所以没必要使用Mipmaps。 材质的纹理数限制UE4的每个材质的纹理可采样数是16个，加上内部的光影贴图，其实我们可以用的大概是13个左右，其实已经够用了，但是如果要突破这个限制的话，我们可以把不同的贴图合成RGB通道就成为一张贴图，到使用的的时候就可以分RGB通道分为3张贴图。","link":"/2020/08/23/UE4--%E6%9D%90%E8%B4%A8%E5%A4%A7%E5%B8%88%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"title":"Hexo博客搭建过程(踩坑)","text":"前言​ 本文主要用来记录自己Hexo博客搭建过程中遇到的坑。 个人域名篇​ 这个个人域名的确有点坑，明明按着教程的操作一步一步来的，还是弄了一晚上，到最后才发现是校园网DNS的坑。。。 1.准备​ 首先我们要购买一个属于自己的域名，可以去腾讯云，阿里云等网站进行购买，这里我在阿里云购买opda.tech，为什么不用com域名，因为这个便宜。 ​ 购买域名后我们还要得到github仓库的IP。通过cmd命令行，输入Ping 你的名字.github.io获取名字 红色箭头所指就是你github仓库的IP，然后我们就可以进行DNS解析。 进去之后，点击新手引导，输入cmd获得的IP即可。 解析完的结果 ​ 2.github的绑定​ 进入你创建的仓库内，点击Setting ​ GitHub Pages设置 就这样github仓库的绑定就完成啦！ 3.最后一步我们还要在本地博客的source文件夹下新建一个CNAME.txt文本，在里面输入我们的自定义域名 最后我们Git Base重新部署一下博客就行啦！ 123hexo cleanhexo ghexo d 4.深坑​ 如果你是校园网用户的话，你要小心校园网DNS这个坑，会让你无法访问你自己的域名，所以解决方法就是修改我们的DNS就好了。 打开我们的控制面板—网络共享中心","link":"/2019/10/30/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"title":"UE4材质大师课程笔记(二)---RenderTarget","text":"RenderTargetUE4的RenderTarget感觉和Unity的差不多，都是获得一个摄像机的渲染结果，然后存在RenderTarget里面进行读取使用。 在UE4中要使用RenderTarget，首先要添加SceneCapture2D组件或者SceneCapture Cube组件，前者获取2D，后者获取Cube立方体贴图。 RenderTarget的使用渲染材质在UE4中过程化生成噪点纹理是比较昂贵的，所以通常的做法是将材质绘制到RenderTarget中。 可以看出以上这个需要529条指令 将材质绘制到RenderTarget 得到左边的RenderTarget噪点图了，然后右键创建静态纹理则可以得到可以用的Texture纹理了。 指令就变为了34，效率得到了提升。 高级应用高度图效果如下，随着鼠标左键的按下，在平面生成不同的高度。 1.首先我们要创建MAT_HeightfieldPainter材质，设置如下，注意要把shading Model改为Unlit无光照模式。这个材质主要用于控制物体在Z轴的世界偏移。 2.创建MAT_ForceSplat材质，设置如下，主要用于处理鼠标点击平面所产生的uv坐标，通过下面的计算获得一个关于这个uv坐标为圆心的渐变圆形贴图 3.新建一个HeightFieldPainter的Actor蓝图，设置如下 然后在构造函数里面进行动态材质的设置，这里主要针对我们上面的材质创建动态材质。 新建TraceFromCamera函数，函数用于从摄像头方向射出射线，进行射线检测，如果检测到碰撞物体，就进行伤害传递。 Begin函数，首先我们要为新建一个RenderTexture并保存，同时将RT传递给Z轴偏移的MAT_HeightfieldPainter材质。 最后处理伤害函数，传递参数给MAT_ForceSplat材质，例如点击的uv坐标，力度，大小，最后要用Draw Material to Render Target函数将材质绘制到RT里面，这样HeighfieldPainter材质才会根据RT图进行Z轴的偏移。 这里注意，这种方法只适用于平面，计算点击位置的uv坐标也比较简单，首先获取点击位置的世界坐标，然后获取静态网格的worldTransform,然后通过Invert Transform获得从世界坐标到静态网格本地坐标的变换矩阵，将点击位置从世界空间转换为静态网格的本地空间，当然我们也要将得到的本地坐标转为uv坐标，就要除于网格的长宽，映射到【0，1】，这样就得到了正确的uv坐标。","link":"/2020/08/23/UE4%E6%9D%90%E8%B4%A8%E5%A4%A7%E5%B8%88%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0(%E4%BA%8C)---RenderTarget/"},{"title":"UE4学习笔记(1)——简单框架","text":"前言纪录自己的UE4学习之路 UE4的简单框架 UE创世，万物皆UObject，接着有Actor 。 UobjectUobject是UE4中最基础的类，具有 元数据、反射生成、GC垃圾回收、序列化、编辑器可见，Class Default Object等功能。 ActorActor是UE4中最基本的场景元素，与Unity3D的gameobject相似，本身是一个容器，但是与unity不同的是，Actor没有任何可视化属性，甚至连位置属性也没有。但是也是与Unity相似，可以挂在多个可视化的组件( Component)，以达到各种功能，Actor也可以有子Actor。 Actor继承至Uobject，多了 Replication（网络复制）,Spawn（生生死死），Tick(有了心跳)等功能。 组件(Component)组件挂在Actor身上发挥功能，例如位置组件，Actor的最终位置来至于他的根组件。组件也可以有根组件。 PawnPawn是可以被控制的物体，相当于有controller的大脑，他可以是交通工具，鱼等，可以默认为生物的基类。 CharacterCharacter是人形的Actor，继承于Pawn， 默认拥有一个用于碰撞的胶囊体组件(CapsuleComponent)和运动相关的组件(CharacterMoveMentComponent)，并具有一些动画相关的功能。可以认为是人性动物的基类。 控制器(Controller)控制器用于控制Pawn的行为， 一般分为AIController和PlayerController。控制器也是从Actor派生的，因此也可以加入到场景中。 PlayerController 玩家控制器。是Pawn和控制其的玩家之间的桥梁，PlayerController代表了人类玩家的意愿。 AIController 用于控制NPC的控制器，决定了NPC如何与玩家互动。 显示HUDUI, 显示玩家的名字，血条，得分等信息。 相机 每个PlayerConroller都有一个PlayerCameraManager，代表了玩家的视角。 游戏规则和状态GameMode 游戏模式。处理游戏的规则，只存在与服务器端，因此客户端相关的逻辑不能存放在GameMode中。 GameState游戏状态， 记录游戏的数据，比如当前游戏的进度，世界任务的完成状态等，会自动同步到各个客户端。 PlayerState 玩家状态。记录玩家个人的数据，比如名字分数等，会自动同步到各个客户端。 总结GamePlay框架使用了MVC架构，其中Pawn是视图，PlayerState是数据模型，PlayerController是控制器。 一个游戏由游戏规则(GameMode)和游戏状态组成(GameState)；玩家在游戏里的化身是Pawn，玩家通过PlayerConroller控制着自己的化身，通过PlayerCameraManager观察世界，PlayerState记录了玩家的数据，HUD显示了这些状态；NPC则由AIConroller去控制，与玩家进行互动。","link":"/2020/08/23/UE4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E6%A1%86%E6%9E%B6/"},{"title":"Unity VEG实现烟花效果","text":"前言这次利用VEG实现普通烟花效果。 主粒子 设置主粒子的速度，位置，周期等参数。 Position(Line)用于设置粒子的初始化位置，从Start到End随机生成一个位置点。 烟花粒子 这里利用GPU Event当主粒子消亡时生成新的眼花粒子。 GPU Event GPU事件由系统在特定条件下触发，并且可以被其他系统捕获以生成新粒子。 可以通过读取Source或使用Inherit Source节点在子系统中访问事件数据。 主粒子的拖尾粒子 烟花粒子的拖尾 就这样我们的烟花就完成啦 现在看起来还是有点难看的，但问题不大，给它加点后处理就好了，PostProcessVolume 就这样，好看多了 未完待续可能后面还想加点其他的功能，所以未完待续。","link":"/2020/08/23/Unity-VEG%E5%AE%9E%E7%8E%B0%E7%83%9F%E8%8A%B1%E6%95%88%E6%9E%9C/"},{"title":"UE4学习笔记(2)---蓝图接口-标签","text":"蓝图接口 蓝图接口（Blueprint Interface） 是一个或多个函数的集合 - 只有名称，没有实现。可以添加到其他蓝图中。任何添加了该接口的蓝图都保证拥有这些函数。接口的函数 可以在添加它的每个蓝图中提供功能。在本质上，这类似于一般编程中的接口概念， 它允许多个不同类型的对象通过一个公共接口 共享和被访问。简单地说，蓝图接口允许不同的蓝图相互共享和发送数据。 创建蓝图接口 新建函数和函数的输入输出值 要使用蓝图接口，就必须继承该接口，并且实现。 实现接口之后，其他蓝图类就可以调用此方法，实现了蓝图之间的通信。 标签在调用蓝图接口方法前，先使用标签来判断是敌人还是友军，其实我感觉UE4的标签和Unity的标签还是挺相似的 标签的设置方法 调用蓝图接口方法 就这样完成了蓝图接口的调用","link":"/2020/08/23/UE4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)---%E8%93%9D%E5%9B%BE%E6%8E%A5%E5%8F%A3-%E6%A0%87%E7%AD%BE/"},{"title":"Unity实现米哈游的Mesh变换转场效果","text":"前言之前看过米哈游大佬制作的桃源恋歌MMD，被其中的Mesh变换转场效果所折服了，所以自己想模仿着实现这个效果，幸好kerjiro技术美术大神开源了这方面的视觉特效项目，感觉自己如果想成为TA还有好长的路要走。。。 最终效果首先让我们来看一下最终效果 实现思路其实这个效果是通过几何着色器来实现的，主要思路就是通过几何着色器对三角面片的顶点进行添加，构成一个Cube。 几何着色器相信大家接触的最多的应该是顶点着色器和像素着色器，那么什么是几何着色器呢？ 定义在顶点和片段着色器之间有一个可选的着色器，叫做几何着色器(Geometry Shader)。几何着色器以一个或多个表示为一个单独基本图形（primitive）即图元的顶点作为输入，比如可以是一个点或者三角形。几何着色器在将这些顶点发送到下一个着色阶段之前，可以将这些顶点转变为它认为合适的内容。几何着色器有意思的地方在于它可以把（一个或多个）顶点转变为完全不同的基本图形（primitive），从而生成比原来多得多的顶点。 使用几何着色器进行图元转换声明着色器 1#pragma geometry geom 设置输出顶点数量，其中N为几何着色器为单个调用输出的顶点最大数量，几何着色器每次输出的顶点数量是可变的，但是不能超过定义的最大值， 出于性能考虑，最大顶点数应尽可能小; 当GS输出在1到20个标量之间时，可以实现GS的性能峰值，如果GS输出在27-40个标量之间，则性能下降50％。每次调用的标量输出数是最大顶点输出数和输出顶点类型结构中的标量数的乘积。 1[maxvertexcount(N)] 声明输入和输出的Struct 1234567891011121314151617//传递给几何着色器的数据struct v2g{ float4 vertex:POSITION; float3 normal:TEXCOORD0; //float2 uv:TEXCOORD1; };//传递给像素着色器的数据struct g2f{ float4 pos : SV_POSITION; float3 normal:TEXCOORD0; //float2 uv : TEXCOORD1; float4 color:COLOR;}; 设置几何着色器输入参数和输出参数， 其中“triangle”为输入的图元类型， 输入参数一定为顶点数组 。 1234567输入图元类型 | 所需顶点数 -|-point | 输入1个点的1个顶点line | 输入1条直线的2个顶点 lineadj | 输入1条具有邻接(lists或strips)的线段的4个顶点 triangle | 输入1个三角形的3个顶点triangleadj | 输入1个具有邻接(lists或strips)的三角形的6个顶点 TriangleStream为流类型(stream type)对象，还有 LineStream 和 PointStream ,存储着由几何着色器输出的几何体顶点列表。内置Append用于向输出流添加顶点序列， 若想扩展输入的图元，也可以用内置Append向输出流添加多出来的顶点。 当指定uint primID:SV_PrimitiveID时，输入汇编阶段会为每个图元自动生成一个图元ID。当调用draw方法绘制n个图元时，ID号为0到n-1，这里用到的原因是为了随机Cube化。 1234void geom(triangle v2g input[3], uint pid : SV_PrimitiveID, inout TriangleStream&lt;g2f&gt; outStream){ //shader body} 将输出顶点传送至输出stream上 1OutputStream.Append(o); 开始动手CPU传递数据给Shader首先我们需要新建一个脚本用于传递数据给Shader，以下就是K神的传递脚本，我已经写好注释。挂在一个空物体上面即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181using System.Collections;using System.Collections.Generic;using UnityEngine;//在编辑器模式下也可运行[ExecuteInEditMode]public class Voxelizer : MonoBehaviour{ //SerializeField用于面板上显示非Public的参数 //Range(0,1)控制可滑选的范围 //控制生成方块的密度 [SerializeField, Range(0, 1)] float _density = 0.05f; //控制生成方块的大小 [SerializeField, Range(0, 10)] float _scale = 3; //动画参数 //用于控制方块变形后的长度 [SerializeField, Range(0, 20)] float _stretch = 5; //用于控制方块变形后上升的最大距离 [SerializeField, Range(0, 1000)] float _fallDistance = 1; //用于控制方块变形后的随机移动范围 [SerializeField, Range(0, 10)] float _fluctuation = 1; //颜色参数 [SerializeField, ColorUsage(false, true)] Color _emissionColor1 = Color.black; [SerializeField, ColorUsage(false, true)] Color _emissionColor2 = Color.black; [SerializeField, ColorUsage(false, true)] Color _transitionColor = Color.white; [SerializeField, ColorUsage(false, true)] Color _lineColor = Color.white; //用于Mesh变换物体的Renderer [SerializeField] Renderer[] _renderers = null; //效果平面的位置与距离 Vector4 EffectorPlane { get { //获取向前的方向 var fwd = transform.forward / transform.localScale.z; //获取向前方向上的移动距离 var dist = Vector3.Dot(fwd, transform.position); return new Vector4(fwd.x, fwd.y, fwd.z, dist); } } //将RGB颜色模型转为HSV颜色模型 Vector4 ColorToHsvm(Color color) { //获取颜色的分量最大值 var max = color.maxColorComponent; float h, s, v; Color.RGBToHSV(color / max, out h, out s, out v); return new Vector4(h, s, v, max); } //获取着色器属性的唯一标识符 //优点：使用属性标识符比将字符串传递给所有材料属性函数更有效。 //例如，如果您经常调用Material.SetColor或使用MaterialPropertyBlock， //则最好只获取一次所需属性的标识符。 static class ShaderIDs { public static readonly int VoxelParams = Shader.PropertyToID(&quot;_VoxelParams&quot;); public static readonly int AnimParams = Shader.PropertyToID(&quot;_AnimParams&quot;); public static readonly int EmissionHsvm1 = Shader.PropertyToID(&quot;_EmissionHsvm1&quot;); public static readonly int EmissionHsvm2 = Shader.PropertyToID(&quot;_EmissionHsvm2&quot;); public static readonly int TransitionColor = Shader.PropertyToID(&quot;_TransitionColor&quot;); public static readonly int LineColor = Shader.PropertyToID(&quot;_LineColor&quot;); public static readonly int EffectorPlane = Shader.PropertyToID(&quot;_EffectorPlane&quot;); public static readonly int PrevEffectorPlane = Shader.PropertyToID(&quot;_PrevEffectorPlane&quot;); public static readonly int LocalTime = Shader.PropertyToID(&quot;_LocalTime&quot;); } //在要使用相同材质但属性稍有不同的多个对象绘制的情况下使用MaterialPropertyBlock。 MaterialPropertyBlock _sheet; Vector4 _prevEffectorPlane = Vector3.one * 1e+5f; private void LateUpdate() { //查看渲染列表是否为空 if (_renderers == null || _renderers.Length == 0) return; //创建新的MaterialPropertyBlock if (_sheet == null) _sheet = new MaterialPropertyBlock(); var plane = EffectorPlane; // Filter out large deltas. //过滤掉大的三角面片 if ((_prevEffectorPlane - plane).magnitude &gt; 100) _prevEffectorPlane = plane; //存储参数 var vparams = new Vector2(_density, _scale); var aparams = new Vector3(_stretch, _fallDistance, _fluctuation); var emission1 = ColorToHsvm(_emissionColor1); var emission2 = ColorToHsvm(_emissionColor2); //将参数传递给shader foreach (var renderer in _renderers) { if (renderer == null) continue; renderer.GetPropertyBlock(_sheet); _sheet.SetVector(ShaderIDs.VoxelParams, vparams); _sheet.SetVector(ShaderIDs.AnimParams, aparams); _sheet.SetVector(ShaderIDs.EmissionHsvm1, emission1); _sheet.SetVector(ShaderIDs.EmissionHsvm2, emission2); _sheet.SetColor(ShaderIDs.TransitionColor, _transitionColor); _sheet.SetColor(ShaderIDs.LineColor, _lineColor); _sheet.SetVector(ShaderIDs.EffectorPlane, plane); _sheet.SetVector(ShaderIDs.PrevEffectorPlane, _prevEffectorPlane); //_sheet.SetFloat(ShaderIDs.LocalTime, time); renderer.SetPropertyBlock(_sheet); print(plane); } } //进行gizmo编辑器的实现,用于可视化Debug Mesh _gridMesh; void OnDestroy() { if (_gridMesh != null) { if (Application.isPlaying) Destroy(_gridMesh); else DestroyImmediate(_gridMesh); } } void OnDrawGizmos() { if (_gridMesh == null) InitGridMesh(); //矩阵用于控制Gizmos跟随物体的移动而移动 Gizmos.matrix = transform.localToWorldMatrix; Gizmos.color = new Color(1, 1, 0, 0.5f); Gizmos.DrawWireMesh(_gridMesh, Vector3.zero); Gizmos.DrawWireMesh(_gridMesh, Vector3.forward); Gizmos.color = new Color(1, 0, 0, 0.5f); Gizmos.DrawWireCube(Vector3.forward / 2, new Vector3(0.02f, 0.02f, 1)); } void InitGridMesh() { const float ext = 0.5f; const int columns = 10; var vertices = new List&lt;Vector3&gt;(); var indices = new List&lt;int&gt;(); for (var i = 0; i &lt; columns + 1; i++) { var x = ext * (2.0f * i / columns - 1); indices.Add(vertices.Count); vertices.Add(new Vector3(x, -ext, 0)); indices.Add(vertices.Count); vertices.Add(new Vector3(x, +ext, 0)); indices.Add(vertices.Count); vertices.Add(new Vector3(-ext, x, 0)); indices.Add(vertices.Count); vertices.Add(new Vector3(+ext, x, 0)); } _gridMesh = new Mesh { hideFlags = HideFlags.DontSave }; _gridMesh.SetVertices(vertices); _gridMesh.SetNormals(vertices); _gridMesh.SetIndices(indices.ToArray(), MeshTopology.Lines, 0); _gridMesh.UploadMeshData(true); }} MaterialPropertyBlock研究代码的时候发现了MaterialPropertyBlock，查阅文档才发现是用于节约性能。实际应用可以查看这篇文章MaterialPropertyBlock。 Shader的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301// Upgrade NOTE: replaced &apos;_Object2World&apos; with &apos;unity_ObjectToWorld&apos;// Upgrade NOTE: replaced &apos;_Object2World&apos; with &apos;unity_ObjectToWorld&apos;Shader &quot;Custom/MeshShader&quot;{ Properties { _MainTex(&quot;主纹理贴图&quot;,2D)=&quot;white&quot;{} } SubShader { Tags { &quot;RenderType&quot; = &quot;Opaque&quot; } LOD 100 Pass { Tags{&quot;LightMode&quot;=&quot;ForwardBase&quot;} CGPROGRAM //声明着色器 #pragma vertex vert #pragma geometry geom #pragma fragment frag #include &quot;UnityCG.cginc&quot; #include &quot;Assets/My/SimplexNoise3D.hlsl&quot; //传递给顶点着色器的数据 struct a2v { float4 vertex:POSITION; float3 normal:NORMAL; float4 texcoord:TEXCOORD0; }; //传递给几何着色器的数据 struct v2g { float4 vertex:POSITION; float3 normal:TEXCOORD0; //float2 uv:TEXCOORD1; }; //传递给像素着色器的数据 struct g2f { float4 pos : SV_POSITION; float3 normal:TEXCOORD0; //float2 uv : TEXCOORD1; float4 color:COLOR; }; sampler2D _MainTex; float4 _MainTex_ST; //用于几何着色器的数据 half2 _VoxelParams; // density, scale 密度，比例 half3 _AnimParams; // stretch, fall distance, fluctuation 伸展、下降距离、波动 float4 _EffectorPlane; float4 _PrevEffectorPlane; //用于像素着色器的数据 half4 _EmissionHsvm1; half4 _EmissionHsvm2; half3 _TransitionColor; half3 _LineColor; //顶点着色器 void vert(inout v2g input) { } g2f VertexOutput( float3 position0, float3 position1, half3 normal0, half3 normal1, half param, half emission = 0, half random = 0, half2 baryCoord = 0.5 ) { g2f i; i.pos = UnityObjectToClipPos(float4(lerp(position0, position1, param),1)); i.normal = normalize(lerp(normal0, normal1, param)); i.color = float4(baryCoord, emission,random); return i; } // 计算方块的位置和大小 void CubePosScale( float3 center, float size, float rand, float param, out float3 pos, out float3 scale ) { const float VoxelScale = _VoxelParams.y; const float Stretch = _AnimParams.x; const float FallDist = _AnimParams.y; const float Fluctuation = _AnimParams.z; // Noise field //噪声场 float4 snoise = snoise_grad(float3(rand * 2378.34, param * 0.8, 0)); // Stretch/move param float move = saturate(param * 4 - 3); move = move * move; // Cube position pos = center + snoise.xyz * size * Fluctuation; pos.y += move * move * lerp(0.25, 1, rand) * size * FallDist; // Cube scale anim scale = float2(1 - move, 1 + move * Stretch).xyx; scale *= size * VoxelScale * saturate(1 + snoise.w * 2); } //哈希值，用于随机觉得面片是三角面片还是Cube float Hash(uint s) { s = s ^ 2747636419u; s = s * 2654435769u; s = s ^ (s &gt;&gt; 16); s = s * 2654435769u; s = s ^ (s &gt;&gt; 16); s = s * 2654435769u; return float(s) * rcp(4294967296.0); // 2^-32 } //几何着色器 [maxvertexcount(24)] void geom(triangle v2g input[3], uint pid : SV_PrimitiveID, inout TriangleStream&lt;g2f&gt; outStream) { //获取密度 const float VoxelDensity = _VoxelParams.x; //获取传入顶点的位置 float3 p0 = input[0].vertex.xyz; float3 p1 = input[1].vertex.xyz; float3 p2 = input[2].vertex.xyz; float3 p0_prev = p0; float3 p1_prev = p1; float3 p2_prev = p2; //获取传入顶点的法线 float3 n0 = input[0].normal; float3 n1 = input[1].normal; float3 n2 = input[2].normal; //计算中心点 float3 center = (p0 + p1 + p2) / 3; float size = distance(p0, center); //变形参数 //将中心点变换到世界空间中 float3 center_ws = mul(unity_ObjectToWorld, float4(center,1)).xyz; float param = 1 - dot(_EffectorPlane.xyz, center_ws) + _EffectorPlane.w; //如果变形还没开始那就将平常操作 if (param &lt; 0) { outStream.Append(VertexOutput(p0, 0, n0, 0, 0, 0, 0)); outStream.Append(VertexOutput(p1, 0, n1, 0, 0, 0, 0)); outStream.Append(VertexOutput(p2, 0, n2, 0, 0, 0, 0)); outStream.RestartStrip(); return; } //变形结束后，不传递任何数据，从而使物体隐身 if (param &gt;= 1) return; // Choose cube/triangle randomly. //uint seed = float3(pid * 877, pid * 877, pid * 877); uint seed = pid * 877; if (Hash(seed) &lt; VoxelDensity) { // -- Cube -- // Random numbers float rand1 = Hash(seed + 1); float rand2 = Hash(seed + 5); // Cube position and scale float3 pos, pos_prev, scale, scale_prev; CubePosScale(center, size, rand1, param, pos, scale); // Secondary animation parameters float morph = smoothstep(0, 0.25, param); float em = smoothstep(0, 0.15, param) * 2; // initial emission em = min(em, 1 + smoothstep(0.8, 0.9, 1 - param)); em += smoothstep(0.75, 1, param); // emission while falling // Cube points calculation float3 pc0 = pos + float3(-1, -1, -1) * scale; float3 pc1 = pos + float3(+1, -1, -1) * scale; float3 pc2 = pos + float3(-1, +1, -1) * scale; float3 pc3 = pos + float3(+1, +1, -1) * scale; float3 pc4 = pos + float3(-1, -1, +1) * scale; float3 pc5 = pos + float3(+1, -1, +1) * scale; float3 pc6 = pos + float3(-1, +1, +1) * scale; float3 pc7 = pos + float3(+1, +1, +1) * scale; // World space to object space conversion // Vertex outputs float3 nc = float3(-1, 0, 0); outStream.Append(VertexOutput(p0, pc2, n0, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc0, n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p0, pc6, n0, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p2, pc4, n2, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(1, 0, 0); outStream.Append(VertexOutput(p2, pc1, n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p1, pc3, n1, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p2, pc5, n2, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p1, pc7, n1, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, -1, 0); outStream.Append(VertexOutput(p2, pc0, n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc1, n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p2, pc4, n2, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p2, pc5, n2, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, 1, 0); outStream.Append(VertexOutput(p1, pc3, n1, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p0, pc2, n0, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p1, pc7, n1, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p0, pc6, n0, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, 0, -1); outStream.Append(VertexOutput(p2, pc1, n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc0, n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p1, pc3, n1, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p0, pc2, n0, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, 0, 1); outStream.Append(VertexOutput(p2, pc4, -n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc5, -n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p0, pc6, -n0, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p1, pc7, -n1, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); } else { // -- Triangle -- half morph = smoothstep(0, 0.25, param); //half morph = 0.25; half em = smoothstep(0, 0.15, param) * 2; outStream.Append(VertexOutput(p0, center, n0, n0, morph, em)); outStream.Append(VertexOutput(p1, center, n1, n1, morph, em)); outStream.Append(VertexOutput(p2, center, n2, n2, morph, em)); outStream.RestartStrip(); } } //计算颜色 half3 SelfEmission(g2f input) { half2 bcc = input.color.rg; half em1 = saturate(input.color.b); half em2 = saturate(input.color.b - 1); half rand = input.color.a; // Cube face color half3 face = lerp(_EmissionHsvm1.xyz, _EmissionHsvm2.xyz, rand); face *= lerp(_EmissionHsvm1.w, _EmissionHsvm2.w, rand); // Cube face attenuation face *= lerp(0.75, 1, smoothstep(0, 0.5, length(bcc - 0.5))); // Edge detection half2 fw = fwidth(bcc); half2 edge2 = min(smoothstep(0, fw * 2, bcc), smoothstep(0, fw * 2, 1 - bcc)); half edge = 1 - min(edge2.x, edge2.y); return face * em1 + _TransitionColor * em2 * face + edge * _LineColor * em1; } half4 frag(g2f z):SV_Target { half4 col = half4(SelfEmission(z),1); return col; } ENDCG } } FallBack &quot;Diffuse&quot;} 这里运用到了三维噪声的知识，这里我只是简单的调用了K神写好的噪声函数，并没有深究，其实我还是看过了一些关于噪声的文章，以后已机会把笔记总结出来。 最终结果 注意这个效果对于模型也是有要求的，模型的面片不能太小，不然就会得到以下的结果…","link":"/2020/08/23/Unity%E5%AE%9E%E7%8E%B0%E7%B1%B3%E5%93%88%E6%B8%B8%E7%9A%84Mesh%E5%8F%98%E6%8D%A2%E8%BD%AC%E5%9C%BA%E6%95%88%E6%9E%9C/"},{"title":"Unity Visual Effect Graph初探","text":"前言最近为了实现动画课程设计的烟花效果，所以要学习一下Unity的新特效工具Visual Effect Graph，特此记录学习的过程，避免以后会忘记。 注意 目前Visual Effect Graph只能在HDRP中使用，也就是说必须使用Unity2018.3以上的版本。 为什么要使用VEF我们已经有传统的Particle System系统，那为什么要用VEF呢？ 其实VEF能比传统的Particle System能做出更加复杂酷炫的特效，具体可以查看Unity的官方文档。而且我们认为VEF还有一个更加巨大有点就是可视化，我刚开始接触Particle System的时候，看到这么多参数，头都晕了….这次VEF的工作流非常的清楚。 VEF的工作流关于VEF的安装和配置就不说了，官方文档有详细的讲解。 首先我们来看一下VEF的画面，可以看出和shader Graph非常的相似。 VEF默认模板由4个流程构成(VEF称为Context)，包含着多个Block，整个VEF工作流抽象成4个部分 Spawn负责生成粒子，右键点击添加的Block都是与粒子生成相关。 Initialize初始化模块，负责初始化粒子的属性，如初始速度，生命周期。 Update每帧对粒子的参数进行更新，比如重力，移动速度，坐标等。 Output主要负责粒子的渲染，如颜色，形状等。 注意每个Context连接并不是唯一，比如一个Spawn可连接多个Initialize，朝多个方向发射 VEF的使用小测试VEF的小测试，以粒子的初始速度为基准设置粒子的颜色 实现以原点为圆心，半径为1，圆以内的呈绿色，圆以外的呈紫色。 也可添加Get Attribute：Color结点获取粒子原本的颜色，达到新效果。 Point Cache bake tool(点阵缓存烘焙器)这个是VEG添加的新工具，它的作用是把一张图或者Mesh的信息，烘焙成一张点阵图，然后再VEG中使用，可烘焙的信息有颜色，法线，位置，UV信息等。 首先点开烘焙工具，烘焙工具在上方Window—Visual Effects—Utilities—Point Cache bake tool,选择要烘焙的网格和信息，这里我选择胶囊体作为测试。 在VEG中使用以下两个节点，即可得到一个粒子形成的胶囊体 Vector Field Force(矢量场力)官方文档解释：矢量场力施加从包含矢量数据的3D纹理中获取的力。我也不是很明白，以后有机会再研究。通过结合矢量场力和Point Cache我们可以实现粒子物体爆掉的感觉。 VFX Binder脚本，参数与事件的绑定为了在游戏运行时根据游戏内的逻辑来实时动态改变VEG，我们可以用VFX Binder绑定脚本。 参数绑定首先，我们为VFX添加VFX Parameter binder脚本 在Hierarchy面板新建一个Cube，这个Cube用于传递位置参数进VEG，实时更新粒子喷发的位置。 进入VEG在参数面板新建一个Vector3用于存储Cube的位置参数，并传递给粒子。 事件绑定在VEG里事件作为一个单独的Context，不能附加任何的Block并且只能和Spawn相连，作用是管理Spawn的发射开关。 现在做鼠标点击位置生成粒子效果 首先新建一个Plane作为脚本的载体，并且绑定VFX Mouse Event Blinder事件,拖入新建的VFX 双击VEX，新建一个Event，注意名字要和脚本上的EventName要一致。 注意Location为Source的Attribute只能用在Initializes中的Block上 最后我们就能实现鼠标点击位置生成粒子的效果了。 感受第一次尝试这样做笔记，比较痛苦，但成就感也是满满的。","link":"/2020/08/23/Unity-Visual-Effect-Graph%E5%88%9D%E6%8E%A2/"}],"tags":[{"name":"杂记","slug":"杂记","link":"/tags/%E6%9D%82%E8%AE%B0/"},{"name":"UE4","slug":"UE4","link":"/tags/UE4/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Unity","slug":"Unity","link":"/tags/Unity/"}],"categories":[{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"},{"name":"UE4","slug":"UE4","link":"/categories/UE4/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"Unity","slug":"Unity","link":"/categories/Unity/"}]}