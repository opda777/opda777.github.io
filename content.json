{"pages":[],"posts":[{"title":"2019年---小记","text":"总结​ 在三维动画，交互设计等等的课程实训，我掐指一算已经有两个月没有更新自己的笔记了，没办法，我也不知道为什么我这个专业的实训特别特别得多….其实早就放假啦，自己也摸鱼了一个星期恢复下元气。 ​ 对于2019我感觉还行，虽然没有参加什么比赛，但是在实训课程的过程中还是学到了很多东西，做出来的成品也让我感到满意，所以希望下一年也再接再厉，希望寒假没有摸鱼，能找到实习就最好了，哈哈哈。 ​ 加油！！！奥利给！！！","link":"/2020/08/23/2019%E5%B9%B4---%E5%B0%8F%E8%AE%B0/"},{"title":"C#基本类型","text":"1Title: C#复习 基本类型数据类型主要用于指明变量和常量存储值的类型 C# 语言的数据类型分为值类型和引用类型。 值类型包括整型、浮点型、字符型、布尔型、枚举型等；引用类型包括类、接口、数组、委托、字符串等。 从内存存储空间的角度而言，值类型的值是存放到栈中的，每次存取值都会在该内存中操作；引用类型首先会在栈中创建一个引用变量，然后在堆中创建对象本身，再把这个对象所在内存的首地址赋给引用变量。 变量变量和常量是相对的：变量是指所存放的值是允许改变的，而常量表示存入的值不允许改变。 常量与变量不同的是，常量在第一次被赋值后值就不能再改变。定义常量需要使用关键字 const 来完成。 1const 数据类型 常量名 = 值; 需要注意的是，在定义常量时必须为其赋值，因为不赋值的话以后就再也不能赋值了。另外，也可以同时定义多个常量。 类的定义1234类的访问修饰符 修饰符 类名{ 类的成员} 类的访问修饰符：用于设定对类的访问限制，包括 public、internal 或者不写，用 internal 或者不写时代表只能在当前项目中访问类；public 则代表可以在任何项目中访问类。 修饰符：修饰符是对类本身特点的描述，包括 abstract、sealed 和 static。abstract 是抽象的意思，使用它修饰符的类不能被实例化；sealed 修饰的类是密封类，不能 被继承；static 修饰的类是静态类，不能被实例化。 类名：类名用于描述类的功能，因此在定义类名时最好是具有实际意义，这样方便用户理解类中描述的内容。在同一个命名空间下类名必须是唯一的。 类的成员：在类中能定义的元素，主要包括字段、属性、方法。 类的成员修饰符1) public成员可以被任何代码访问。 2) private成员仅能被同一个类中的代码访问，如果在类成员前未使用任何访问修饰 符，则默认为private。 3) internal成员仅能被同一个项目中的代码访问。 4) protected成员只能由类或派生类中的代码访问。派生类是在继承中涉及的，将在后面详细介绍。 字段字段的定义与前面介绍的变量和常量的定义类似，只是在变量或常量前面可以加上访问修饰符、修饰符。 在修饰字段时通常用两个修饰符，即readonly （只读）和static （静态的）。 使用 readonly 修饰字段意味着只能读取该字段的值而不能给字段赋值。 使用 static 修饰的字段是静态字段，可以直接通过类名访问该字段。 需要注意的是常量不能使用 static 修饰符修饰。 1访问修饰符 修饰符 数据类型 字段名 方法的定义1234访问修饰符 修饰符 返回值类型 方法名(参数列表){ 语句块;} 修饰符在定义方法时修饰符包括 virtual（虚拟的）、abstract（抽象的）、override（重写的）、static（静态的）、sealed（密封的）。override 是在类之间继承时使用的。 参数传递 方式 描述 值参数 复制参数的实际值给函数的形式参数，实参和形参使用的是两个不同内存中的值。 引用参数 这种方式复制参数的内存位置的引用给形式参数。这意味着，当形参的值发生改变时，同时也改变实参的值。 输出参数 这种方式可以返回多个值。 按引用传递参数1234public void sawp(ref int x, ref int y){} 按输出传递参数1234public void GetValue(out int x, out int y){} get和set访问器属性经常与字段连用，并提供了 get 访问器和 set 访问器，分别用于获取或设置字段的值。 123456789101112//设置图书编号属性 public int Id { get { return id; } set { id = value; } } 可空类型（Nullable）C＃提供了一个特殊的数据类型，nullable类型（可空类型），可空类型可以表示其基础值类型正常范围内的值，再加上一个null值。 12&lt;data_type&gt; ? &lt;variable_name&gt; = null;int? num1 = null; Null合并运算符（？?）如果第一个操作数的值为null，则运算符返回第二个操作数的值，否则返回第一个操作数的值。 1num3 = num1 ?? 5.34; C# 多维数组长度一致 1234567891011//一个 string 变量的二维数组string [,] names;//一个 int 变量的三维数组int [ , , ] m;int [,] a = int [3,4] = { {0, 1, 2, 3} , /* 初始化索引号为 0 的行 */ {4, 5, 6, 7} , /* 初始化索引号为 1 的行 */ {8, 9, 10, 11} /* 初始化索引号为 2 的行 */}; C# 交错数组长度没有限制，可以不一样，可以理解为数组的数组 123456// 声明一个交错数组 a，a 中有三个元素，分别是 a[0],a[1],a[2] 每个元素都是一个数组int[][] a = new int[3][]; //以下是声明交错数组的每一个元素的，每个数组的长度可以不同a[0] = new int[] { 1,2,3 };a[1] = new int[] { 4,5,6,7,8 };a[2] = new int[] { 9, 10, 11, 12, 13, 14, 15, 16, 17, 18 }; 传递数组给函数123456789double getAverage(int[] arr, int size){}/* 一个带有 5 个元素的 int 数组 */int [] balance = new int[]{1000, 2, 3, 17, 50};/* 传递数组的指针作为参数 */avg = app.getAverage(balance, 5 ) ; 参数数组当声明一个方法时，您不能确定要传递给函数作为参数的参数数目。C# 参数数组解决了这个问题，参数数组通常用于传递未知数量的参数给函数。 1234567public int AddElements(params int[] arr){}//会把1，5，2，9，8合并入arr数组int num = SumVals(1,5,2,9,8);//也可以直接传进一个数组 params 关键字参数数组必须是一维数组。 会把传递进来的参数并入一个数组。 Array类Array 类是 C# 中所有数组的基类，它是在 System 命名空间中定义。Array 类提供了各种用于数组的属性和方法。如：获取数组长度，进行排序等 C＃字符串（String）创建String对象方法 123456789101112131415161718192021222324//字符串，字符串连接 string fname, lname; fname = &quot;Rowan&quot;; lname = &quot;Atkinson&quot;; string fullname = fname + lname; Console.WriteLine(&quot;Full Name: {0}&quot;, fullname); //通过使用 string 构造函数 char[] letters = { &apos;H&apos;, &apos;e&apos;, &apos;l&apos;, &apos;l&apos;,&apos;o&apos; }; string greetings = new string(letters); Console.WriteLine(&quot;Greetings: {0}&quot;, greetings); //方法返回字符串 string[] sarray = { &quot;Hello&quot;, &quot;From&quot;, &quot;Tutorials&quot;, &quot;Point&quot; }; string message = String.Join(&quot; &quot;, sarray); Console.WriteLine(&quot;Message: {0}&quot;, message); //用于转化值的格式化方法 DateTime waiting = new DateTime(2012, 10, 10, 17, 58, 1); string chat = String.Format(&quot;Message sent at {0:t} on {0:D}&quot;, waiting); Console.WriteLine(&quot;Message: {0}&quot;, chat); Console.ReadKey() ; C# 结构（Struct）在 C# 中，结构是值类型数据结构。它使得一个单一变量可以存储各种数据类型的相关数据。struct 关键字用于创建结构。 1234567struct Books{ public string title; public string author; public string subject; public int book_id;}; C#结构特点 结构可带有方法、字段、索引、属性、运算符方法和事件。 结构可定义构造函数，但不能定义析构函数。但是，您不能为结构定义默认的构造函数。默认的构造函数是自动定义的，且不能被改变。 与类不同，结构不能继承其他的结构或类。 结构不能作为其他结构或类的基础结构。 结构可实现一个或多个接口 结构成员不能指定为 abstract、virtual 或 protected（因为都不可以继承） 当您使用 New 操作符创建一个结构对象时，会调用适当的构造函数来创建结构。与类不同，结构可以不使用 New 操作符即可被实例化。 如果不使用 New 操作符，只有在所有的字段都被初始化之后，字段才被赋值，对象才被使用。 类与结构的不同 类是引用类型，结构是值类型。 结构不支持继承。 结构不能声明默认的构造函数。 C#枚举（Enum）声明与使用C# 枚举是值数据类型。换句话说，枚举包含自己的值，且不能继承或传递继承。 1enum Days { Sun, Mon, tue, Wed, thu, Fri, Sat }; 枚举列表中的每个符号代表一个整数值，一个比它前面的符号大的整数值。默认情况下，第一个枚举符号的值是 0. C#类（Class）当您定义一个类时，您定义了一个数据类型的蓝图。 12345678910111213141516171819202122&lt;access specifier&gt; class class_name { // member variables &lt;access specifier&gt; &lt;data type&gt; variable1; &lt;access specifier&gt; &lt;data type&gt; variable2; ... &lt;access specifier&gt; &lt;data type&gt; variableN; // member methods &lt;access specifier&gt; &lt;return type&gt; method1(parameter_list) { // method body } &lt;access specifier&gt; &lt;return type&gt; method2(parameter_list) { // method body } ... &lt;access specifier&gt; &lt;return type&gt; methodN(parameter_list) { // method body }} 访问标识符 指定了对类及其成员的访问规则。类的默认访问标识符是 internal，成员的默认访问标识符是 private。 成员函数和封装123456private double length; // 长度public void setLength( double len ) { length = len; } 成员变量是对象的属性（从设计角度），且它们保持私有来实现封装。这些变量只能使用公共成员函数来访问。 构造函数类的 构造函数 是类的一个特殊的成员函数，当创建类的新对象时执行。 构造函数的名称与类的名称完全相同，它没有任何返回类型。 1234567class Line{ public Line() { Console.WriteLine(&quot;对象已创建&quot;); }} 默认的构造函数没有任何参数。但是如果您需要一个带有参数的构造函数可以有参数，这种构造函数叫做参数化构造函数。 析构函数析构函数用于在结束程序（比如关闭文件、释放内存等）之前释放资源。析构函数不能继承或重载。 1234~Line() //析构函数 { Console.WriteLine(&quot;对象已删除&quot;); } 静态成员static 关键字把类成员定义为静态的。直接调用类而不需要创建类的实例来获取。静态变量可在成员函数或类的定义外部进行初始化。您也可以在类的定义内部初始化静态变量。 1234class StaticVar{ public static int num;} 一个成员函数声明为 static。这样的函数只能访问静态变量。静态函数在对象被创建之前就已经存在。 1234public static int getNum() { return num; } 继承继承的思想实现了 属于（IS-A） 关系。派生类只能有一个直接基类，但一个基类可以有多个直接派生类。继承是可以传递的。 123456789class Shape{}// 派生类class Rectangle : Shape{} 基类初始化派生类继承了基类的成员变量和成员方法。因此父类对象应在子类对象创建之前被创建。您可以在成员初始化列表中进行父类的初始化。 12public Tabletop(double l, double w) : base(l, w) { } C#不支持多重继承C# 不支持多重继承。但是，您可以使用接口来实现多重继承。 123456// 接口 PaintCost public interface PaintCost { int getCost(int area); } C#多态性多态性可以是静态的或动态的。在静态多态性中，函数的响应是在编译时发生的。在动态多态性中，函数的响应是在运行时发生的。 C#提供了两种技术实现多态：函数重载，运算符重载 函数重载同一个范围内对相同的函数名有多个定义。函数的定义必须彼此不同，可以是参数列表中的参数类型不同，也可以是参数个数不同。不能重载只有返回类型不同的函数声明。 123456789void print(int i) { Console.WriteLine(&quot;Printing int: {0}&quot;, i ); } void print(double f) { Console.WriteLine(&quot;Printing float: {0}&quot; , f); } 动态多态性C# 允许您使用关键字 abstract 创建抽象类，用于提供接口的部分类的实现。当一个派生类继承自该抽象类时，实现即完成。抽象类包含抽象方法，抽象方法可被派生类实现。派生类具有更专业的功能。 您不能创建一个抽象类的实例。 您不能在一个抽象类外部声明一个抽象方法。 通过在类定义前面放置关键字 sealed，可以将类声明为密封类。当一个类被声明为 sealed 时，它不能被继承。抽象类不能被声明为 sealed。 12345678910111213141516171819abstract class Shape { public abstract int area(); } class Rectangle: Shape { private int length; private int width; public Rectangle( int a=0, int b=0) { length = a; width = b; } public override int area () { Console.WriteLine(&quot;Rectangle 类的面积：&quot;); return (width * length); } }","link":"/2020/08/23/C#%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/"},{"title":"Static Batch,Dynamic Batch,GPU Instancing","text":"1Title: 图形学复习 Static Batch,Dynamic Batch,GPU InstancingStatic Batch在运行开始阶段，将标明为Static的物体，合并成一个Mesh。对于使用了同一材质的物体，Unity只需要调用一个DrawCall就可以绘制全部物体。但是对于不同材质的物体，Unity还是要调用多个DrawCall，但可以减少DrawCall之间的状态切换，还是有益于性能。 内部实现Unity首先把静态物体变换到世界空间，然后为他们构建一个更大的顶点和索引缓存。 缺点由于勾选了Static，所以不可以移动 对于内存消耗很大，因为每一个物体都对应一个网格的复制体。 无法参与批处理情况 改变Renderer.material将会造成一份材质的拷贝，因此会打断批处理，你应该使用Renderer.sharedMaterial来保证材质的共享状态。 Dynamic Batch将使用同一材质的Mesh进行合并，并且每帧进行合并。利用一个DrawCall绘制全部物体 缺点能进行Dynamic Batch的网格顶点属性规模要小于900. 使用光照纹理的物体需要小心处理 多Pass的Shader会中断处理。 GPU Instancing在使用相同材质球、相同Mesh(预设体的实例会自动地使用相同的网格模型和材质)的情况下，Unity会在运行时对于正在视野中的符合要求的所有对象使用Constant Buffer[5]将其位置、缩放、uv偏移、lightmapindex等相关信息保存在显存中的“统一/常量缓冲器”[6]中，然后从中抽取一个对象作为实例送入渲染流程，当在执行DrawCall操作后，从显存中取出实例的部分共享信息与从GPU常量缓冲器中取出对应对象的相关信息一并传递到下一渲染阶段，与此同时，不同的着色器阶段可以从缓存区中直接获取到需要的常量，不用设置两次常量。 我们可以将这些静态的物件如植被等全部从场景中剔除，而保存其位置、缩放、uv偏移、lightmapindex等相关信息，在需要渲染的时候，根据其保存的信息，通过Instance来渲染，这能够减少那些因为内存原因而不能合批的大批量相同物件的渲染时间。 各种着色器作用顶点着色器最主要的是把模型空间的位置转换到裁剪空间。同时处理顶点颜色。 曲面细分这个阶段细分图元用的。比如实现LOD效果，加顶点实现更细节的动画，用低模加细分在运行的时候实现高模效果。 几何着色器几何着色器主要是添加或者减少图元。 裁剪在裁剪坐标系（其次坐标系）下裁减掉不在视野外的图元。 屏幕映射每个图元的X和Y坐标转换到二维的屏幕坐标系。 三角形设置计算三角网格表示数据的过程。 三角形遍历检查每个像素是否被三角网格覆盖，是的话就生成一个片元。并且对信息进行插值 片元着色器对片元进行效果颜色的最终计算 逐片元操作先进行测试工作，比如模版测试-&gt;深度测试-&gt;透明测试。如果通过所有测试还要进行颜色混合。当然如果没有透明的话片元测试会在片元着色器前面。最后输出像素到颜色缓冲区。 屏幕图像利用双缓冲技术，将颜色打印到屏幕上 人物描边的方法一.屏幕后处理方法。先用获取深度图，再比较点和周围八个点的Normal和Depth是否大于一定的阀值，如果是则是边，添加颜色。 二.视角和法线的点积，进行描边。 三.写两个Pass, 然后第一个pass的顶点根据法线外移一定的量进行描边。 屏幕模糊处理一.压缩像素模糊。获取屏幕图片，然后放在低像素的RT进行压缩，再放回到原像素。 二.快速模糊。获取屏幕图片，像素点取周围4或8个点的颜色累加，然后再除以4或8。 三.卷积核模糊（高斯模糊）。获取屏幕图片，按照周围的点用一定的卷积核（按权系数）进行平均颜色。 四.运动模糊1。储存多帧图片。图片按权融合作为最后的屏幕图片，累计缓存 五.运动模糊2。获取上一帧和当前帧的深度纹理。建立当前片元的NDC。当前的世界坐标*上一帧的VP再除以上一帧的齐次坐标的w，得到上一帧数的lastNDC，再lastNDC-ndc=&gt;speed,沿speed方向进行多次采样。作为颜色， 六．深度模糊（景深DOF）。思路是首先渲染一张模糊的图，然后在深度图中找到聚焦点对应的深度，该深度附近用原图，其他地方渐变至模糊图。 HDR高动态范围，指用远远高于8位的精度去存储亮度信息。最后还是要通过ToneMapping映射会LDR内。 全局光照模拟光线在场景中的传播，其实就是计算间接光照。无论是Bake全局光照，还是预计算实时全局光照，都只对Static物体有效。 伽马校正就是把像素写入颜色缓冲时进行抵消显示伽马的处理。 在伽马空间，整体颜色会比较暗，因为受到了显示伽马的转换。 在线性空间，因为进行了抵消显示伽马的处理，所以会比较亮。 ) 美术输出资源时都是在sRGB空间的，但Normal Map等其他电脑计算出来的纹理则一般在线性空间，即Linear Texture。 所有需要人眼参与被创作出来的纹理，都应是sRGB（如美术画出来的图）。所有通过计算机计算出来的纹理（如噪声，Mask，LightMap）都应是Linear。 Unity中的Color Space Gamma，那Unity不会对输入和输出做任何处理，换句话说，Remove Gamma Correction 、Gamma Correction都不会发生，除非你自己手动实现。 Linear，那么就是上文提到的统一线性空间的流程了。对于sRGB纹理，Unity在进行纹理采样之前会自动进行Remove Gamma Correction，对于Linear纹理则没有这一步。而在输出前，Unity会自动进行Gamma Correction再让显示器输出。 ShadowMap的实现在灯的位置用相机渲染一个LightMode 为ShadowCaster Pass通道来得到可投射阴影的光源的阴影映射纹理以及摄像机的深度纹理，利用这两个纹理来得到屏幕空间的阴影图，如果摄像机的深度图中记录的表面深度大于转换到阴影映射纹理中的深度值，则说明该表面是可见的但是却处于阴影当中。 使用Unity内置的阴影三剑客接受阴影直接用Unity 的Shadow_Coords、Transfer_Shadow和 Shadow_Attenuation。光照衰减用Unity_Light_Attenuation Shader的优化使用Shader的LOD技术，只有Shader的LOD值小于某个值，Shader才能使用。 将计算放在顶点函数上，计算顶点数&lt;像素数。 尽可能用低精度的浮点数运算。float适合顶点坐标，half适合纹理坐标，标量，fixed适合颜色变量。 尽可能用少的插值变量，例如我们可以把两个纹理坐标打包在一个四维变量内。 把多个屏幕后特效合并到一个Shader里面。 不要使用分支语句和循环语句。 不要进行Sin，cos等复杂的数学运算，可以用查找表代替。 尽量不要Discard操作，会影响某些硬件优化。 不同几种剔除(Culling)在渲染流程中的使用总结视椎体剔除发生在应用程序阶段(Application Stage),运行在CPU上。裁剪的依据主要是根据摄像机的视野(field of view)以及近裁减面和远裁剪面的距离，将可视范围外的物体排除出渲染，被剔除的物体将不会进入渲染的几何阶段(Geometry Stage)。 遮挡剔除发生在应用程序阶段(Application Stage)，运行在CPU上。根据场景中Static物体的位置预先生成场景OcclusionCulling数据，运行时就可以剔除对应静态物体之后的其他物体。 视口剔除发生在几何阶段(Geometry Stage)后期，投影变换之后屏幕映射之前，是渲染管线的必要一环。通过视口剔除可以将视口外的图元舍弃掉，减小光栅化阶段的消耗。 背面剔除背面剔除即是将背向视点的图元剔除，因为它们对最终渲染的图像没有贡献。 Shader后处理屏幕模糊处理降采样模糊获取屏幕图片，放到低分辨率的RT图中，然后放回屏幕上。 快速模糊获取屏幕图片，采样周边4或8个像素的值，取平均。 高斯模糊(卷积核模糊)获取屏幕图片，分两个Pass，分别进行竖直方向和水平方向的卷积核处理。 运动模糊（累积缓冲）存储多帧照片，然后进行融合。 运动模糊（运动缓冲）构建当前帧的NDC，然后获取深度纹理，根据深度图重构世界坐标，得到世界坐标后，与上一帧的VP矩阵相乘，得到上一帧的NDC位置，CurrentNDC - LastNdc得到速度方向，按照速度方向进行多次采样。 Bloom(全屏后处理)获取屏幕图片，第一Pass获取提取亮度区域，第二，三Pass进行高斯模糊，第四Pass进行Bloom和原图叠加。 Glow(选择区域Bloom)第一种方法：利用人物的Alpha通道进行存储要Bloom的区域，然后进行后处理 第二种方法：设置与主摄像机一致专门用于渲染要Bloom的物体的摄像机，在C#利用Shader的RenderType 用RenderWithShader 替换要发亮的Shader 然后再在C#中进混合。 景深首先得到一张高斯模糊的图片，然后利用深度图重构世界坐标，根据深度减去阈值进行lerp（原图，模糊图）。 雾的做法利用深度图重构世界坐标，计算雾效系数，作为雾颜色和原始颜色的混合。三种计算方式： 线性，指数，指数平方 Mipmap多级渐远纹理，预先计算好图片缩小后的图片，每一层都是对上一层图片降采样的结果，当物体原理摄像机就可以直接使用较小的纹理，空间换时间。如果不是用Mipmap就会出现失真状况。 色彩空间 调整亮度，饱和度，对比度首先利用亮度公式得到像素的亮度值：luminance = 0.2125 * R+0.7154 * G + 0.0721 * B。 利用亮度值创建一个饱和度为0的颜色值：(luminance,luminance,luminance),进行插值 创建一个对比度为0的颜色值(各分量为0.5)：再进行插值。 四元数和旋转欧拉旋转Unity的旋转顺序是ZXY们，还有两种旋转时所用的旋转坐标： 1.绕坐标系E下的Z轴旋转α，绕坐标系E下的Y轴旋转β，绕坐标系E下的X轴旋转r，即进行一次旋转时不一起旋转当前坐标系； 2.绕坐标系E下的Z轴旋转α，绕坐标系E在绕Z轴旋转α后的新坐标系E’下的Y轴旋转β，绕坐标系E’在绕Y轴旋转β后的新坐标系E’’下的X轴旋转r， 即在旋转时，把坐标系一起转动； 在第一种情况下、按ZXY顺序旋转和在第二种情况下、按YXZ顺序旋转是一样的。 Unity选择使用的是第一种","link":"/2020/08/23/Static%20Batch,Dynamic%20Batch,GPU%20Instancing/"},{"title":"C++重点","text":"C++对象的内存模型当对象被创建时，编译器会为每个对象分配内存空间，包括成员变量和成员函数。 直观直观的认识是，如果定义了10个对象，那么就要分别为这10个对象的变量和函数分配内存空间，如下图所示： 虽然每个对象的成员变量不同，但是成员函数的代码却是一样的，上面的内存模型保存了10份相同的代码片段，浪费了很多空间。 事实事实上，编译器会将成员变量和成员函数分开存储：分别为每个对象的成员变量分配内存，但是所有对象都共享同一段函数代码。如下图所示： 对象的大小只受成员变量的影响，和成员函数没有关系。成员函数在代码区分配内存，而不是在栈区。 C++函数编译原理和成员函数的实现C++中的函数在编译时会根据它所在的命名空间、它所属的类、以及它的参数列表（也叫参数签名）等信息进行重新命名，形成一个新的函数名。这个新的函数名只有编译器知道，对用户是不可见的。名字编码（Name Mangling） 成员函数的调用成员函数最终被编译成与对象无关的全局函数。成员变量的作用域不是全局，不经任何处理就无法在函数内部访问。 C++规定，编译成员函数时要额外添加一个参数，把当前对象的指针传递进去，通过指针来访问成员变量。 123456789101112//编译前void Demo::display(){cout&lt;&lt;a&lt;&lt;endl;cout&lt;&lt;b&lt;&lt;endl;}//编译后void new_function_name(Demo * const p){//通过指针p来访问a、bcout&lt;&lt;p-&gt;a&lt;&lt;endl;cout&lt;&lt;p-&gt;b&lt;&lt;endl;} 这样通过传递对象指针就完成了成员函数和成员变量的关联。这与我们从表明上看到的刚好相反，通过对象调用成员函数时，不是通过对象找函数，而是通过函数找对象。 对象数组所谓对象数组，指每一个数组元素都是对象的数组，即若一个类有若干个对象，我们把这一系列的对象用一个数组来存放。 构造函数有0或1个参数如果构造函数只有1个参数，在定义对象数组时可以直接在等号后面的花括号内提供实参来实现初始化。 1exam ob1[4]={11,22,33,44}; //用只有1个参数的构造函数给对象数组赋值 C++成员对象和封闭类详解一个类的成员变量如果是另一个类的对象，就称之为“成员对象”。包含成员对象的类叫封闭类（enclosed class）。 封闭类构造函数的初始化列表当封闭类的对象生成并初始化时，它包含的成员对象也需要被初始化，这就会引发成员对象构造函数的调用。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class CTyre //轮胎类{private: int radius; //半径 int width; //宽度public: CTyre(int r, int w) : radius(r), width(w) { }};class CEngine //引擎类{};class CCar { //汽车类private: int price; //价格 CTyre tyre; CEngine engine;public: CCar(int p, int tr, int tw);};CCar::CCar(int p, int tr, int tw) : price(p), tyre(tr, tw){};int main(){ CCar car(20000, 17, 225); return 0;} 生成封闭类对象的语句一定要让编译器能够弄明白其成员对象是如何初始化的 执行顺序封闭类对象生成时，先执行所有成员对象的构造函数，然后才执行封闭类自己的构造函数。成员对象构造函数的执行次序和成员对象在类定义中的次序一致，与它们在构造函数初始化列表中出现的次序无关。 当封闭类对象消亡时，先执行封闭类的析构函数，然后再执行成员对象的析构函数，成员对象析构函数的执行次序和构造函数的执行次序相反，即先构造的后析构 思考：为什么封闭类对象消亡时，要先执行封闭类的析构函数，然后才执行成员对象的析构函数 答：是因为可能封闭类中析构函数会调用成员对象 封闭类的复制构造函数封闭类的对象，如果是用默认复制构造函数初始化的，那么它包含的成员对象也会用复制构造函数初始化。 静态成员变量静态成员变量是一种特殊的成员变量，它被关键字static修饰 1static int m_total; //静态成员变量 static 成员变量属于类，不属于某个具体的对象，即使创建多个对象，也只为 m_total 分配一份内存，所有对象使用的都是这份内存中的数据。当某个对象修改了 m_total，也会影响到其他对象。 注意：static 成员变量不占用对象的内存，而是在所有对象之外开辟内存，即使不创建对象也可以访问。具体来说，static 成员变量和普通的 static 变量类似，都在内存分区中的全局数据区分配内存 静态成员函数静态成员函数与普通成员函数的根本区别在于：普通成员函数有 this 指针，可以访问类中的任意成员；而静态成员函数没有 this 指针，只能访问静态成员（包括静态成员变量和静态成员函数）。 Const成员变量和成员函数在类中，如果你不希望某些数据被修改，可以使用const关键字加以限定。const 可以用来修饰成员变量和成员函数。 const成员变量初始化 const 成员变量只有一种方法，就是通过构造函数的初始化列表 const成员函数（常成员函数）const 成员函数可以使用类中的所有成员变量，但是不能修改它们的值，这种措施主要还是为了保护数据而设置的。 const的位置最后再来区分一下 const 的位置： 函数开头的 const 用来修饰函数的返回值，表示返回值是 const 类型，也就是不能被修改，例如const char * getname()。 函数头部的结尾加上 const 表示常成员函数，这种函数只能读取成员变量的值，而不能修改成员变量的值，例如char * getname() const。 Const对象一旦将对象定义为常对象之后，不管是哪种形式，该对象就只能访问被 const 修饰的成员了（包括 const 成员变量和 const 成员函数），因为非 const 成员可能会修改对象的数据（编译器也会这样假设），C++禁止这样做。 1const Student stu(&quot;小明&quot;, 15, 90.6); C++函数参数为什么要使用const引用const引用可以初始化为不同类型的对象或者初始化为右值,普通的const引用则只能绑定到与该引用同类型的对象。 1234567891011121314151617181920212223#include &lt;iostream&gt;class Foo {public: Foo() {} ~Foo() {} int a;};void do_not_optimize(Foo &amp;v){ std::cout &lt;&lt; v.a &lt;&lt; std::endl;}void do_not_optimize2(const Foo &amp;v){ std::cout &lt;&lt; v.a &lt;&lt; std::endl;}int main(){ const int&amp; a = 10; //编译通过 // int &amp;b = 20; //，编译错误，字面常量是右值 // do_not_optimize(Foo()); //compile error,函数返回值是临时变量，是右值 do_not_optimize2(Foo()); return 0;} 当传递进函数参数的类型不对的时候，C++会进行自动的类型转换，生成一个临时变量，这样为右值。 友元函数和友元类借助友元（friend），可以使得其他类中的成员函数以及全局范围内的函数访问当前类的 private 成员。 1friend void show(Student *pstu); //将show()声明为友元函数 将其他类的成员函数声明为友元函数1234567//声明Student类public: void show(Address *addr);//声明Address类//将Student类中的成员函数show()声明为友元函数 friend void Student::show(Address *addr); 友元类不仅可以将一个函数声明为一个类的“朋友”，还可以将整个类声明为另一个类的“朋友”，这就是友元类。友元类中的所有成员函数都是另外一个类的友元函数。 12//将Student类声明为Address类的友元类 friend class Student; 浅析C++类的作用域class和struct到底有什么区别 使用 class 时，类中的成员默认都是 private 属性的；而使用 struct 时，结构体中的成员默认都是 public 属性的。 class 继承默认是 private 继承，而 struct 继承默认是 public 继承 class 可以使用模板，而 struct 不能 建议：在编写C++代码时，我强烈建议使用 class 来定义类，而使用 struct 来定义结构体，这样做语义更加明确。 C++引用一种比指针更加便捷的传递聚合类型数据的方式，那就是引用（Reference）。 引用可以看做是数据的一个别名，通过这个别名和原来的名字都能够找到这份数据。 1type &amp;name = data; 引用必须在定义的同时初始化，并且以后也要从一而终，不能再引用其它数据. 注意，引用在定义时需要添加&amp;，在使用时不能添加&amp;，使用时添加&amp;表示取地址。 C++引用作为函数返回值不能返回局部数据（例如局部变量、局部对象、局部数组等）的引用，因为当函数调用完成后局部数据就会被销毁 C++引用在本质上是什么，它和指针到底有什么区别？相同点：都是地址的概念； 指针指向一块内存，它的内容是所指内存的地址；而引用则是某块内存的别名。 **不同点： 指针是一个实体，而引用仅是个别名； 引用只能在定义时被初始化一次，之后不可变；指针可变；引用“从一而终”，指针可以“见异思迁”； //引用没有const，指针有const，const的指针不可变； 引用不能为空，指针可以为空 “sizeof 引用”得到的是所指向的变量(对象)的大小，而“sizeof 指针”得到的是指针本身的大小； 引用是类型安全的，而指针不是 (引用比指针多了类型检查 指针和引用的自增(++)运算意义不一样； C++引用为什么不能绑定到临时数据临时变量的定义：临时变量通常在函数参数传递发生类型转换以及函数返回值时被创建。 123456789101112void uppercasify(const string&amp; str){}int main(int argc, char* argv[]){ char subtleBookPlug[] = &quot;Effective C++&quot;; uppercasify(subtleBookPlug); // 此处有类型转换 return 1;} 函数uppercasify需要const string&amp;类型的参数，而实参类型为char *，故编译器会尝试着进行类型转换。此时一个string类型的临时变量将被创建，并用subtleBookPlug来初始化对象，最后将临时变量传给函数uppercasify。 123456789101112void uppercasify(string&amp; str) // 参数类型改为string &amp;{}int main(int argc, char* argv[]){ char subtleBookPlug[] = &quot;Effective C++&quot;; uppercasify(subtleBookPlug); return 1;} 如果创建了一个临时变量，那函数所修改的对象为临时变量，而不是用户所期待的subtleBookPlug了，从而容易引起误操作。 C++继承时的名字遮蔽问题如果派生类中的成员（包括成员变量和成员函数）和基类中的成员重名，那么就会遮蔽从基类继承过来的成员。所谓遮蔽，就是在派生类中使用该成员（包括在定义派生类时使用，也包括通过派生类对象访问该成员）时，实际上使用的是派生类新增的成员，而不是从基类继承来的。 基类成员函数和派生类成员函数不构成重载 C++类继承时的作用域嵌套在继承情况下，派生类的作用域嵌套在基类作用域中：如果不能在派生类作用域中确定名字，就在外围基类作用域中查找该名字的定义。 123Bulk_item bulk; cout &lt;&lt; bulk.book() &lt;&lt; endl; 名字book的使用将这样确定[先派生-&gt;后基类]： C++继承时的对象模型没有继承时的内存模型 对象的内存中只包含成员变量，存储在栈区或堆区（使用 new 创建对象）； 成员函数与对象内存分离，存储在代码区。 继承时的内存模型有继承关系时，派生类的内存模型可以看成是基类成员变量和新增成员变量的总和，所有成员函数仍在另外一个区域——代码区，由所有对象共享。 可以发现，基类的成员变量排在前面，派生类的排在后面。 有成员变量遮蔽时的内存分布当基类A、B的成员变量被遮蔽，仍然会留在派生类对象 obj_c 的内存中，C 类新增的成员变量始终排在基类A、B的后面。 C++多继承时的对象内存模型无虚函数时排列顺序： 继承自父类的成员变量排在当前类所有成员变量之前 继承自多个父类的成员变量按照类继承列表中的声明顺序依次排列每个父类中的成员变量 C++虚继承和虚基类详解 类 A 派生出类 B 和类 C，类 D 继承自类 B 和类 C，这个时候类 A 中的成员变量和成员函数继承到类 D 中变成了两份，一份来自 A–&gt;B–&gt;D 这条路径，另一份来自 A–&gt;C–&gt;D 这条路径。 虚继承为了解决多继承时的命名冲突和冗余数据问题，C++ 提出了虚继承，使得在派生类中只保留一份间接基类的成员。 12345//直接基类Bclass B: virtual public A{ //虚继承protected: int m_b;}; 这段代码使用虚继承重新实现了上图所示的菱形继承，这样在派生类 D 中就只保留了一份成员变量 m_a，直接访问就不会再有歧义了。 这个被共享的基类就称为虚基类（Virtual Base Class） 虚继承时的构造函数在虚继承中，虚基类是由最终的派生类初始化的，换句话说，最终派生类的构造函数必须要调用虚基类的构造函数。 在普通继承中，派生类构造函数中只能调用直接基类的构造函数，不能调用间接基类的。 C++虚继承下的内存模型举例：假设有虚继承结构如下，虚基类A中有int成员a_；B1虚继承自A，有int成员b1_；B2虚继承自A，有int成员b2_；D继承自B1、B2，有int成员d_。 分析：B1类对象内存模型 该对象的内存分为B1部分和虚基类部分。从B1部分的首地址开始的4个字节存放的是一个vbptr（B1部分的虚基类表指针），该指针指向了一个虚基类表（virtual base table of B1） 分析：D类对象内存模型 C++向上转型类其实也是一种数据类型，也可以发生数据类型转换，不过这种转换只有在基类和派生类之间才有意义，并且只能将派生类赋值给基类，包括将派生类对象赋值给基类对象、将派生类指针赋值给基类指针、将派生类引用赋值给基类引用，这在 C++ 中称为向上转型（Upcasting）。相应地，将基类赋值给派生类称为向下转型（Downcasting）。 将派生类对象赋值给基类对象赋值的本质是将现有的数据写入已分配好的内存中，对象的内存只包含了成员变量，所以对象之间的赋值是成员变量的赋值，成员函数不存在赋值问题。 这种转换关系是不可逆的，只能用派生类对象给基类对象赋值，而不能用基类对象给派生类对象赋值。理由很简单，基类不包含派生类的成员变量，无法对派生类的成员变量赋值。同理，同一基类的不同派生类对象之间也不能赋值。 将派生类指针赋值给基类指针 概括起来说就是：编译器通过指针来访问成员变量，指针指向哪个对象就使用哪个对象的数据；编译器通过指针的类型来访问成员函数，指针属于哪个类的类型就使用哪个类的函数。 将派生类指针赋值给基类指针时到底发生了什么？（未解决）C++帮你进行了隐式转换 多态与虚函数面向对象程序设计语言有封装、继承和多态三种机制，这三种机制能够有效提高程序的可读性、可扩充性和可重用性。 为了让基类指针能够访问派生类的成员函数，C++ 增加了虚函数（Virtual Function）。使用虚函数非常简单，只需要在函数声明前面增加 virtual 关键字。 123456789//基类Peoplepublic: People(char *name, int age); virtual void display(); //声明为虚函数 //派生类Teacherpublic: Teacher(char *name, int age, int salary); virtual void display(); //声明为虚函数 有了虚函数，基类指针指向基类对象时就使用基类的成员（包括成员函数和成员变量），指向派生类对象时就使用派生类的成员。换句话说，基类指针可以按照基类的方式来做事，也可以按照派生类的方式来做事，它有多种形态，或者说有多种表现方式，我们将这种现象称为多态（Polymorphism）。 C++提供多态的目的是：可以通过基类指针对所有派生类（包括直接派生和间接派生）的成员变量和成员函数进行“全方位”的访问，尤其是成员函数。如果没有多态，我们只能访问成员变量。 多态的用途12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;using namespace std;//军队class Troops{public: virtual void fight(){ cout&lt;&lt;&quot;Strike back!&quot;&lt;&lt;endl; }};//陆军class Army: public Troops{public: void fight(){ cout&lt;&lt;&quot;--Army is fighting!&quot;&lt;&lt;endl; }};//99A主战坦克class _99A: public Army{public: void fight(){ cout&lt;&lt;&quot;----99A(Tank) is fighting!&quot;&lt;&lt;endl; }};//武直10武装直升机class WZ_10: public Army{public: void fight(){ cout&lt;&lt;&quot;----WZ-10(Helicopter) is fighting!&quot;&lt;&lt;endl; }};int main(){ Troops *p = new Troops; p -&gt;fight(); //陆军 p = new Army; p -&gt;fight(); p = new _99A; p -&gt; fight(); p = new WZ_10; p -&gt; fight(); p = new CJ_10; p -&gt; fight(); //空军 p = new AirForce; p -&gt; fight(); p = new J_20; p -&gt; fight(); p = new CH_5; p -&gt; fight(); p = new H_6K; p -&gt; fight(); return 0;} 有了多态，只需要一个指针变量 p 就可以调用所有派生类的虚函数。 C++虚函数注意事项以及构成多态的条件构成多态的条件 必须存在继承关系； 继承关系中必须有同名的虚函数，并且它们是覆盖关系（函数原型相同）。 存在基类的指针，通过该指针调用虚函数。 虚函数指针总结：当使用类的指针调用成员函数时，普通函数由指针类型决定，而虚函数由指针指向的实际类型决定 一般继承（无虚函数覆盖） 一般继承（有虚函数覆盖） 多重继承（无虚函数覆盖） 多重继承（有虚函数覆盖） 虚析构函数的必要性虚析构函数使得在删除指向子类对象的基类指针时可以调用子类的析构函数达到释放子类中堆内存的目的，而防止内存泄露的. 顺序：先析构子类然后析构基类。 纯虚函数和抽象类1virtual 返回值类型 函数名 (函数参数) = 0; 纯虚函数没有函数体，只有函数声明，在虚函数声明的结尾加上=0，表明此函数为纯虚函数。 包含纯虚函数的类称为抽象类（Abstract Class）。 抽象基类除了约束派生类的功能，还可以实现多态。 12345678910int main(){ Line *p = new Cuboid(10, 20, 30); cout&lt;&lt;&quot;The area of Cuboid is &quot;&lt;&lt;p-&gt;area()&lt;&lt;endl; cout&lt;&lt;&quot;The volume of Cuboid is &quot;&lt;&lt;p-&gt;volume()&lt;&lt;endl; p = new Cube(15); cout&lt;&lt;&quot;The area of Cube is &quot;&lt;&lt;p-&gt;area()&lt;&lt;endl; cout&lt;&lt;&quot;The volume of Cube is &quot;&lt;&lt;p-&gt;volume()&lt;&lt;endl; return 0;} C++运算符重载也就是说，运算符重载是通过函数实现的，它本质上是函数重载。 格式123返回值类型 operator 运算符名称 (形参表列){ //TODO:} 在全局范围内重载运算符12345678910//声明为友元函数 friend complex operator+(const complex &amp;A, const complex &amp;B); //在全局范围内重载+complex operator+(const complex &amp;A, const complex &amp;B){ complex C; C.m_real = A.m_real + B.m_real; C.m_imag = A.m_imag + B.m_imag; return C;} 运算符重载函数不是 complex 类的成员函数，但是却用到了 complex 类的 private 成员变量，所以必须在 complex 类中将该函数声明为友元函数。 C++运算符重载时要遵循的规则1) 并不是所有的运算符都可以重载。 2) 重载不能改变运算符的优先级和结合性。 3) 重载不会改变运算符的用法，原有有几个操作数、操作数在左边还是在右边，这些都不会改变。 4) 运算符重载函数不能有默认的参数，否则就改变了运算符操作数的个数，这显然是错误的。 5) 运算符重载函数既可以作为类的成员函数，也可以作为全局函数。 将运算符重载函数作为类的成员函数时，二元运算符的参数只有一个，一元运算符不需要参数。之所以少一个参数，是因为这个参数是隐含的。 将运算符重载函数作为全局函数时，一般都需要在类中将该函数声明为友元函数。原因很简单，该函数大部分情况下都需要使用类的 private 成员。 以全局函数(友元函数)形式重载123/以全局函数的形式重载 friend Complex operator+(const Complex &amp;c1, const Complex &amp;c2); friend Complex operator-(const Complex &amp;c1, const Complex &amp;c2); 以成员函数的形式重载12Complex &amp; operator+=(const Complex &amp;c);Complex &amp; operator-=(const Complex &amp;c); 友元函数和成员函数重载的区别成员函数：单目运算符作为类成员函数重载时没有型参（除了后置自增（自减）有一个整型参数： 双目运算符作为类成员函数重载时只有一个型参，作为运算符的右操作数，其左操作数就是本对象自己，也就是this。 友元函数：需要定义两个参数来运算（对于双目运算符）；这样就可以使用交换律。 友元可以像类成员一样访问类的成员和函数，但是使用不慎会造成破坏类的封装性。 C++重载&gt;&gt;和&lt;&lt;cout 是 ostream 类的对象，cin 是 istream 类的对象，要想达到这个目标，就必须以全局函数（友元函数）的形式重载&lt;&lt;和&gt;&gt; 12345678910111213friend istream &amp; operator&gt;&gt;(istream &amp; in, complex &amp; A);friend ostream &amp; operator&lt;&lt;(ostream &amp; out, complex &amp; A); //重载输入运算符istream &amp; operator&gt;&gt;(istream &amp; in, complex &amp; A){ in &gt;&gt; A.m_real &gt;&gt; A.m_imag; return in;}//重载输出运算符ostream &amp; operator&lt;&lt;(ostream &amp; out, complex &amp; A){ out &lt;&lt; A.m_real &lt;&lt;&quot; + &quot;&lt;&lt; A.m_imag &lt;&lt;&quot; i &quot;;; return out;} C++重载[]（下标运算符)C++ 规定，下标运算符[ ]必须以成员函数的形式进行重载。 格式 1返回值类型 &amp; operator[ ] (参数); 1const 返回值类型 &amp; operator[ ] (参数) const; 第一种声明方式，[ ]不仅可以访问元素，还可以修改元素。 使用第二种声明方式，[ ]只能访问而不能修改元素。 在实际开发中，我们应该同时提供以上两种形式，这样做是为了适应 const 对象，因为通过 const 对象只能调用 const 成员函数，如果不提供第二种形式，那么将无法访问 const 对象的任何元素。 C++重载++和–（自增和自减运算符）12stopwatch operator++(); //++i，前置形式stopwatch operator++(int); //i++，后置形式 在这个函数中参数n是没有任何意义的，它的存在只是为了区分是前置形式还是后置形式。 C++重载new和delete运算符内存管理运算符 new、new[]、delete 和 delete[] 也可以进行重载，其重载形式既可以是类的成员函数，也可以是全局函数。一般情况下，内建的内存管理运算符就够用了，只有在需要自己管理内存时才会重载。 C++模板C++异常处理入门，C++ try catch入门程序的错误大致可以分为三种，分别是语法错误、逻辑错误和运行时错误 C++ 提供了异常（Exception）机制，让我们能够捕获运行时错误，给程序一次“起死回生”的机会，或者至少告诉用户发生了什么再终止程序。 捕获异常12345try{ // 可能抛出异常的语句}catch(exceptionType variable){ // 处理异常的语句} catch 告诉 try：你去检测一下程序有没有错误，有错误的话就告诉我，我来处理，没有的话就不要理我！ 处理流程抛出（Throw）–&gt; 检测（Try） –&gt; 捕获（Catch） C++多维数组和指针1数组与指针的关系是因为数组下标操作符[]，比如，int a[3][2]相当于*(*(a+3)+2) 。 一维数组与数组指针1char a[3]; 数组一共有3个元素，元素的类型为char，如果想定义一个指针指向该数组，也就是如果想把数组名a赋值给一个指针变量。一个数组的数组名代表其首元素的首地址，也就是相当于&amp;a[0]，而a[0]的类型为char，因此&amp;a[0]类型为char *。 1char * p = a;//相当于char * p = &amp;a[0] a和&amp;a[0]代表的都是数组首元素的首地址，而如果你将&amp;a的值打印出来，会发现该值也等于数组首元素的首地址。&amp;a虽然在数值上也等于数组首元素首地址的值，但是其类型并不是数组首元素首地址类型，也就是char *p = &amp;a是错误的。 对数组名进行取地址操作，其类型为整个数组，因此，&amp;a的类型是char (*)[3] 1char (*p)[3] = &amp;a; 二维数组与数组指针二维数组 1char a[3][2]; 123char (*p)[2] = a;//a为第一维数组的数组名，类型为char (*)[2] char * p = a[0];//a[0]维第二维数组的数组名，类型为char * 对a取地址操作代表整个数组的首地址，类型为数组类型(请允许我暂且这么称呼)，也就是char (*)[3][2] 1char (*p)[3][2] = &amp;a; 多级指针所谓的多级指针，就是一个指向指针的指针 12345char *p = &quot;my name is chenyang.&quot;; char **pp = &amp;p;//二级指针 char ***ppp = &amp;pp;//三级指针 智能指针unique_ptr: 不允许多个指针共享资源，就是不能指向同一个内存地址，但可以用Move函数转移内存地址给另一个指针，但原指针会失效，Move的作用就是将左值转换为了右值。 shared_ptr: 多个指针共享资源 weak_ptr: 可以复制shared_ptr，但其构造和释放对资源不造成影响 Vector对象C++标准模板库里的类模板，比数组更加安全和方便，能容纳任何类型的数组，只要使用前说明类型。 12vector&lt;int&gt; arr(5);建立大小为5的int数组 配合auto进行for循环 深层复制和浅层复制浅层复制实现对象间数据元素的一一对应复制，默认的复制构造方法是浅层复制 深层复制当被复制的对象数据成员是指针类型时，不是复制该指针成员本身，而是将指针所指对象进行复制 移动构造源对象资源的控制权全部交给目标对象 函数返回含有指针成员的对象 版本一（使用深层复制构造函数）：返回时构造临时对象，动态分配将临时对象返回到Main函数，然后删除临时对象 在这里，由于a在getNum函数完成之后会消亡，但又为了Return回a对象，所以需要创建临时变量存储a对象，这时候就用到了深层复制构造函数。 版本二（使用移动构造函数）：将要返回的局部对象转移到主调函数，避免了内存的无谓拷贝。 &amp;&amp;为右值引用，临时变量为右值 移动操作必须确保移动后源对象可以被销毁且销毁后不会影响新创建的对象，例如如果源对象中有数据成员是指针，则必须置为空，否则在源对象执行析构函数时，会将新创建对象中的指针指向的资源释放掉。 字符串常量 C风格字符串 String类 C++函数指针一种特殊的指针，它指向函数的入口； 12345/** 定义一个函数指针p，只能指向返回值为int，形参为两个int的函数*/int (*p)(int,int);","link":"/2020/08/23/C++%E9%87%8D%E7%82%B9/"},{"title":"Hexo博客搭建过程(踩坑)","text":"前言​ 本文主要用来记录自己Hexo博客搭建过程中遇到的坑。 个人域名篇​ 这个个人域名的确有点坑，明明按着教程的操作一步一步来的，还是弄了一晚上，到最后才发现是校园网DNS的坑。。。 1.准备​ 首先我们要购买一个属于自己的域名，可以去腾讯云，阿里云等网站进行购买，这里我在阿里云购买opda.tech，为什么不用com域名，因为这个便宜。 ​ 购买域名后我们还要得到github仓库的IP。通过cmd命令行，输入Ping 你的名字.github.io获取名字 红色箭头所指就是你github仓库的IP，然后我们就可以进行DNS解析。 进去之后，点击新手引导，输入cmd获得的IP即可。 解析完的结果 ​ 2.github的绑定​ 进入你创建的仓库内，点击Setting ​ GitHub Pages设置 就这样github仓库的绑定就完成啦！ 3.最后一步我们还要在本地博客的source文件夹下新建一个CNAME.txt文本，在里面输入我们的自定义域名 最后我们Git Base重新部署一下博客就行啦！ 123hexo cleanhexo ghexo d 4.深坑​ 如果你是校园网用户的话，你要小心校园网DNS这个坑，会让你无法访问你自己的域名，所以解决方法就是修改我们的DNS就好了。 打开我们的控制面板—网络共享中心","link":"/2019/10/30/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"title":"UE4学习笔记(1)——简单框架","text":"前言纪录自己的UE4学习之路 UE4的简单框架 UE创世，万物皆UObject，接着有Actor 。 UobjectUobject是UE4中最基础的类，具有 元数据、反射生成、GC垃圾回收、序列化、编辑器可见，Class Default Object等功能。 ActorActor是UE4中最基本的场景元素，与Unity3D的gameobject相似，本身是一个容器，但是与unity不同的是，Actor没有任何可视化属性，甚至连位置属性也没有。但是也是与Unity相似，可以挂在多个可视化的组件( Component)，以达到各种功能，Actor也可以有子Actor。 Actor继承至Uobject，多了 Replication（网络复制）,Spawn（生生死死），Tick(有了心跳)等功能。 组件(Component)组件挂在Actor身上发挥功能，例如位置组件，Actor的最终位置来至于他的根组件。组件也可以有根组件。 PawnPawn是可以被控制的物体，相当于有controller的大脑，他可以是交通工具，鱼等，可以默认为生物的基类。 CharacterCharacter是人形的Actor，继承于Pawn， 默认拥有一个用于碰撞的胶囊体组件(CapsuleComponent)和运动相关的组件(CharacterMoveMentComponent)，并具有一些动画相关的功能。可以认为是人性动物的基类。 控制器(Controller)控制器用于控制Pawn的行为， 一般分为AIController和PlayerController。控制器也是从Actor派生的，因此也可以加入到场景中。 PlayerController 玩家控制器。是Pawn和控制其的玩家之间的桥梁，PlayerController代表了人类玩家的意愿。 AIController 用于控制NPC的控制器，决定了NPC如何与玩家互动。 显示HUDUI, 显示玩家的名字，血条，得分等信息。 相机 每个PlayerConroller都有一个PlayerCameraManager，代表了玩家的视角。 游戏规则和状态GameMode 游戏模式。处理游戏的规则，只存在与服务器端，因此客户端相关的逻辑不能存放在GameMode中。 GameState游戏状态， 记录游戏的数据，比如当前游戏的进度，世界任务的完成状态等，会自动同步到各个客户端。 PlayerState 玩家状态。记录玩家个人的数据，比如名字分数等，会自动同步到各个客户端。 总结GamePlay框架使用了MVC架构，其中Pawn是视图，PlayerState是数据模型，PlayerController是控制器。 一个游戏由游戏规则(GameMode)和游戏状态组成(GameState)；玩家在游戏里的化身是Pawn，玩家通过PlayerConroller控制着自己的化身，通过PlayerCameraManager观察世界，PlayerState记录了玩家的数据，HUD显示了这些状态；NPC则由AIConroller去控制，与玩家进行互动。","link":"/2020/08/23/UE4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E6%A1%86%E6%9E%B6/"},{"title":"UE4--材质大师课程笔记","text":"压缩和内存一般来说纹理导入UE4都是经过压缩的，压缩方式有BC(Block Compression块压缩)/DXTC(Directx Texture Compression DirectX纹理压缩)两种，其实都是用于PC的Directx平台的格式。但是法线贴图有点特殊，是无法通过这两种方式进行压缩的。 ​ 如下图所示就是贴图导入UE4后所选择的压缩方式。 压缩方式后面所带的数字表明是不同的压缩格式，例如BC3(DXTC5)表示带透明度的纹理，BC1(DXTC1)表示不带透明度的纹理。 法线贴图的压缩方式是通过剔除蓝色通道的方式进行压缩，这样可以存储更多的数据，同时对红色和绿色通道进行轻度压缩。最后通过对红绿色进行蓝色通道的复原，这些都是UE4内部自己调用的，不用我们去调整。如下图只是进行蓝色通道复原的演示。 注意的是，法线贴图的导入方式必须是选择NormalMap。 为什么要对纹理进行压缩最主要是因为受限于内存和带宽，如果不对纹理进行压缩，可能导致卡顿。但帧率过低一般和纹理压缩没有什么关系。可以通过查看统计数据，来查看场景中哪些纹理在内存中的大小。 多级渐进纹理 纹理尺寸和纹理池纹理池UE4在计算机内存中，会为纹理暴保留一定的空间，这个空间就是纹理池，我们可以手动调整纹理池的大小，当纹理池大小不够用的时候，会导致贴图的分辨率降低，效果下降。 打开控制台，输入r.Streaming.PoolSize查看纹理池大小，并且可以进行修改。 Mipmaps(多级渐进纹理)Mipmaps为原始纹理的副本，大小为1/4左右,使用Mipmaps的原因是为了减少噪点的生成。 左侧是使用了Mipmaps，右边没有使用，可以看出右边的噪点非常多，所以Mipmaps可以看成我们手动进行模糊 UE4会对远处使用不同的Mipmaps来模拟模糊的效果，如下图离镜头最近的就使用Mipmaps0原始纹理，然后随着离镜头越来越远，使用不同的Mipmaps。 可以在贴图的LOD选择中进行Mipmaps的设置 注意纹理尺寸使用Mipmaps可以提高我们的性能，加快渲染速度和减少纹理锯齿，但注意不适于2的幂数的纹理无法生成Mipmaps，但是UI纹理可以是任意分辨率，因为UI纹理不会从远处到近处，所以没必要使用Mipmaps。 材质的纹理数限制UE4的每个材质的纹理可采样数是16个，加上内部的光影贴图，其实我们可以用的大概是13个左右，其实已经够用了，但是如果要突破这个限制的话，我们可以把不同的贴图合成RGB通道就成为一张贴图，到使用的的时候就可以分RGB通道分为3张贴图。","link":"/2020/08/23/UE4--%E6%9D%90%E8%B4%A8%E5%A4%A7%E5%B8%88%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"title":"UE4学习笔记(2)---蓝图接口-标签","text":"蓝图接口 蓝图接口（Blueprint Interface） 是一个或多个函数的集合 - 只有名称，没有实现。可以添加到其他蓝图中。任何添加了该接口的蓝图都保证拥有这些函数。接口的函数 可以在添加它的每个蓝图中提供功能。在本质上，这类似于一般编程中的接口概念， 它允许多个不同类型的对象通过一个公共接口 共享和被访问。简单地说，蓝图接口允许不同的蓝图相互共享和发送数据。 创建蓝图接口 新建函数和函数的输入输出值 要使用蓝图接口，就必须继承该接口，并且实现。 实现接口之后，其他蓝图类就可以调用此方法，实现了蓝图之间的通信。 标签在调用蓝图接口方法前，先使用标签来判断是敌人还是友军，其实我感觉UE4的标签和Unity的标签还是挺相似的 标签的设置方法 调用蓝图接口方法 就这样完成了蓝图接口的调用","link":"/2020/08/23/UE4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)---%E8%93%9D%E5%9B%BE%E6%8E%A5%E5%8F%A3-%E6%A0%87%E7%AD%BE/"},{"title":"UE4材质大师课程笔记(二)---RenderTarget","text":"RenderTargetUE4的RenderTarget感觉和Unity的差不多，都是获得一个摄像机的渲染结果，然后存在RenderTarget里面进行读取使用。 在UE4中要使用RenderTarget，首先要添加SceneCapture2D组件或者SceneCapture Cube组件，前者获取2D，后者获取Cube立方体贴图。 RenderTarget的使用渲染材质在UE4中过程化生成噪点纹理是比较昂贵的，所以通常的做法是将材质绘制到RenderTarget中。 可以看出以上这个需要529条指令 将材质绘制到RenderTarget 得到左边的RenderTarget噪点图了，然后右键创建静态纹理则可以得到可以用的Texture纹理了。 指令就变为了34，效率得到了提升。 高级应用高度图效果如下，随着鼠标左键的按下，在平面生成不同的高度。 1.首先我们要创建MAT_HeightfieldPainter材质，设置如下，注意要把shading Model改为Unlit无光照模式。这个材质主要用于控制物体在Z轴的世界偏移。 2.创建MAT_ForceSplat材质，设置如下，主要用于处理鼠标点击平面所产生的uv坐标，通过下面的计算获得一个关于这个uv坐标为圆心的渐变圆形贴图 3.新建一个HeightFieldPainter的Actor蓝图，设置如下 然后在构造函数里面进行动态材质的设置，这里主要针对我们上面的材质创建动态材质。 新建TraceFromCamera函数，函数用于从摄像头方向射出射线，进行射线检测，如果检测到碰撞物体，就进行伤害传递。 Begin函数，首先我们要为新建一个RenderTexture并保存，同时将RT传递给Z轴偏移的MAT_HeightfieldPainter材质。 最后处理伤害函数，传递参数给MAT_ForceSplat材质，例如点击的uv坐标，力度，大小，最后要用Draw Material to Render Target函数将材质绘制到RT里面，这样HeighfieldPainter材质才会根据RT图进行Z轴的偏移。 这里注意，这种方法只适用于平面，计算点击位置的uv坐标也比较简单，首先获取点击位置的世界坐标，然后获取静态网格的worldTransform,然后通过Invert Transform获得从世界坐标到静态网格本地坐标的变换矩阵，将点击位置从世界空间转换为静态网格的本地空间，当然我们也要将得到的本地坐标转为uv坐标，就要除于网格的长宽，映射到【0，1】，这样就得到了正确的uv坐标。","link":"/2020/08/23/UE4%E6%9D%90%E8%B4%A8%E5%A4%A7%E5%B8%88%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0(%E4%BA%8C)---RenderTarget/"},{"title":"UE4官方直播材质篇 笔记","text":"矢量表达式ObjectPositionWS：输出对象边界的世界场景空间中心位置。 Absolute world position：输出世界空间中当前像素的位置。 ![absolu world position](D:\\360MoveData\\Users\\Administrator.WIN-OGAUOR7DBB3\\Desktop\\absolu world position.png) VertexNormalWS:表达式输出世界场景空间顶点法线 PixelNormalWS：表达式输出当前像素的世界空间法线向量 常量表达式PerInstanceRandom（按实例随机）：表达式按材质所应用于的静态网格实例输出不同的随机浮点值。 函数表达式SpeedTreeColorVariation:常用于不同物体的随机颜色 植物霜冻效果利用网格的世界空间法线的Z轴来进行SnowColor和BaseColor的渐变，渐变主要使用了Lerp函数。","link":"/2020/08/23/UE4%E5%AE%98%E6%96%B9%E7%9B%B4%E6%92%AD%E6%9D%90%E8%B4%A8%E7%AF%87-%E7%AC%94%E8%AE%B0/"},{"title":"Unity Compute Shader","text":"Unity Compute ShaderCompute Shader 就是一段运行在 GPU上的程序,这段程序并不需要用来处理网格数据或者是纹理数据的,它们可以输出缓冲数据或者纹理并且在多个执行的线程间共享内存。 数学和并行.任何一个涉及到对数据集中的每一个元素都进行一同样一系列操作(不包含条件分支)的问题都非常适合它。 Compute Shader例子1234567891011#pragma kernel CSMainRWTexture2D&lt;float4&gt; Result;[numthreads(8,8,1)]void CSMain (uint3 id : SV_DispatchThreadID){ // TODO: insert actual code here! Result[id.xy] = float4(id.x &amp; id.y, (id.x &amp; 15)/15.0, (id.y &amp; 15)/15.0, 0.0);} #pragma kernel CSMain 定义了该shader的入口函数。这也是C#文件访问该kernel的接口，下面会提到。当然，一个.compute文件可以包含多个kernel，只需要写多个#pragma kernel xxx即可。但是必须至少包含一个kernel，否则会报编译错误。 1#pragma kernel CSMain 这声明了一个变量,Shader会利用这个变量包含的数据来工作,因为我们不初始利用网格数据来工作的,所以你必须明确的声明你的Compute Shader要读或者写哪些数据。数据类型前面的”RW”表明了这个变量是可读可写的。 1RWTexture2D&lt;float4&gt; Result; 这一行指定了当前Compute Shader要产生的线程组的大小。GPU通过创建同时运行的多个线程，拥有大规模并行处理能力。线程组规定了如何组织这些生成的线程。在上面的代码中，我们指定了我们希望每个线程组包含64个线程。就像一个二维数组一样。 1[numthreads(8,8,1)] Compute shader的应用12345678910111213public ComputeShader shader; void RunShader(){int kernelHandle = shader.FindKernel(&quot;CSMain&quot;); RenderTexture tex = new RenderTexture(256,256,24);tex.enableRandomWrite = true;tex.Create(); shader.SetTexture(kernelHandle, &quot;Result&quot;, tex);shader.Dispatch(kernelHandle, 256/8, 256/8, 1);} FindKernel 方法需要一个字符串参数作为名字,这个名字可以Shader中相关内核程序的任意一个。 ComputeShader.SetTexture这个调用让我们可以把Shader需要的数据从CPU内存传递到GPU内存。 传递给Dispatch方法的三个整数定义了,我们想生成的线程组数量。我们一共生成的线程数量如下： 32 * 32个线程组 * 64(每个线程组中线程的数量) = 65536个线程，也就是内核程序的一次调用只处理一个像素。 线程的关系 如果我们在程序的Dispatch接口发送了（5，3，2）这样的结构，就会生成5x3x2个线程组，其中每个组的线程结构由ComputeShader中的numthreads定义，图中numthreads定义了10x8x3的三维结构 SV_GroupThreadID 表示该线程在该组内的位置 SV_GroupID 表示整个组所分配的位置 SV_DispatchThreadID 表示该线程在所有组的线程中的位置 SV_GroupIndex 表示该线程在该组内的索引 结构缓冲(Structured Buffers)在C#脚本定义数据类型 12345struct VecMatPair{public Vector3 point;public Matrix4x4 matrix;} 同时也得在Compute Shader中定义相应的结构 123456789101112131415#pragma kernel Multiplystruct VecMatPair{ float3 pos; float4x4 mat;};RWStructuredBuffer&lt;VecMatPair&gt; dataBuffer;[numthreads(16,1,1)]void Multiply (uint3 id : SV_DispatchThreadID){ dataBuffer[id.x].pos = mul(dataBuffer[id.x].mat, float4(dataBuffer[id.x].pos, 1.0));} 结构缓冲的应用首先需要指定好缓冲每一个元素所占的字节 123456789101112public ComputeShader shader; void RunShader(){ VecMatPair[] data = new VecMatPair[5]; //INITIALIZE DATA HERE ComputeBuffer buffer = new ComputeBuffer(data.Length, 76); int kernel = shader.FindKernel(&quot;Multiply&quot;); shader.SetBuffer(kernel, &quot;dataBuffer&quot;, buffer); shader.Dispatch(kernel, data.Length, 1,1);} GPU传递回CPU把数据传递会给CPU的代码非常的简单，你需要做的就是用一个相同类型的缓冲区接收它。 123456789101112131415public ComputeShader shader;void RunShader(){VecMatPair[] data = new VecMatPair[5];VecMatPair[] output = new VecMatPair[5];//INITIALIZE DATA HEREComputeBuffer buffer = new ComputeBuffer(data.Length, 76);int kernel = shader.FindKernel(&quot;Multiply&quot;);shader.SetBuffer(kernel, &quot;dataBuffer&quot;, buffer);shader.Dispatch(kernel, data.Length, 1,1);buffer.GetData(output);}","link":"/2020/08/23/Unity%20Compute%20Shader/"},{"title":"Unity PBR实现_学习笔记","text":"思路首先整理需要计算的光源：直接光照，间接光照，自发光，最后的光照效果加起来就行了。 首先直接光照，就是直接收到光源影响的光照，分为漫反射和和镜面反射。 间接光照，物体除了受到直接光源的影响，还会受到周围物体所反射的光和环境光，也分为间接漫反射和间接镜面反射。1.对于静态物体的间接漫反射，unity会把光照信息烘焙到Lightmap上，也就是光照贴图，也会分为动态光照贴图和静态光照贴图，我们只需采样贴图得到光照信息则可，动态物体则会用光照探针LightProbe。2.对于镜面反射，我们会采用反射探针来描绘物体反射的内容。 自发光，指物体自己能发光，物体的自发光也会对别的物体产生影响，需要额外写一个Pass。 实现准备材质属性 12345678910111213//材质属性 Properties{ _Color(&quot;Color&quot;,color)=(1,1,1,1) //颜色 _MainTex(&quot;Albedo&quot;,2D)=&quot;white&quot;{} //反照率，材质表面的颜色 _MetallicGlossMap(&quot;Metallic&quot;,2D)=&quot;white&quot; {}//金属贴图，r通道存储金属度，a通道存储光滑度 _BumpMap(&quot;Normal Map&quot;,2D)=&quot;white&quot; {} //法线贴图 _OcclusionMap(&quot;Occlusion&quot;,2D)=&quot;white&quot; {} //环境光遮挡贴图 AO _MetallicStrength(&quot;MetallicStrength&quot;,Range(0,1))=1 //金属强度 _GlossStrength(&quot;Smoothness&quot;,Range(0,1))=1 //光滑强度 _BumpScale(&quot;Normal Scale&quot;,Range(0,1))=1 //法线影响大小 _EmissionColor(&quot;EmissionColor&quot;,color)=(0,0,0) //自发光颜色 _EmissionMap(&quot;Emission Map&quot;,2D)=&quot;white&quot; {} //自发光贴图 } 顶点函数的输入输出结构体，texcoord1和texcoord2是为了计算动态和静态光照贴图所需要的uv坐标 12345678910111213141516171819202122//定义顶点函数的输入和输出函数 struct a2v { float4 vertex:POSITION; float3 normal:NORMAL; float4 tangent:TANGENT; float2 texcoord:TEXCOORD0; float2 texcoord1:TEXCOORD1;//计算动态光照贴图的uv坐标 float2 texcoord2:TEXCOORD2;//计算静态光照贴图的uv坐标 } struct v2f { float4 pos :SV_POSITION; float2 uv:TEXCOORD0; half4 ambientOrLightmapUV:TEXCOORD1;//存储环境光或光照贴图的uv坐标 float4 TtoW0:TEXCOORD2; float4 TtoW1:TEXCOORD3; float4 TtoW2:TEXCOORD4;//xyz存储从切线空间到世界空间的矩阵，w存储着世界坐标 SHADOW_COORDS(5)//定义阴影所需要的变量 UNITY_FOG_COORDS(6);//定义雾效所需要的变量 } 顶点函数用来准备片元函数所需要的数据，将顶点坐标从模型空间转换到裁剪空间，算出从切线空间到世界空间的矩阵，方便片元函数得到正确的法线向量，还有计算环境光照或光照贴图的uv坐标。 123456789101112131415161718192021222324252627282930//顶点函数主要计算片元函数需要的数据 v2f vert(a2v v) { v2f o; UNITY_INITIALIZE_OUTPUT(v2f,o);//初始化结构体数据，定义在HLSLSupport.cginc o.pos=UnityObjectToClipPos(v.vertex);//将顶点坐标从模型空间转换到裁剪空间 o.uv=TRANSFORM_TEX(v.texcoord,_MainTex);//计算偏移后的uv坐标 float3 worldPos=mul(Unity_ObjectToWorld,v.vertex);//获取世界空间的顶点坐标 half3 worldNormal= UnityObjectToWorldNormal(v.normal);//获取世界空间的法线向量 half3 worldTangent = UnityObjectToWorldDir(v.tangent);//获取世界空间的切线向量 half3 worldBinormal=cross(worldNormal,worldTangent)*v.tangent.w;//获取世界空间的副切线向量,*v.tangent.w是为了确定副切线的方向性 //计算环境光照或者光照贴图的uv坐标 o.ambientOrLightmapUV=VertexGI(v.texcoord1,v.texcoord2,worldPos,worldNormal); //前3x3存储着切线空间到世界空间的矩阵，后3x1存储着世界坐标 //这样做的目的是为了减少存储耗能 o.TtoW0 = float4(worldTangent.x,worldBinormal.x,worldNormal.x,worldPos.x); o.TtoW1 = float4(worldTangent.y,worldBinormal.y,worldNormal.y,worldPos.y); o.TtoW2 = float4(worldTangent.z,worldBinormal.z,worldNormal.z,worldPos.z); //填充阴影所选哟的参数 TRANSFER_SHADOW(o); //填充雾效所需要的参数 UNITY_TRANSFER_FOG(o,o.pos); return o; } VertexGI函数主要是为了计算环境光照或光照贴图的uv坐标。其中UNITY_SHOULD_SAMPLE_SH代码段处理的是从light probe中读取颜色值。一般渲染时静态物体读取lightmap，非静态物体读取light probe。 Unity内置函数参数解析： unity_LightmapST：光照贴图的uv坐标缩放和偏移参数 unity_4LightPosX0,unity_4LightPosY0,unity_4LightPosZ0 float4 //仅用于Base Pass,前4个非重要的点光源在世界空间中的位置 unity_DynamicLightmapST：动态光照贴图的uv坐标缩放和偏移参数 unity_LightColor half4[4] //仅用于Base Pass，存储了前4个非重要的点光源的颜色 unity_4LightAtten() float4 //仅用于Base Pass， 存储了前4个非重要的点光源的衰减因子 12345678910111213141516171819202122232425262728//计算环境光照或光照贴图uv坐标 inline half4 VertexGI(float2 uv1,float2 uv2,float3 worldPos,float3 worldNormal) { half4 ambientOrLightmapUV = 0; //如果开启光照贴图，计算光照贴图uv坐标 #ifdef LIGHTMAP_ON ambientOrLightmapUV.xy = uv1.xy * unity_LightmapST.xy + unity_LightmapST.zw; //仅对动态物体采样光照探头，UNITY_SHOULD_SAMPLE_SH代码段处理的是从light probe中读取颜色值 #elif UNITY_SHOULD_SAMPLE_SH //计算非重要的顶点光照 #ifdef VERTEXLIGHT_ON //计算4个顶点光照 ambientOrLightmapUV.rgb=Shade4PointLights(unity_4LightPosX0,unity_4LightPosY0,unity_4LightPosZ0, unity_LightColor[0],unity_LightColor[1],unity_LightColor[2],unity_LightColor[3], unity_4LightAtten0,worldPos,worldNormal); #endif //计算球谐光照 ambientOrLightmapUV.rgb += ShaSH9(half4(worldNormal,1)); #endif //如果开启了动态光照贴图，计算动态光照贴图的uv坐标 #ifdef DYNAMICLIGHTMAP_ON ambientOrLightmapUV.zw = uv2.xy * unity_DynamicLightmapST.xy + unity_DynamicLightmapST.zw; #endif return ambientOrLightmapUV; } 在片元函数，我们还需要对材质属性进行处理，转换为我们能直接使用的变量。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748half4 frag(v2f i): SV_Target { //数据准备 float3 worldPos = float3(i.TtoW0.w,i.TtoW1.w,i.TtoW2.w);//世界坐标 float3 albedo = tex2D(_MainTex,i.uv).rgb * _Color.rgb;//固有色 half2 metallicGloss = tex2D(_MetallicGlossMap,i.uv).ra;//对金属粗糙度贴图进行采样 half metallic=metallicGloss.x * _MetallicStrength;//金属度 half roughness = 1-metallicGloss.y*_GlossStrength;//粗糙度 half occlusion = tex2D(_OcclusionMap,i.uv).g;//环境光遮挡AO //计算世界空间的法线 half3 normalTangent = UnpackNormal(tex2D(_BumpMap,i.uv)); normalTangent.xy *=_BumpScale; normalTangent.z = sqrt(1-saturate(dot(normalTangent.xy,normalTangent.xy))); half3 worldNormal = normalize(half3(dot(i.TtoW0.xyz,normalTangent), dot(i.TtoW.xyz,normalTangent), dot(i.TtoW2.xyz,normalTangent))); //获取世界空间下的灯光方向，观察方向，反射方向 half3 lightDir = normalize(UnityWorldSpaceLightDir(worldPos)); half3 viewDir = normalize(UnityWorldSpaceViewDir(worldPos)); half3 refDir = reflect(-viewDir,worldNormal); half3 emission = tex2D(_EmissionMap,i.uv) * _EmissionColor;//自发光颜色 //计算BRDF需要用到的数据 half3 halfDir = normalize(lightDir + viewDir); half nv = saturate(dot(worldNormal,viewDir)); half nl = saturate(dot(worldNormal,lightDir)); half nh = saturate(dot(worldNormal,halfDir)); half lv = saturate(dot(lightDir,viewDir)); half lh = saturate(dot(lightDir,halfDir)); //计算BRDF中的漫反射率和镜面反射率，符合能量守恒 //镜面反射颜色 half3 specColor = lerp(unity_ColorSpaceDielectricSpec.rgb,albedo,metallic); //计算漫反射总比率 half OneMinusReflectivity = (1 - metallic) * unity_ColorSpaceDielectricSpec.a; //漫反射颜色 half3 diffColor = albedo * OneMinusReflectivity; //计算间接光照，包含间接漫反射和间接镜面反射 half3 indirectDiffuse = ComputeIndirectDiffuse(i.ambientOrLightmapUV,occlusion); half3 indirectSpecular = ComputeIndirectSpecular(refDir,worldPos,roughness,occlusion); } 然后我们需要计算BRDF中需要的镜面反射率，漫反射率。按照“Diffuse和Specular互斥”能量守恒，我们可以进行简单的划分diffuse和specular。 12float3 specilarTint = albedo * _Metallic;//高光反射率float3 albedo = albedo * (1-_Metallic); 但是这样简单的区分，会出现一些问题，在我们现实生活中，即使是非常光滑的物体也是很难反光的，而如果用了以上简单的区分，光滑的非金属物体将没有高光反射，这个就是需要电介质反射率需要参与计算的地方。 1234567//计算BRDF中的漫反射率和镜面反射率，符合能量守恒 //镜面镜面反射率 half3 specColor = lerp(unity_ColorSpaceDielectricSpec.rgb,albedo,metallic); //计算漫反射总比率 half OneMinusReflectivity = (1 - metallic) * unity_ColorSpaceDielectricSpec.a; //计算漫反射率 half3 diffColor = albedo * OneMinusReflectivity; unity_ColorSpaceDielectricSpec里面存的是Unity选用的电介质反射率,定义了绝缘体的高光颜色和反射率，不完全为0，是一个经验值，alpha通道是1-dielectricSpec,实际上是将Matellic的数值remap到[DielectricSpec,1]的范围，则非金属性reamp在[1-dielectricSpec,0]. 接着就计算间接光照，包含间接漫反射和间接镜面反射。 123//计算间接光照，包含间接漫反射和间接镜面反射 half3 indirectDiffuse = ComputeIndirectDiffuse(i.ambientOrLightmapUV,occlusion); half3 indirectSpecular = ComputeIndirectSpecular(refDir,worldPos,roughness,occlusion); 计算漫反射的时候，我们需要判断物体是动态物体还是静态，动态物体就是顶点函数之前计算的非重要光源，对于静态物体就直接光照贴图采样即可。 123456789101112131415161718192021222324//计算间接光漫反射 inline half3 ComputeIndirectDiffuse(half4 ambientOrLightmapUV,half occlusion); { half3 indirectDiffuse = 0; //如果是动态物体，间接光漫反射为再顶点函数中的非重要光源 #if UNITY_SHOULD_SAMPLE_SH indirectDiffuse = ambientOrLightmapUV.rgb; #endif //如果是静态物体，则采样光照贴图或动态贴图 #ifdef LIGHTMAP_ON //对光照贴图进行采样和解码 indirectDiffuse = DecodeLightmap(UNITY_SAMPLE_TEX2D(unity_Lightmap,ambientOrLightmapUV.xy)); #endif #ifdef DYNAMICLIGHTMAP_ON //对动态光照贴图进行采样和解码 indirectDiffuse += DecodeRealtimeLightmap(UNITY_SAMPLE_TEX2D(unity_DynamicLightmap,ambientOrLightmapUV.zw)); #endif //将间接光漫反射乘以环境光遮罩 return indirectDiffuse * occlusion; } 上面的代码使用了DecodeLightmap和DecodeRealtimeLightmap解码Unity内置的光照贴图，这是因为Unity烘焙的LightMap是**32BIT的HDR图，在桌面端，光照贴图的编码为RGBM,在移动端，大部分是double-LDR，因此需要针对不同平台进行解码。 接下来我们要计算的就是间接镜面反射，要处理两个反射探头（Reflection Probe），要对反射探头的反射方向进行重新映射和采样。 123456789101112131415161718192021222324252627//计算间接光镜面反射 inline half3 ComputeIndirectSpecular(half3 refDir,float3 worldPos,half roughness,half occlusion) { half3 specular = 0 ; //重新映射第一个反射探头的采样方向 half3 refDir1 = BoxProjectedDirection(refDir,worldPos,unity_SpecCube0_ProbePosition,unity_SpecCube0_BoxMin,unity_SpecCube0_BoxMax); //对第一个反射探头进行采样 half3 ref1 = SamplerReflectProbe(UNITY_PASS_TEXCUBE(unity_SpecCube0),refDir1,roughness,unity_SpecCube0_HDR); //如果第一个反射探头的权重小于1，我们将采样第二个反射探头，进行混合 //下面if语句产生分支，定义再HLSLSupport.cginc UNITY_BRANCH if(unity_SpecCube0_BoxMin.w &lt; 0.999999) { //重新映射第二个反射探头的方向 half3 refDir2 = BoxProjectedDirection(refDir,worldPos,unity_SpecCube1_ProbePosition,unity_SpecCube1_BoxMin,unity_SpecCube1_BoxMax); //对第二个反射探头进行采样 half3 ref2 = SamplerReflectProbe(UNITY_PASS_TEXCUBE_SAMPLER(unity_SpecCube1,unity_SpecCube0),refDir2,roughness,unity_SpecCube1_HDR); //进行混合 specular =lerp(ref2,ref1,unity_SpecCube0_BoxMin.w); } else { specular = ref1; } return specular * occlusion; } 使用UNITY_PASS_TEXCUBE_SAMPLER宏将第二个反射探测器针的纹理与我们唯一的采样器相结合。 这里需要解释的是为什么重新映射反射方向。CubeMap正常来说是不考虑物体与被反射物体的距离的，如果反射的物体距离被反射的物体很远时，反射效果比较好。 但是当距离比较近的时候，反射会有点奇怪。 这就需要Box Projection Cube Map的技术，通过重新修正反射采样方向。 反射时，我们采样Reflection Probe时的向量对应的起点是Reflection Probe的中心点R，方向是在当前像素点计算的视线方向对应法线方向的反射向量PK。 ABCD是Reflection Probe对应的Cube，P为当前像素点，E为相机位置，N是法线方向，PK是反射方向，如果按照PK方向采样Reflection Probe，得到的就是错误的采样方向RL，所以需要真正的采样方向RK。 其实就是求RK向量即可。首先K是Cube包围盒上的点，所以第一步我们要求得包围盒边界得坐标值才能计算出K点，Unity在unity_SpecCube0_BoxMin，unity_SpecCube0_BoxMax这两个内置的shader uniform变量中为我们存储了包围盒的BoundingBox最大最小值。 如何做向量和Box的碰撞检测？ 从起点A出发，沿着d方向，检测碰撞。根据d的方向，我们只需要考虑MaxX边界以及MaxZ边界的碰撞，产生碰撞点B和D。 用方程表示，假设沿着单位d方向经过t0距离后，遇到点B。假设沿着单位d方向经过t1距离后，遇到点D。则得A + t0 * d = B A + t1 * d = D B.x = Max X D.z = Max Z。在方程中A，d，Max X Max Z都是已知量，所以可以求出t0和t1,很明显我们要得到的碰撞点是B点碰撞，我们需要的碰撞点是t = min(t0, t1)。 总结：从起点出发，沿着方向前进，发生碰撞的时候，经过的距离最短的点就是我们要的点。 如何得知碰撞边界通过上面二维空间，可以得知两个潜在的碰撞边界Max X 与Max Z，那么如果方向变为任意方向该如何处理？ 可以考虑各个轴向，比如，当方向的x分量大于0时，即d.x &gt; 0 时，我们关心Max X 当方向的x分量小于0时，即d.x &lt; 0 时，我们关心Min X。Y轴和Z轴也是如此。 1float3 collisionEdge = (d &gt; 0.0f) ? boxMax : boxMin; collisionEdge 中存储了三个轴向上我们关心的边界。 确定了碰撞边界后如何计算碰撞点在三位空间中我们有三个碰撞边界，因此有三个潜在的碰撞点。 可以列出方程 A.x + d.x * tx = collisionEdge.x A.y + d.y * ty = collisionEdge.y A.z + d.z * tz = collisionEdge.z 可以求得三个量tx，ty，tz，分别是三个边界碰撞要经过的距离。根据上面我们得知，最小的t就是我们需要的t,将向量整合后得到 123float3 t = (collisonEdge - worldPosition) / d;float collisionDist = min(t.x, min(t.y, t.z));float3 collisionDir = d * collisionDist; 整合得到1234567891011121314151617inline half3 BoxProjectedDirection(half3 worldRefDir,float3 worldPos,float4 cubemapCenter,float4 boxMin,float4 boxMax) { UNITY_BRANCH if(cubemapCenter.w &gt; 0.0)//如果反射探头开启了BoxProjection选项，cubemapCenter.w&gt;0 { half3 rbmax = (boxMax.xyz - worldPos) / worldRefDir; half3 rbmin = (boxMin.xyz - worldPos) / worldRefDir; half3 rbminmax = (worldRefDir &gt; 0.0f) ? rbmax :rbmin; half fa = min(min(rbminmax.x,rbminmax,y),rbminmax.z); worldPos -= cubemapCenter.xyz; worldRefDir = worldPos + worldRefDir *fa; } return worldRefDir; } 对反射探头进行采样在反射探头中存储的是一组图像，内容逐渐模糊，是因为当我们看到比较粗糙的物体时，反射的内容也是比较模糊的，但是实时模糊是比较昂贵的，所以unity是烘焙成一组图像mipmap，随着不同等级进行采样，级数越高越模糊，6是总级数。 123456789inline half3 SamplerReflectProbe(UNITY_ARGS_TEXCUBE(tex),half3 refDir,half roughness,half4 hdr) { roughness = roughness * (1.7 - 0.7 * roughness); half mip = roughness * 6; //采样 half4 rgbm = UNITY_SAMPLE_TEXCUBE_LOD(tex,refDir,mip); //采样后的结果包含HDR，我们需要把结果转换到RGB return DecodeHDR(rgbm,hdr); } 因为物体的粗糙度和反射图像的清晰度不是线性关系，所以有第一个公式，主要为了节省性能。 上面我们只是计算了间接光的直接颜色，我们还要将IBL的BRDF计算过程做了预计算，放入了LUT查找图里 12vec2 envBRDF = texture2D(BRDFIntegrationMap, vec2(NdotV, roughness)).xy;vec3 indirectSpecular = prefilteredColor * (F * envBRDF.x + envBRDF.y) 用NdotV，roughness作为参数就可以直接从图中获得计算结果，并得到处理了视角和高光的最终颜色值。虽然纹理随机采样会导致cache miss，但毕竟节约了大量的计算。 注意这个LUT是虚幻和OpenGL的实现，实际上Unity用的是另一套东西 1surfaceReduction * gi.specular * FresnelLerp (specColor, grazingTerm, nv); 注意到Unity用的是一个叫surfaceReduction的系数，以及一个在F0（specColor就是我们的F0）和grazingTerm之间进行插值的菲涅尔系数。纹理采样的开销远大于计算这几个参数的开销，也就是说Unity这个做法通常而言比采样LUT要来的快。当然我也不知道这怎么来的。 12345678910111213//计算掠射角时反射率half grazingTerm = saturate((1 - roughness) + (1-oneMinusReflectivity));//计算间接光镜面反射indirectSpecular *= ComputeFresnelLerp(specColor,grazingTerm,nv);//计算间接光漫反射indirectDiffuse *= diffColor;//计算间接光镜面反射菲涅尔项inline half3 ComputeFresnelLerp(half3 c0,half3 c1,half cosA){ half t = pow(1 - cosA,5); return lerp(c0,c1,t);} 间接光终于算完了，就剩下我们的直接光照了，只要把上面的公式往上带就好了。 首先我们先计算BRDF的镜面反射 12345half V = ComputeSmithJointGGXVisibilityTerm(nl,nv,roughness);//计算BRDF高光反射项，可见性Vhalf D = ComputeGGXTerm(nh,roughness);//计算BRDF高光反射项,法线分布函数Dhalf3 F = ComputeFresnelTerm(specColor,lh);//计算BRDF高光反射项，菲涅尔项Fhalf3 specularTerm = V * D * F;//计算镜面反射项 V这一项被称为可见性项，是阴影遮掩函数G除以BRDF镜面反射分母(n·l)(n·v)部分，在这里为了方便我们也把系数4也加了进去。我们会在分母的后面加上1e-5f,来防止分母为0 1234567891011121314151617181920212223//计算Smith-Joint阴影遮掩函数，返回的是除以镜面反射项分母的可见性项Vinline half ComputeSmithJointGGXVisibilityTerm(half nl,half nv,half roughness){ half ag = roughness * roughness; half lambdaV = nl * (nv * (1 - ag) + ag); half lambdaL = nv * (nl * (1 - ag) + ag); return 0.5f/(lambdaV + lambdaL + 1e-5f);}//计算法线分布函数inline half ComputeGGXTerm(half nh,half roughness){ half a = roughness * roughness; half a2 = a * a; half d = (a2 - 1.0f) * nh * nh + 1.0f; //UNITY_INV_PI定义在UnityCG.cginc 为1/π return a2 * UNITY_INV_PI / (d * d + 1e-5f);}//计算菲涅尔inline half3 ComputeFresnelTerm(half3 F0,half cosA){ return F0 + (1 - F0) * pow(1 - cosA, 5);} 然后就是BRDF漫反射部分 1half3 diffuseTerm = ComputeDisneyDiffuseTerm(nv,nl,lh,roughness,diffColor);//计算漫反射项 123456//计算漫反射项inline half3 ComputeDisneyDiffuseTerm(half nv,half nl,half lh,half roughness,half3 baseColor){ half Fd90 = 0.5f + 2 * roughness * lh * lh; return baseColor * UNITY_INV_PI * (1 + (Fd90 - 1) * pow(1-nl,5)) * (1 + (Fd90 - 1) * pow(1-nv,5));} 终于全部都计算完毕了，直接加起来就好了。 123456//计算最后的颜色half3 color = UNITY_PI * (diffuseTerm + specularTerm) * _LightColor0.rgb * nl * atten + indirectDiffuse + indirectSpecular + emission;//设置雾效,定义在UnityCG.cgincUNITY_APPLY_FOG(i.fogCoord, color.rgb); 总结其实PBR公式那么复杂，可以简单归纳为 然后又分为直接光照，间接光照，自发光，那么什么辐射度，就是为了告诉你这是基于物理的渲染，不用深究，虽然我感觉我就是在囫囵吞枣。终于把这个难啃的骨头啃了，虽然我觉得不久之后我又会忘记哈哈哈。","link":"/2020/08/23/Unity-PBR%E5%AE%9E%E7%8E%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Unity PBR学习笔记（1）","text":"前言在知乎看到大佬的翻译文章，通过Unity学习PBR算法，在这里做一下笔记。 什么是PBR(基于物理渲染)PBR是指基于物理的渲染((Physically Based Rendering)，指在不同程度上都基于与现实世界物理原理更相符的渲染技术集合，使用了一种更符合物理学规律的方式来模拟光线，所以和phong或者Blinn-Phong光照模型更加真实。 判断PBR光照模型是否基于物理PBR模型只是对现实世界的一种近似，所以它是基于物理的着色而非物理着色，判断一种PBR光照模型是否基于物理，必须满足一下三个条件： 1.基于微平面的表面模型 2.能量守恒 3.应用于基于物理的BRDF(双向反射分布函数) 微平面模型当光纤照在一个绝对平滑的表面，它回一个完美的轨迹反射出去，但光照射到粗糙平面。它将无法以相似的方式反射出去。这就是微平面。 可以看出，一个平面越是粗糙，微平面排列越是混乱，入射光线更趋向于向完全不同的方向发散开来，进而产生更广泛的镜面反射。与之相反的是，对于一个光滑的平面，光纤大体回更趋向于同一个方向反射，造成更小更锐利的反射。 在微观尺度，没有任何平面是完全光滑的。然而由于微平面已经微小到无法逐像素进行区分，所以我们只有假设一个粗糙度(Roughness)参数，来粗略估算微平面的粗糙程度。 较高的粗糙度值显示出来的镜面反射的轮廓要更大一些。与之相反地，较小的粗糙值显示出的镜面反射轮廓则更小更锐利。 能量守恒微平面使用了能量守恒(Energy Conservation)，出射光线的能量永远不能超过入射光线的能量（发光面除外）。如图示我们可以看到，随着粗糙度的上升镜面反射区域的会增加，但是镜面反射的亮度却会下降。如果不管反射轮廓的大小而让每个像素的镜面反射强度(Specular Intensity)都一样的话，那么粗糙的平面就会放射出过多的能量，而这样就违背了能量守恒定律。 ​ 为了遵守能量守恒定律，我们需要对漫反射光和镜面反射光进行区分，当一束光线碰撞到一个表面时，会分成折射部分和反射部分。反射部分：直接反射而不会进入平面的部分光线，这就是镜面反射。折射部分：余下的会进入表面并被吸收的部分光线，这就是漫反射光线。 次表面反射一般来说，并非所有能量都会被全部吸收，光线也会沿着随机的方向发散，然后而其他粒子碰撞直到能量完全耗尽或者再次离开表面，而光线脱离物体表面后将会协同构成该表面的（漫反射）颜色。但是在基于物理的渲染中进行了简化，折射光全部会被完全吸收而不会散开。 但是次表面散射(Subsurface Scattering)把这个问题考虑进去，显著提升了皮肤，大理石等视觉效果，有一种晶莹剔透的感觉。 金属表面对于金属表面，遵从反射与折射原理，但是所有的折射光都会被直接吸收而不会散开，只留下发射光，也就是说，金属表面不会显示出漫反射颜色。 结论我们可以知道反射光和折射光两者的关系是互斥的。无论哪种光线，被气材质表面所反射的能量将无法再被材质吸收。因此，折射光余下进入表面的能量正好是计算完发射之后剩下的能量。 12float kS = calculateSpecularComponent(...); // 反射/镜面 部分float kD = 1.0 - ks; // 折射/漫反射 部分 这样就遵循了能量守恒定律，反射和折射加起来的总份额就不会超过1.0。 反射率方程反射率方程是某些大佬自己想出来的绝妙方程，是用来模拟光照视觉效果的最好模型。 辐射通量辐射通量表示一个光源所输出的能量，以瓦特为单位。光是由多种不同波长的能量所集合而成，每种波长与一种特定的可见的颜色相关。所以一个光源所输出的能量可以被视作为这个光源包含的所有波长的一个函数。 辐射通量$\\Phi$将会计算这个不同波长构成的函数的总面积。但是将这个计量输入有点不切实际，所以我们不直接使用波长的强度而是使用RGB作为辐射通量的简化。所以RGB可以表示光的颜色。 立体角立体角用ω表示，投射到单位球体上的一个截面的大小或者面积，是一个带有体积的方向。 辐射强度辐射强度表示一个光源向每单位立体角所投送的辐射通量。 计算辐射强度的公式如下 其实$I$表示辐射通量$\\Phi$除以立体角$\\omega$。 辐射率方程表示一个拥有辐射强度的光源在单位面积或单位立体角上辐射的总能量。这个方程表示，一个拥有辐射强度$\\Phi$的光源在单位面积$A$，单位立体角$\\omega$上辐射出的总能量： 辐射率是辐射度量学上表示一个区域平面上光线总量的物理量。它受到入射光线和平面法线的夹角的余弦值影响：与我们的漫反射光照的概念相似，其实就是**光线的方向向量和平面法向量的点积。 1float cosTheta = dot(lightDir,N); 其中辐射率方程原本为 dA⊥ 是dA投影在一个假想的垂直于w的平面，dA 要乘上cos theta后才是真正垂直的投影面积。 如果我们把立体角$\\omega$和面积$A$看做是无穷小的，那么我们就能用辐射率表示单束光线通过空间的一个点的通量。我们实际上将立体角$\\omega$转变为方向向量$\\omega$然后把面$A$转换为点$p$，这样就能在着色器中使用辐射率来计算单束光线对每个片段的作用。 事实上，我们通常关心的是所有投射到点P上的光线总和，这个和就为辐射照度或者辐照度。 现在回过头来看反射率方程： 在渲染方程中L代表通过某个无限小的立体角$$\\omega_i$$在某个点上的辐射率，而立体角可以视作为入射方向向量$$\\omega_i$$，注意我们利用光线和平面间的入射角的的余弦值$$ \\cos{\\theta} $$来计算能量，则是$$n * \\omega_i$$ **。用$$\\omega_o$$表示观察方向，也就是出射方向，反射率公式计算了点$P$在$$\\omega_o$$方向上被反射出来的辐射率$$L_o(p,\\omega_o)$$的总和。也就是说$$L_o$$表示从$$w_o$$方向上观察，光线投射到点$p$上反射出来的辐照度**。 基于反射率公式是围绕所有入射辐射率的总和，也就是辐照度来计算，所以需要计算的不只是单一方向的入射光，而是一个以点$p$为半球领域$\\Omega$内所有方向的入射光。 为了计算半球领域$\\Omega$，就需要用到积分，简单来说就是在半球领域$\\Omega$中按一定的步长将反射率方程分散求解，然后再按照步长大小将所得到的结果平均化。（Riemann sum方法） 1234567891011int steps = 100;float sum = 0.0f;vec3 P = ...;vec3 Wo = ...;vec3 N = ...;float dW = 1.0f / steps;for(int i = 0; i &lt; steps; ++i) { vec3 Wi = getNextIncomingLightDir(i); sum += Fr(p, Wi, Wo) * L(p, Wi) * dot(N, Wi) * dW;} 这里利用dw所有的离散部分进行缩放，和最后就等于积分函数的总面积，我们可以通过增加离散部分的数量来提高准确度。 总结反射率方程概括了在半球领域$\\Omega$内，碰撞到点$p$上所有入射方向$$w_i$$上的光线辐射率，并且受到$$f_r$$的约束，然后返回观察方向上反射光的$$L_o$$。入射光辐射率可以从光源获取，也可以用环境贴图来计算所有入射方向上的辐射率。 现在剩下的未知符号就是$$f_r$$，它就是BDRF(双向反射分布函数)，作用就是**基于表面材质属性对入射辐射率进行缩放或者加权。 BRDFBRDF接受入射光方向$$w_i$$，出射观察方向$$w_o$$，平面法线$$n$$和表示微平面粗糙程度的参数$$a$$作为函数的输入参数。BRDF可以近似求出每束光线对于一个给点了材质属性的平面最终反射出来光线所作的贡献程度。如，如果有一个完全光滑的表面（比如镜面），那么只有一束与出射光线$$w_o$$拥有相同角度的光线会得到1.0返回值，其余都是0。 几乎所有实时渲染管线使用的都是一种被称为Cook-Torrance BRDF模型。 Cook-Torrance BRDF兼有漫反射和镜面反射两个部分： $$k_d$$这里指的是被折射部分所占的比率，而$$k_s$$是被反射部分的比率，BRDF左侧表示漫反射，指$$f_{lambert}$$，被称为Lambertian漫反射，公式为： $$c$$表示表面颜色，处以$$\\pi$$是为了对漫反射光进行标准化，因为反射率积分方程受$$\\pi$$影响。 Lambertian漫反射与其他漫反射的关系之前们使用表面法向量与光照方向向量进行点成，然后将结果与表面颜色相乘得到漫反射参数，点乘依然还在，但不在BRDF中，而是转换为$$L_o$$积分公式的$$n*w_i$$。 Cook-Torrance BRDF的镜面反射部分 镜面部分包含三个函数，此外分母部分还有一个标准化因子。$$D$$表示法线分布函数(Normal Distribution Function)，菲涅尔方程(Fresnel Rquation)，几何函数(Geometry Function)。 D使用Trowbridge-Reitz GGX，F使用Fresnel-Schlick近似(Fresnel-Schlick Approximation)，而G使用Smith’s Schlick-GGX。 法线分布函数从统计学上近似的表示与中间向量$$h$$取向一致的微平面比率。举例，假设给定向量$$h$$,微平面中有35%与向量$$h$$取向一致，那么发现分布函数会返回0.35。公式如下： $$n$$表示微平面的法向量，$$h$$表示用来与法向量做比较的中间向量，$$a$$表示表面粗糙度。 不同粗糙度下，效果也不一样。 这里使用的GLSL编写法线分布函数 123456789101112float D_GGX_TR(vec3 N, vec3 H, float a){ float a2 = a*a; float NdotH = max(dot(N, H), 0.0); float NdotH2 = NdotH*NdotH; float nom = a2; float denom = (NdotH2 * (a2 - 1.0) + 1.0); denom = PI * denom * denom; return nom / denom;} 几何函数几何函数求得了微平面相互遮蔽的比率，相互遮蔽户会损耗光线能量。 几何函数采用材质的粗糙度$$a$$作为输入参数，**粗糙度越高的表面相互遮蔽的概率就越高。Schlick-GGX公式如下： $$k$$是$$a$$基于几何函数是针对直接光照还是针对IBL光照的重映射(Remapping): 我们还需要将几何遮蔽(Geometry Obstruction)和几何阴影(Geometry Shadowing)）都考虑进去。使用史密斯法将两者都纳入其中。 不同粗糙度，效果如下 GLSL编写的几何函数如下： 1234567891011121314151617float GeometrySchlickGGX(float NdotV, float k){ float nom = NdotV; float denom = NdotV * (1.0 - k) + k; return nom / denom;}float GeometrySmith(vec3 N, vec3 V, vec3 L, float k){ float NdotV = max(dot(N, V), 0.0); float NdotL = max(dot(N, L), 0.0); float ggx1 = GeometrySchlickGGX(NdotV, k); float ggx2 = GeometrySchlickGGX(NdotL, k); return ggx1 * ggx2;} 菲涅尔方程此方程表示的是被反射的光线对比被折射光线的所占比率，比率会随着我们观察角度不同而不同。 菲涅尔方程可以用Fresnel-Schlick近似法求得近似解： $$F_o$$是平面的基础反射率，当我们的视线和表面法线的夹角接近90度，菲涅尔现象就越明显，反光越强： 注意Fresnel-Schlick仅仅对非金属表面有定义。对于金属，使用折射指数计算基础折射率不能得到正确结果。所以我们要预先处理$$F_0$$，对于金属来说，基础反射率一般是带有颜色的，所以$$F_0$$要用RGB表示，这种现象只能在金属表面观察到，而对于非金属表面，由于$$F_0$$值较小，即使乘了表面颜色也影响不大。 所以我么还需要一个金属度(Metalness)参数作为输入参数，金属度用来描述一个材质表面时金属的还是非金属的。 如果是金属表面的话，我们就需要对基础反射率添加色彩，这里用了线性插值 12vec3 F0 = vec3(0.04);F0 = mix(F0, surfaceColor.rgb, metalness); Fresnel Schlick近似可以用代码表示为： 1234vec3 fresnelSchlick(float cosTheta, vec3 F0){ return F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);} 其中cosTheta是表面法向量n与观察方向v的点乘的结果。 间接光PBR并不是只有直接光照，PBR还有间接光照，这一部分由IBL(Image-Based-Light)实现，原理就是Cubemap(环境贴图)。 间接光的总公式如下，使用的也是和直接光相同的BRDF方程，但是与直接光不同的是，直接光可以按步长进行拆分，最后加起来平均，间接光是真的要解积分。 其实就是分为了两部分，间接光漫反射和间接光高光反射。 间接光漫反射可以从上面的公式看出这是个半球积分，不可能采样整个半球的数据，再算一次BRDF。所以我们会直接把计算结果存在CubeMap里面，我们直接采样CubeMap获得光照数据，最后代入PBR公式算出结果即可。 间接光漫反射不用太复杂，直接弄出一张很模糊的环境图,再采样得到颜色值即可。 间接光高光反射高光部分有粗糙度$$a$$参数，所以我们必须要烘焙出多个粗糙度下的环境贴图，主要是模糊程度不同，生成下图： 然后合并到一张cubemap的多个mipMap层级上，再利用cubeTexLod函数，根据粗糙度选择特定层级的两个mipMap层级进行三线插值，就能近似得到需要半球积分过的光照颜色值。 12float lod = getMipLevelFromRoughness(roughness);vec3 prefilteredColor = textureCubeLod(PrefilteredEnvMap, refVec, lod); UnityStander工作流金属工作流Albedo：非金属表示颜色贴图，金属表示基础反射率(base reflectivity)。跟diffuse贴图的区别是，albedo贴图不应该包含局部阴影信息（交给AO贴图），而只包含纯颜色信息（或折射吸收系数） Normal：普通法线贴图。 Metallic：金属度贴图，每个像素的金属度，可以使0或1，或者0-1之间的灰度值。从概念上来说金属度应该是一个0或1的二元值，要么是金属要么是非金属，但将金属度设置为0-1之间的灰度值可以让美术做出一些其他比较好的效果，比如金属上的划痕之类的。 Roughness：粗糙度贴图，像素的roughness表示其微平面朝向的一致性，越粗糙越凌乱，反射光线区域大且模糊，反之则集中且清晰。有的引擎会使用smoothness光弧度贴图，这样在美术上可能更直观，smoothness = 1 - roughtness。 AO：环境光遮蔽贴图，ambient occusion，局部阴影信息，AO贴图可以明显地提升渲染效果。AO贴图要么手动生成，要么在3D建模时就计算好。 高光反射工作流Albedo：控制了漫反射颜色。 Specular：控制了高光反射的颜色。 举个例子：对于金属材质，我们的Albedo应该是全黑的，应该金属材质几乎不存在此表面散射的现象。 各自的优点和缺点1， Specular Workflow 工作流: 1234561.1 优点 1. Diffusion 和reflectance有分别的明确的输入，这对于有传统shader贴图绘制工作的美术更可取。 2. 提供一个完整的色彩输入，能更好地控制非金属的反射值（实际上不用区分金属非金属，按材质取值）。 1.2 缺点 1.容易对reflectance赋予错误的值，造成错误的结果,因为容易违反能量守恒原则。 2.占用更多的存储空间。 2, Metalness 12345678 2.1 缺点 1.金属非金属过度区域有白边。2.对于非金属的反射值缺乏控制和表现。3.如果不理解工作流，容易为metalness map 错误复制，造成错误结果。 2.2 优点 1.Albedo Map 就是物体的固有色，完全不用去区分到底是什么材质，需要处理好。2.简单底将材质分为金属和非金属两类，但也可能对于非现实材质（比如卡通）的表现造成困难。3.占用更少的存储空间。","link":"/2020/08/23/Unity-PBR%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/"},{"title":"Unity VEG实现烟花效果","text":"前言这次利用VEG实现普通烟花效果。 主粒子 设置主粒子的速度，位置，周期等参数。 Position(Line)用于设置粒子的初始化位置，从Start到End随机生成一个位置点。 烟花粒子 这里利用GPU Event当主粒子消亡时生成新的眼花粒子。 GPU Event GPU事件由系统在特定条件下触发，并且可以被其他系统捕获以生成新粒子。 可以通过读取Source或使用Inherit Source节点在子系统中访问事件数据。 主粒子的拖尾粒子 烟花粒子的拖尾 就这样我们的烟花就完成啦 现在看起来还是有点难看的，但问题不大，给它加点后处理就好了，PostProcessVolume 就这样，好看多了 未完待续可能后面还想加点其他的功能，所以未完待续。","link":"/2020/08/23/Unity-VEG%E5%AE%9E%E7%8E%B0%E7%83%9F%E8%8A%B1%E6%95%88%E6%9E%9C/"},{"title":"Unity Visual Effect Graph初探","text":"前言最近为了实现动画课程设计的烟花效果，所以要学习一下Unity的新特效工具Visual Effect Graph，特此记录学习的过程，避免以后会忘记。 注意 目前Visual Effect Graph只能在HDRP中使用，也就是说必须使用Unity2018.3以上的版本。 为什么要使用VEF我们已经有传统的Particle System系统，那为什么要用VEF呢？ 其实VEF能比传统的Particle System能做出更加复杂酷炫的特效，具体可以查看Unity的官方文档。而且我们认为VEF还有一个更加巨大有点就是可视化，我刚开始接触Particle System的时候，看到这么多参数，头都晕了….这次VEF的工作流非常的清楚。 VEF的工作流关于VEF的安装和配置就不说了，官方文档有详细的讲解。 首先我们来看一下VEF的画面，可以看出和shader Graph非常的相似。 VEF默认模板由4个流程构成(VEF称为Context)，包含着多个Block，整个VEF工作流抽象成4个部分 Spawn负责生成粒子，右键点击添加的Block都是与粒子生成相关。 Initialize初始化模块，负责初始化粒子的属性，如初始速度，生命周期。 Update每帧对粒子的参数进行更新，比如重力，移动速度，坐标等。 Output主要负责粒子的渲染，如颜色，形状等。 注意每个Context连接并不是唯一，比如一个Spawn可连接多个Initialize，朝多个方向发射 VEF的使用小测试VEF的小测试，以粒子的初始速度为基准设置粒子的颜色 实现以原点为圆心，半径为1，圆以内的呈绿色，圆以外的呈紫色。 也可添加Get Attribute：Color结点获取粒子原本的颜色，达到新效果。 Point Cache bake tool(点阵缓存烘焙器)这个是VEG添加的新工具，它的作用是把一张图或者Mesh的信息，烘焙成一张点阵图，然后再VEG中使用，可烘焙的信息有颜色，法线，位置，UV信息等。 首先点开烘焙工具，烘焙工具在上方Window—Visual Effects—Utilities—Point Cache bake tool,选择要烘焙的网格和信息，这里我选择胶囊体作为测试。 在VEG中使用以下两个节点，即可得到一个粒子形成的胶囊体 Vector Field Force(矢量场力)官方文档解释：矢量场力施加从包含矢量数据的3D纹理中获取的力。我也不是很明白，以后有机会再研究。通过结合矢量场力和Point Cache我们可以实现粒子物体爆掉的感觉。 VFX Binder脚本，参数与事件的绑定为了在游戏运行时根据游戏内的逻辑来实时动态改变VEG，我们可以用VFX Binder绑定脚本。 参数绑定首先，我们为VFX添加VFX Parameter binder脚本 在Hierarchy面板新建一个Cube，这个Cube用于传递位置参数进VEG，实时更新粒子喷发的位置。 进入VEG在参数面板新建一个Vector3用于存储Cube的位置参数，并传递给粒子。 事件绑定在VEG里事件作为一个单独的Context，不能附加任何的Block并且只能和Spawn相连，作用是管理Spawn的发射开关。 现在做鼠标点击位置生成粒子效果 首先新建一个Plane作为脚本的载体，并且绑定VFX Mouse Event Blinder事件,拖入新建的VFX 双击VEX，新建一个Event，注意名字要和脚本上的EventName要一致。 注意Location为Source的Attribute只能用在Initializes中的Block上 最后我们就能实现鼠标点击位置生成粒子的效果了。 感受第一次尝试这样做笔记，比较痛苦，但成就感也是满满的。","link":"/2020/08/23/Unity-Visual-Effect-Graph%E5%88%9D%E6%8E%A2/"},{"title":"Unity3D卡通风格地编","text":"Unity地形工具Terrain增加地块工具，可以通过点击来增加地块 地形笔刷工具 设置地形高度 首先设置总体地形最高高度，然后利用Ctrl + 鼠标左键 来控制想要绘制的地形高度，这样就可以达到高低不一致的效果 平滑高度","link":"/2020/08/23/Unity3D%E5%8D%A1%E9%80%9A%E9%A3%8E%E6%A0%BC%E5%9C%B0%E7%BC%96/"},{"title":"Unity实现米哈游的Mesh变换转场效果","text":"前言之前看过米哈游大佬制作的桃源恋歌MMD，被其中的Mesh变换转场效果所折服了，所以自己想模仿着实现这个效果，幸好kerjiro技术美术大神开源了这方面的视觉特效项目，感觉自己如果想成为TA还有好长的路要走。。。 最终效果首先让我们来看一下最终效果 实现思路其实这个效果是通过几何着色器来实现的，主要思路就是通过几何着色器对三角面片的顶点进行添加，构成一个Cube。 几何着色器相信大家接触的最多的应该是顶点着色器和像素着色器，那么什么是几何着色器呢？ 定义在顶点和片段着色器之间有一个可选的着色器，叫做几何着色器(Geometry Shader)。几何着色器以一个或多个表示为一个单独基本图形（primitive）即图元的顶点作为输入，比如可以是一个点或者三角形。几何着色器在将这些顶点发送到下一个着色阶段之前，可以将这些顶点转变为它认为合适的内容。几何着色器有意思的地方在于它可以把（一个或多个）顶点转变为完全不同的基本图形（primitive），从而生成比原来多得多的顶点。 使用几何着色器进行图元转换声明着色器 1#pragma geometry geom 设置输出顶点数量，其中N为几何着色器为单个调用输出的顶点最大数量，几何着色器每次输出的顶点数量是可变的，但是不能超过定义的最大值， 出于性能考虑，最大顶点数应尽可能小; 当GS输出在1到20个标量之间时，可以实现GS的性能峰值，如果GS输出在27-40个标量之间，则性能下降50％。每次调用的标量输出数是最大顶点输出数和输出顶点类型结构中的标量数的乘积。 1[maxvertexcount(N)] 声明输入和输出的Struct 1234567891011121314151617//传递给几何着色器的数据struct v2g{ float4 vertex:POSITION; float3 normal:TEXCOORD0; //float2 uv:TEXCOORD1; };//传递给像素着色器的数据struct g2f{ float4 pos : SV_POSITION; float3 normal:TEXCOORD0; //float2 uv : TEXCOORD1; float4 color:COLOR;}; 设置几何着色器输入参数和输出参数， 其中“triangle”为输入的图元类型， 输入参数一定为顶点数组 。 1234567输入图元类型 | 所需顶点数 -|-point | 输入1个点的1个顶点line | 输入1条直线的2个顶点 lineadj | 输入1条具有邻接(lists或strips)的线段的4个顶点 triangle | 输入1个三角形的3个顶点triangleadj | 输入1个具有邻接(lists或strips)的三角形的6个顶点 TriangleStream为流类型(stream type)对象，还有 LineStream 和 PointStream ,存储着由几何着色器输出的几何体顶点列表。内置Append用于向输出流添加顶点序列， 若想扩展输入的图元，也可以用内置Append向输出流添加多出来的顶点。 当指定uint primID:SV_PrimitiveID时，输入汇编阶段会为每个图元自动生成一个图元ID。当调用draw方法绘制n个图元时，ID号为0到n-1，这里用到的原因是为了随机Cube化。 1234void geom(triangle v2g input[3], uint pid : SV_PrimitiveID, inout TriangleStream&lt;g2f&gt; outStream){ //shader body} 将输出顶点传送至输出stream上 1OutputStream.Append(o); 开始动手CPU传递数据给Shader首先我们需要新建一个脚本用于传递数据给Shader，以下就是K神的传递脚本，我已经写好注释。挂在一个空物体上面即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181using System.Collections;using System.Collections.Generic;using UnityEngine;//在编辑器模式下也可运行[ExecuteInEditMode]public class Voxelizer : MonoBehaviour{ //SerializeField用于面板上显示非Public的参数 //Range(0,1)控制可滑选的范围 //控制生成方块的密度 [SerializeField, Range(0, 1)] float _density = 0.05f; //控制生成方块的大小 [SerializeField, Range(0, 10)] float _scale = 3; //动画参数 //用于控制方块变形后的长度 [SerializeField, Range(0, 20)] float _stretch = 5; //用于控制方块变形后上升的最大距离 [SerializeField, Range(0, 1000)] float _fallDistance = 1; //用于控制方块变形后的随机移动范围 [SerializeField, Range(0, 10)] float _fluctuation = 1; //颜色参数 [SerializeField, ColorUsage(false, true)] Color _emissionColor1 = Color.black; [SerializeField, ColorUsage(false, true)] Color _emissionColor2 = Color.black; [SerializeField, ColorUsage(false, true)] Color _transitionColor = Color.white; [SerializeField, ColorUsage(false, true)] Color _lineColor = Color.white; //用于Mesh变换物体的Renderer [SerializeField] Renderer[] _renderers = null; //效果平面的位置与距离 Vector4 EffectorPlane { get { //获取向前的方向 var fwd = transform.forward / transform.localScale.z; //获取向前方向上的移动距离 var dist = Vector3.Dot(fwd, transform.position); return new Vector4(fwd.x, fwd.y, fwd.z, dist); } } //将RGB颜色模型转为HSV颜色模型 Vector4 ColorToHsvm(Color color) { //获取颜色的分量最大值 var max = color.maxColorComponent; float h, s, v; Color.RGBToHSV(color / max, out h, out s, out v); return new Vector4(h, s, v, max); } //获取着色器属性的唯一标识符 //优点：使用属性标识符比将字符串传递给所有材料属性函数更有效。 //例如，如果您经常调用Material.SetColor或使用MaterialPropertyBlock， //则最好只获取一次所需属性的标识符。 static class ShaderIDs { public static readonly int VoxelParams = Shader.PropertyToID(&quot;_VoxelParams&quot;); public static readonly int AnimParams = Shader.PropertyToID(&quot;_AnimParams&quot;); public static readonly int EmissionHsvm1 = Shader.PropertyToID(&quot;_EmissionHsvm1&quot;); public static readonly int EmissionHsvm2 = Shader.PropertyToID(&quot;_EmissionHsvm2&quot;); public static readonly int TransitionColor = Shader.PropertyToID(&quot;_TransitionColor&quot;); public static readonly int LineColor = Shader.PropertyToID(&quot;_LineColor&quot;); public static readonly int EffectorPlane = Shader.PropertyToID(&quot;_EffectorPlane&quot;); public static readonly int PrevEffectorPlane = Shader.PropertyToID(&quot;_PrevEffectorPlane&quot;); public static readonly int LocalTime = Shader.PropertyToID(&quot;_LocalTime&quot;); } //在要使用相同材质但属性稍有不同的多个对象绘制的情况下使用MaterialPropertyBlock。 MaterialPropertyBlock _sheet; Vector4 _prevEffectorPlane = Vector3.one * 1e+5f; private void LateUpdate() { //查看渲染列表是否为空 if (_renderers == null || _renderers.Length == 0) return; //创建新的MaterialPropertyBlock if (_sheet == null) _sheet = new MaterialPropertyBlock(); var plane = EffectorPlane; // Filter out large deltas. //过滤掉大的三角面片 if ((_prevEffectorPlane - plane).magnitude &gt; 100) _prevEffectorPlane = plane; //存储参数 var vparams = new Vector2(_density, _scale); var aparams = new Vector3(_stretch, _fallDistance, _fluctuation); var emission1 = ColorToHsvm(_emissionColor1); var emission2 = ColorToHsvm(_emissionColor2); //将参数传递给shader foreach (var renderer in _renderers) { if (renderer == null) continue; renderer.GetPropertyBlock(_sheet); _sheet.SetVector(ShaderIDs.VoxelParams, vparams); _sheet.SetVector(ShaderIDs.AnimParams, aparams); _sheet.SetVector(ShaderIDs.EmissionHsvm1, emission1); _sheet.SetVector(ShaderIDs.EmissionHsvm2, emission2); _sheet.SetColor(ShaderIDs.TransitionColor, _transitionColor); _sheet.SetColor(ShaderIDs.LineColor, _lineColor); _sheet.SetVector(ShaderIDs.EffectorPlane, plane); _sheet.SetVector(ShaderIDs.PrevEffectorPlane, _prevEffectorPlane); //_sheet.SetFloat(ShaderIDs.LocalTime, time); renderer.SetPropertyBlock(_sheet); print(plane); } } //进行gizmo编辑器的实现,用于可视化Debug Mesh _gridMesh; void OnDestroy() { if (_gridMesh != null) { if (Application.isPlaying) Destroy(_gridMesh); else DestroyImmediate(_gridMesh); } } void OnDrawGizmos() { if (_gridMesh == null) InitGridMesh(); //矩阵用于控制Gizmos跟随物体的移动而移动 Gizmos.matrix = transform.localToWorldMatrix; Gizmos.color = new Color(1, 1, 0, 0.5f); Gizmos.DrawWireMesh(_gridMesh, Vector3.zero); Gizmos.DrawWireMesh(_gridMesh, Vector3.forward); Gizmos.color = new Color(1, 0, 0, 0.5f); Gizmos.DrawWireCube(Vector3.forward / 2, new Vector3(0.02f, 0.02f, 1)); } void InitGridMesh() { const float ext = 0.5f; const int columns = 10; var vertices = new List&lt;Vector3&gt;(); var indices = new List&lt;int&gt;(); for (var i = 0; i &lt; columns + 1; i++) { var x = ext * (2.0f * i / columns - 1); indices.Add(vertices.Count); vertices.Add(new Vector3(x, -ext, 0)); indices.Add(vertices.Count); vertices.Add(new Vector3(x, +ext, 0)); indices.Add(vertices.Count); vertices.Add(new Vector3(-ext, x, 0)); indices.Add(vertices.Count); vertices.Add(new Vector3(+ext, x, 0)); } _gridMesh = new Mesh { hideFlags = HideFlags.DontSave }; _gridMesh.SetVertices(vertices); _gridMesh.SetNormals(vertices); _gridMesh.SetIndices(indices.ToArray(), MeshTopology.Lines, 0); _gridMesh.UploadMeshData(true); }} MaterialPropertyBlock研究代码的时候发现了MaterialPropertyBlock，查阅文档才发现是用于节约性能。实际应用可以查看这篇文章MaterialPropertyBlock。 Shader的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301// Upgrade NOTE: replaced &apos;_Object2World&apos; with &apos;unity_ObjectToWorld&apos;// Upgrade NOTE: replaced &apos;_Object2World&apos; with &apos;unity_ObjectToWorld&apos;Shader &quot;Custom/MeshShader&quot;{ Properties { _MainTex(&quot;主纹理贴图&quot;,2D)=&quot;white&quot;{} } SubShader { Tags { &quot;RenderType&quot; = &quot;Opaque&quot; } LOD 100 Pass { Tags{&quot;LightMode&quot;=&quot;ForwardBase&quot;} CGPROGRAM //声明着色器 #pragma vertex vert #pragma geometry geom #pragma fragment frag #include &quot;UnityCG.cginc&quot; #include &quot;Assets/My/SimplexNoise3D.hlsl&quot; //传递给顶点着色器的数据 struct a2v { float4 vertex:POSITION; float3 normal:NORMAL; float4 texcoord:TEXCOORD0; }; //传递给几何着色器的数据 struct v2g { float4 vertex:POSITION; float3 normal:TEXCOORD0; //float2 uv:TEXCOORD1; }; //传递给像素着色器的数据 struct g2f { float4 pos : SV_POSITION; float3 normal:TEXCOORD0; //float2 uv : TEXCOORD1; float4 color:COLOR; }; sampler2D _MainTex; float4 _MainTex_ST; //用于几何着色器的数据 half2 _VoxelParams; // density, scale 密度，比例 half3 _AnimParams; // stretch, fall distance, fluctuation 伸展、下降距离、波动 float4 _EffectorPlane; float4 _PrevEffectorPlane; //用于像素着色器的数据 half4 _EmissionHsvm1; half4 _EmissionHsvm2; half3 _TransitionColor; half3 _LineColor; //顶点着色器 void vert(inout v2g input) { } g2f VertexOutput( float3 position0, float3 position1, half3 normal0, half3 normal1, half param, half emission = 0, half random = 0, half2 baryCoord = 0.5 ) { g2f i; i.pos = UnityObjectToClipPos(float4(lerp(position0, position1, param),1)); i.normal = normalize(lerp(normal0, normal1, param)); i.color = float4(baryCoord, emission,random); return i; } // 计算方块的位置和大小 void CubePosScale( float3 center, float size, float rand, float param, out float3 pos, out float3 scale ) { const float VoxelScale = _VoxelParams.y; const float Stretch = _AnimParams.x; const float FallDist = _AnimParams.y; const float Fluctuation = _AnimParams.z; // Noise field //噪声场 float4 snoise = snoise_grad(float3(rand * 2378.34, param * 0.8, 0)); // Stretch/move param float move = saturate(param * 4 - 3); move = move * move; // Cube position pos = center + snoise.xyz * size * Fluctuation; pos.y += move * move * lerp(0.25, 1, rand) * size * FallDist; // Cube scale anim scale = float2(1 - move, 1 + move * Stretch).xyx; scale *= size * VoxelScale * saturate(1 + snoise.w * 2); } //哈希值，用于随机觉得面片是三角面片还是Cube float Hash(uint s) { s = s ^ 2747636419u; s = s * 2654435769u; s = s ^ (s &gt;&gt; 16); s = s * 2654435769u; s = s ^ (s &gt;&gt; 16); s = s * 2654435769u; return float(s) * rcp(4294967296.0); // 2^-32 } //几何着色器 [maxvertexcount(24)] void geom(triangle v2g input[3], uint pid : SV_PrimitiveID, inout TriangleStream&lt;g2f&gt; outStream) { //获取密度 const float VoxelDensity = _VoxelParams.x; //获取传入顶点的位置 float3 p0 = input[0].vertex.xyz; float3 p1 = input[1].vertex.xyz; float3 p2 = input[2].vertex.xyz; float3 p0_prev = p0; float3 p1_prev = p1; float3 p2_prev = p2; //获取传入顶点的法线 float3 n0 = input[0].normal; float3 n1 = input[1].normal; float3 n2 = input[2].normal; //计算中心点 float3 center = (p0 + p1 + p2) / 3; float size = distance(p0, center); //变形参数 //将中心点变换到世界空间中 float3 center_ws = mul(unity_ObjectToWorld, float4(center,1)).xyz; float param = 1 - dot(_EffectorPlane.xyz, center_ws) + _EffectorPlane.w; //如果变形还没开始那就将平常操作 if (param &lt; 0) { outStream.Append(VertexOutput(p0, 0, n0, 0, 0, 0, 0)); outStream.Append(VertexOutput(p1, 0, n1, 0, 0, 0, 0)); outStream.Append(VertexOutput(p2, 0, n2, 0, 0, 0, 0)); outStream.RestartStrip(); return; } //变形结束后，不传递任何数据，从而使物体隐身 if (param &gt;= 1) return; // Choose cube/triangle randomly. //uint seed = float3(pid * 877, pid * 877, pid * 877); uint seed = pid * 877; if (Hash(seed) &lt; VoxelDensity) { // -- Cube -- // Random numbers float rand1 = Hash(seed + 1); float rand2 = Hash(seed + 5); // Cube position and scale float3 pos, pos_prev, scale, scale_prev; CubePosScale(center, size, rand1, param, pos, scale); // Secondary animation parameters float morph = smoothstep(0, 0.25, param); float em = smoothstep(0, 0.15, param) * 2; // initial emission em = min(em, 1 + smoothstep(0.8, 0.9, 1 - param)); em += smoothstep(0.75, 1, param); // emission while falling // Cube points calculation float3 pc0 = pos + float3(-1, -1, -1) * scale; float3 pc1 = pos + float3(+1, -1, -1) * scale; float3 pc2 = pos + float3(-1, +1, -1) * scale; float3 pc3 = pos + float3(+1, +1, -1) * scale; float3 pc4 = pos + float3(-1, -1, +1) * scale; float3 pc5 = pos + float3(+1, -1, +1) * scale; float3 pc6 = pos + float3(-1, +1, +1) * scale; float3 pc7 = pos + float3(+1, +1, +1) * scale; // World space to object space conversion // Vertex outputs float3 nc = float3(-1, 0, 0); outStream.Append(VertexOutput(p0, pc2, n0, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc0, n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p0, pc6, n0, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p2, pc4, n2, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(1, 0, 0); outStream.Append(VertexOutput(p2, pc1, n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p1, pc3, n1, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p2, pc5, n2, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p1, pc7, n1, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, -1, 0); outStream.Append(VertexOutput(p2, pc0, n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc1, n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p2, pc4, n2, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p2, pc5, n2, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, 1, 0); outStream.Append(VertexOutput(p1, pc3, n1, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p0, pc2, n0, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p1, pc7, n1, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p0, pc6, n0, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, 0, -1); outStream.Append(VertexOutput(p2, pc1, n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc0, n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p1, pc3, n1, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p0, pc2, n0, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); nc = float3(0, 0, 1); outStream.Append(VertexOutput(p2, pc4, -n2, nc, morph, em, rand2, float2(0, 0))); outStream.Append(VertexOutput(p2, pc5, -n2, nc, morph, em, rand2, float2(1, 0))); outStream.Append(VertexOutput(p0, pc6, -n0, nc, morph, em, rand2, float2(0, 1))); outStream.Append(VertexOutput(p1, pc7, -n1, nc, morph, em, rand2, float2(1, 1))); outStream.RestartStrip(); } else { // -- Triangle -- half morph = smoothstep(0, 0.25, param); //half morph = 0.25; half em = smoothstep(0, 0.15, param) * 2; outStream.Append(VertexOutput(p0, center, n0, n0, morph, em)); outStream.Append(VertexOutput(p1, center, n1, n1, morph, em)); outStream.Append(VertexOutput(p2, center, n2, n2, morph, em)); outStream.RestartStrip(); } } //计算颜色 half3 SelfEmission(g2f input) { half2 bcc = input.color.rg; half em1 = saturate(input.color.b); half em2 = saturate(input.color.b - 1); half rand = input.color.a; // Cube face color half3 face = lerp(_EmissionHsvm1.xyz, _EmissionHsvm2.xyz, rand); face *= lerp(_EmissionHsvm1.w, _EmissionHsvm2.w, rand); // Cube face attenuation face *= lerp(0.75, 1, smoothstep(0, 0.5, length(bcc - 0.5))); // Edge detection half2 fw = fwidth(bcc); half2 edge2 = min(smoothstep(0, fw * 2, bcc), smoothstep(0, fw * 2, 1 - bcc)); half edge = 1 - min(edge2.x, edge2.y); return face * em1 + _TransitionColor * em2 * face + edge * _LineColor * em1; } half4 frag(g2f z):SV_Target { half4 col = half4(SelfEmission(z),1); return col; } ENDCG } } FallBack &quot;Diffuse&quot;} 这里运用到了三维噪声的知识，这里我只是简单的调用了K神写好的噪声函数，并没有深究，其实我还是看过了一些关于噪声的文章，以后已机会把笔记总结出来。 最终结果 注意这个效果对于模型也是有要求的，模型的面片不能太小，不然就会得到以下的结果…","link":"/2020/08/23/Unity%E5%AE%9E%E7%8E%B0%E7%B1%B3%E5%93%88%E6%B8%B8%E7%9A%84Mesh%E5%8F%98%E6%8D%A2%E8%BD%AC%E5%9C%BA%E6%95%88%E6%9E%9C/"},{"title":"ue4雪","text":"ue4雪主要思路：利用VertexNormal划分雪的区域，然后对于岩石和雪的属性进行Lerp，最重要的还有基于屏幕空间的此表面散射，此表面散射的强度和不透明度有关，当不透明度为0的时候，无散射。 https://www.bilibili.com/video/av82942893?from=search&amp;seid=15809526983300723419 交互雪，主要思路：利用SceneCapture绘制RenderTarget，利用SceneDepth和CustomDepth进行脚印的绘制。 https://zhuanlan.zhihu.com/p/80913086","link":"/2020/08/23/ue4%E9%9B%AA/"},{"title":"x Title MagicaVoxel","text":"1Title: MagicaVoxel","link":"/2020/08/23/x%20Title%20MagicaVoxel/"},{"title":"建议后处理描边，主要思路：利用自定义深度进行上下左右4像素描边","text":"建议后处理描边，主要思路：利用自定义深度进行上下左右4像素描边，并且利用CustomDepth实现了遮挡发光。 https://zhuanlan.zhihu.com/p/81310476 https://zhuanlan.zhihu.com/p/81755071 简易后处理描边，主要思路：利用自定义深度进行周边8像素描边 http://www.uejoy.com/?p=347 发光描边，youtube做法，利用场景深度SceneDepth进行比较，然后利用CustomDepth进行发光物的选择，利用CustomStencil进行发光颜色的选择 https://www.bilibili.com/video/av79974250?from=search&amp;seid=11481119403927745359","link":"/2020/08/23/%E5%BB%BA%E8%AE%AE%E5%90%8E%E5%A4%84%E7%90%86%E6%8F%8F%E8%BE%B9%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%80%9D%E8%B7%AF%EF%BC%9A%E5%88%A9%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B7%B1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E4%B8%8A%E4%B8%8B%E5%B7%A6%E5%8F%B34%E5%83%8F%E7%B4%A0%E6%8F%8F%E8%BE%B9/"},{"title":"什么是渲染流水线","text":"什么是渲染流水线应用阶段：在CPU中运行，主要有三个任务：1.准备好场景数据 2.进行剔除（culling）3.设置好模型的渲染状态 几何阶段：在GPU中运行，和每个渲染图元打交道，进行逐顶点，逐多边形操作。 光栅化阶段：在GPU中运行，主要任务：决定每个渲染图形中哪些像素被绘制在屏幕上，对几何阶段得到的逐顶点数据进行插值，再逐像素处理。 CPU和GPU的通信应用阶段的任务： 把数据加载到显存：把渲染所需要的数据从硬盘到系统内存最后到显存 设置渲染状态：定义了场景中的网格如何被渲染，例如用什么Shader。 调用DrawCall：CPU通过DrawCall告知GPU去计算一个需要被渲染的图元列表。 GPU流水线 顶点着色器：主要任务坐标变换（把顶点坐标从模型空间转换到齐次裁剪空间），转换后由硬件进行透视除法，最后得到NDC。逐顶点光照。 裁剪：把不在摄像机视野范围的物体不需要被处理 屏幕映射：把裁剪后的每个图元的x和y坐标转换到屏幕坐标系，跟屏幕的分辨率有关，屏幕坐标和z坐标构成了窗口坐标系 三角形设置：计算一个三角网格边界的数据坐标信息，为三角形遍历做准备。 三角形遍历：检查每一个像素，为了三角网格覆盖的像素生成片元，找到哪些像素被三角网格覆盖的过程就是三角形遍历，也叫扫描变换，并进行数据插值 片元着色器：前面的光栅化并不影响屏幕上每个像素的颜色，而是产生数据用于表达一个三角网格如何覆盖每个像素。这一阶段可以完成很多渲染操作，比如纹理采样。 逐片元操作：主要任务： （1）决定每个片元的可见性，比如深度测试，模板测试 （2）如果片元通过测试，则片元的颜色值和颜色缓冲区进行混合 在Unity的渲染流水线中，深度测试是在片元着色器之前，被Early-Z技术 双缓冲技术：前置缓冲是之前在屏幕上的图像，后置缓冲是幕后的渲染。 CPU和GPU如何并行工作利用命令缓冲区（CommandBuffer）进行并行工作，命令缓冲区包含了一个命令队列，CPU往里面加命令，GPU从里面读取命令 DrawCall多了会影响帧率因为每次调用DrawCall前，CPU要往GPU发送数据，比如检查渲染状态，如果DrawCall数量太多，CPU就会花费大量时间去提交DrawCall 如何减少DrawCall思路：把很多小DrawCall合并成大DrawCall，就是批处理了（Batching） 注意：要在CPU内存中合并网格需要耗费时间，所以批处理更适合静态物体，只要合并一次即可。对于动态物体我们每一帧重新合并再发送给GPU。 注意：利用批处理，CPU在RAM把多个网格合并成一个更大的网格，再发送给GPU，然后在一个Draw Call中渲染它们。但要注意的是，使用批处理合并的网格将会使用同一种渲染状态。也就是说，如果网格之间需要使用不同的渲染状态，那么就无法使用批处理技术 Unity的内置ShaderUnlit Shader：一个不包含光照但包含雾效的基本顶点片元着色器。 Image Effect Shader：实现各种屏幕后特效的基本模板 Compute Shader:一个GPU计算的Shader Unity Shader结构1.Shader名字 Shader “Custom/MyShader” 2.Properties属性 Properties{ _Color(“Color”,Color)=(1,1,1,1); } 3.SubShader语义块 SubShader{ ​ [Tags]//标签 ​ [RenderSetup]//状态 ​ Pass{ ​ } ​ //other Passes } 4.常见渲染状态 再SubShader中设置了渲染状态，会被应用到所有的Pass 状态名称 设置指令 解释 Cull Cull Back|Front|Off 设置剔除模式：剔除背面|正面|关闭剔除 ZTese ZTest Less Greater|LEqual|GEqual|Equal|NotEqual|Always 设置深度测试时使用的函数 ZWrite ZWrite On|Off 开启/关闭深度写入 Blend Blend SrcFactor DstFactor 开启并设置混合模式 5.SubShader的标签 用于告诉Unity的渲染引擎，SubShader希望怎么以及何时渲染这个对象。 结构如下： Tags {“TagName1” = “Value1”} 支持的类型： 6.Pass语义块 结构如下 Pass{ ​ [Name] ​ [Tags] ​ [RenderSetup] } 定义该Pass名称，通过这个名称就可以进行Pass的复用，注意要全部大写 Name “MyPassName” 复用：UsePass “MyShader/MYPASSNAME” 7.Pass的标签 同样是用来告诉Unity我们希望怎么渲染物体 除了普通的Pass定义外，Unity ShaderLab还支持一些特殊的Pass，以便进行代码的复用和更复杂的效果. UsePass:Pass的复用。 GrabPass：该Pass负责抓取屏幕并将结果存储在一张纹理中，以便后续的Pass处理。 8.留一条后路 如果上面所有的SubShader在这显卡上不可用，就用最低级的Shader 结构如下: Fallback “Nmae” //或者 Fallback Off Fallback还会影响阴影投射，在渲染阴影纹理时，Unity会在每个Unity Shader中寻找一个阴影投射的Pass，而Fallback内置Shader中就包含一个通用的Pass。 Shader数学基础（未解决）1.Unity使用的坐标系 右侧，上侧，前侧分别对应X,Y,Z的正方向，Unity使用的是左手坐标系。但是在观察空间，Unity使用的是右手坐标系，则摄像机的前向是Z轴的负方向。 2.矢量的点积 从三维矢量的方向看 性质1：点积可以结合标量乘法，也就是说对点积中一个矢量进行缩放，也是对最后点积结果的缩放 性质2：点积可以结合矢量加法和减法 性质3：一个矢量和本身进行点积的结果，就是该矢量的模的平方，很多情况下，我们比较两个矢量的长度大小，可以直接使用点积结果，因为开平方需要消耗一定性能。 从三角代数方面看，更有几何意义 如果矢量ab都为归一化向量，我们就可以得到两个矢量中的夹角角度 3.矢量的叉积（未解决） 叉积不满足交换律，对两个矢量进行叉积的结果是得到一个同时垂直于这两个矢量的新矢量。新矢量的模长等于ab向量模长的面积,方向和左手右手坐标系有关 4.矩阵复合变换 由于矩阵乘法不满足交换律，所以我们约定变换的顺序是先缩放，再旋转，最后平移 旋转角度是，旋转顺序是zxy。 坐标空间的变换注意在观察空间中摄像机是右手坐标系，摄像机的前方是负Z轴 模型空间（model space）–&gt;世界空间（world space） 模型变换（model transform） 世界空间（world space）–&gt;观察空间（view space）观察变换（view transform） 观察空间（view space）–&gt;裁剪空间（clip space，齐次裁剪空间）用于变换的矩阵被称为裁剪矩阵（clip matrix），也叫投影矩阵（projection matrix） 裁剪空间的目标是为了能够更方便地对渲染图元进行裁剪，空间由视锥体决定，也分为正交投影，透视投影 投影矩阵的目的： 1.为后面真正的投影做准备，经过投影矩阵的变换后，顶点的w分量具有特殊的意义 2.对x,y,z分量进行缩放，因为直接使用视锥体的6个裁剪平面进行裁剪会很麻烦，经过投影矩阵的变换后，我们直接w分量作为一个范围值，如果x,y,z都在这个范围内，就说明顶点在裁剪空间 裁剪空间（clip space，齐次裁剪空间） –&gt;屏幕空间（screen space） 步骤： 1.进行齐次除法，就是用w分量除以x,y,z分量，得到归一化的设备坐标NDC。 2.经过齐次除法后，视锥体都变换到一个相同的立方体内，我么根据变换后的x，y坐标来映射输出窗口的像素坐标。 总结 法线变换（P87）进行非统一缩放时，如果使用和变换顶点相同的变换矩阵来变换法线，就会得到错误的结果，即变换后的法线方向与平面不再垂直 数学答疑解惑1.使用3x3还是4x4的变换矩阵 对于线性变换（旋转和缩放），3x3足以 如果存在平移变换，4x4 对于顶点变换，我们通常使用4x4，对于方向矢量变换，3x3足够，因为平移变换对于方向矢量没有任何影响 2.CG矩阵 CG使用的是行优先填充矩阵，但是在Unity API中Matrix4x4采用的是列优先。 3.获取片元的屏幕坐标 1.使用语义vpos 1234fixed4 frag(float4 sp:VPOS) : SV_Target{ //用屏幕坐标除以屏幕分辨率_ScreenParams.xy,得到视口空间的坐标 return fixed4(so.xy/_ScreenParams.xy,0.0,1.0);} 2.使用ComputeScreenPos，自己手动完成屏幕映射，先齐次除法，再映射到视口空间 Shader入门篇1.POSITION,TANGENT,NORMAL这些语义的数据由该材质的MeshRender组件提供，每帧调用DrawCall时，MeshRender会把他负责渲染的模型数据发送给Unity Shader。 2.ShaderLab属性和CG变量类型 uniform关键字，在Unity Shader中可以省略 3.引入头文件 12345CGPROGRAM//...#include &quot;UnityCG.cginc&quot;//...ENDCG 常用文件 可以直接使用UnityCG.cginc中预定义的结构体 UnityCG.cginc中常用的函数 渲染平台的差异当我们同时处理多张渲染图像时（前提时开启了抗锯齿），例如同时处理屏幕图像和法线纹理，在DirectX平台上就会出现图像在竖直方向朝向不同，我们就需要在顶点着色器进行纹理的反转 123456//判断是否时DirectX平台#if UNITY_UV_STARTS_AT_TOP//判断在这样的平台下是否开启了抗锯齿，如果开启了抗锯齿，纹素竖直方向会变为负值if(_MainTex_TexelSize.y&lt;0) uv.y = 1-uv.y;#endif Shader整洁高效之道1.float half 还是fixed 根据需求不同进行选择 2.Shader Target 我们可以指定更高级的shader Target，提高shader model的等级，那样shader的能力就越大。 1#pragma target4.0 3.慎用分支和循环语句 因为会降低GPU的并行处理操作 Unity的基础光照1.光源和物体相交的结果：散射（scattering）和吸收（absorption） 散射（scattering）：只改变光线的方向，但不改变光线的密度的和颜色。通常有两种方向：散射到物体内部，也被称为折射（refraction），散射到物体外部，被称为反射（reflection）。 吸收（absorption）：只改变光线密度和颜色，但不改变方向。 总的来说，可以用高光反射（specular）表示物体表面的反射，漫反射（diffuse）表示光线的折射，吸收和散射出表面。 光照模型BRDF光照模型当给定了入射光线的方向和辐照度，BRDF可以给出某个出射方向上的光照能量分布。 标准光照模型（Phong模型）基本方法：把进入摄像机内的光线分为4部分。 1.自发光（emissive）：需要全局光照(global illumination),才能照亮周围物体，否则只是自己本身看起来更亮了。 2.高光反射（specular）： 反射方向计算公式： 高光反射公式： Clight：光源颜色，Mspecular：高光颜色，Mgloss：光泽度，用于控制高光的区域。 3.漫反射（diffuse）： n：表面法线。I：指向光源的单位矢量。Clight：光源颜色。Mdiffuse：材质颜色。 4.环境光（ambient）：用于描述其他所有的间接光照。 5.Blinn模型 为了避免计算反射方向r，Blinn引入新的矢量h，是通过对v和i的取平均后归一化得到。 总结：Phong模型和Blinn模型都是经验模型。 逐像素还是逐顶点逐像素操作(Phong Shading)效果 &gt; 逐顶点操作（Gouraud Shading） 逐像素操作计算量 &gt; 逐顶点操作 因为顶点数目要远远小于像素数目，在逐顶点操作中由于有非线性的计算（比如计算高光反射），但后面线性插值就会破坏原计算的非线性关系。 半兰伯特模型 这样我们就把点积的结果范围从【-1，1】映射到【0，1】解决了背面光照问题。 基础纹理123o.uv=v.texcoord.xy * _MainTex_ST.xy + _MainTex.zw;//也可以利用Unity内置宏//o.uv = TRANSFORM_TEX(v.texcoord,_MainTex); 1.Wrap Mode Wrap Mode决定了当纹理坐标超过【0，1】范围后如何被平铺。 分为两种模式：一种是Repeat，超过1部分整数被舍弃，直接用小数采样，这样纹理就会不断重复。 另一种是Clamp，会自动截取到【0，1】之间。 2.Filter Mode 决定了纹理由于变换产生拉伸时会采用哪种滤波模式。 支持3种模式：Point，Bilinera，Trilinear，得到的图片效果依次提升，但消耗的性能也依次增加。 放大纹理时，三种Filter Mode效果。 3.多级渐远纹理（mipmapping） 多级渐远纹理技术将原纹理提前用滤波处理得到更小的图像，每一层都是对上一层降采样的结果。 当物体远离摄像机时，可以直接使用较小的纹理。缺点是空间换时间 开启Mipmap首先要将Texture Type选择成Advanced，然后勾选Generate Mip Maps。 Point：使用最近邻滤波，采样像素通常只有一个 Bilinear：使用线性滤波，找到4个邻近像素，进行像素插值 Trlinear：与Bilinear相似，但会在多级MipMap中进行混合。 4.Format决定了存储纹理的格式 凹凸映射目的：使用一张纹理来修改模型表面的法线，以提供更多的细节 高度纹理高度图存储的是强度值，用于表示模型表面局部的海拔高度 优点：直观，可以明确知道模型表面的凹凸情况 缺点：计算复杂，在实时计算中不能直接得到表面法线。 法线纹理法线纹理存储的就是表面的法线方向，法线方向的分量在【-1，1】，但像素范围是【0，1】，所以要进行映射 这就要求，我们在shader中对法线纹理进行纹理采样后，还要反映射才能得到原先的法线方向。 模型空间的法线纹理模型空间下的法线纹理看起来是五颜六色，是因为所有的法线是同一个坐标空间，即模型空间，但是每个点存储的法线方向是各异的，所以造成了五颜六色。 优点：实现简单，更加直观，计算更少。 在纹理坐标的缝合处和尖锐的边角部分，可见的突变缝隙较小。 切线空间的法线纹理对于每个模型的顶点都有自己的切线空间，原点是顶点本身，Z轴就是法线方向，X轴就是切线方向，Y轴由法线和切线叉积可得，就是副切线，如果说一个点的法线方向不变，也就是在切线空间中值为（0，0，1），映射到纹理就是（0.5，0.5，1）浅蓝色，蓝色也说明大部分顶点法线和模型本身法线一样，不需要改变 优点：自由度很高，模型空间中法线纹理是绝对法线信息 可以进行UV动画，可以通过移动纹理UV实现凹凸移动效果，但是在模型空间下的法线纹理是完全错误的。 可以重用纹理。 可以压缩，因为切线空间下的法线Z方向总是正方向，我们可以仅存储XY方向，推到出Z方向。 计算空间的选择1.在切线空间下进行光照计算，同时需要将光照方向和视角方向变换到切线空间 2.在世界空间下进行光照计算，把采样得到的法线方向变换到世界空间下。 从效率上说，第一种方法优于第二种，因为在顶点着色器就完成对光照方向和视角方向的变换。第二种方法还要在片元着色器中完成矩阵计算。 从通用性，第二种由于第一种，因为我们也要在世界空间上进行一些计算，例如Cubemap环境映射。 在切线空间下计算（未解决）我们需要知道模型空间到切线空间的变换矩阵，详细看P149 注意：Tangent与Normal不同，是float4类型，因为我们需要tangent.w来决定切线空间下副切线的方向性。 只有我们将法线纹理的类型设置未Normal map，才能使用Unity内置宏UnpackNormal（packedNormal），反映射法线。 在世界空间下计算（未解决）思路：在顶点着色器计算出从切线空间到世界空间的变换矩阵，传递给片元着色器 变换矩阵的计算由顶点的切线，副切线和法线在世界空间下的表示得到 法线纹理的类型 我们将纹理类型设置为Normal mapUnity就会根据不同平台进行纹理的压缩（例如使用DXT5nm格式），我们就需要通过UnpackNormal对不同压缩格式的进行正确的采样 1.DXT5nm 使用了DXT5nm格式，纹理的a通过对应法线的x分量，g通道对应了法线的y分量，纹理的r和b通道机会被舍弃，因为法线的Z分量可以通过推导得出。 2.从高度图里生成法线纹理 将高度图导入Unity并设置Texture Type为Normal map，勾选Create from Grayscale，生成了法线贴图。 Bumpiness：控制凹凸程度 Filtering：使用那种方式计算凹凸程度。第一种Smooth，生成法线比较平滑。另一种Sobel滤波（边缘检测的滤波器）。 渐变纹理使用不同的渐变纹理控制漫反射光照 遮罩纹理人为的保护某些区域，避免被修改。 通常我们会充分利用一张纹理的RGBA通道，用于存储不同的属性，例如高光强度存在R，边缘光强度存在G等等 透明效果实现透明的两种方法： 1.透明度测试 只要一个片元的透明度满足条件，该片元就被舍弃。否则将按普通的不透明物体处理。也就是说透明度测试不需要关闭深度写入，与其他不透明物体最大不同是根据透明度舍弃片元。无法得到真正的半透明效果 2.透明度混合 与存储在颜色缓冲的颜色进行混合，并且需要关闭深度写入，但没有关闭深度测试。也就是说，对于透明度混合来说，深度缓冲只是只读。 渲染顺序1.关闭深度写入的结果 如果不关闭深度写入，会导致后面的物体被剔除，因为深度测试的时候，半透明物体距离摄像机更近。所以我们就破坏了深度缓冲机制，这时候渲染顺序就很重要。 2.先渲染透明物体B，在渲染不透明物体A 正确的半透明效果 3.先渲染透明物体A，再渲染透明物体B 错误的效果，B直接覆盖A的颜色。 4.引擎的解决方法 （1）先渲染所有的不透明物体，并开启他们的深度测试和深度写入 （2）把不透明物体感召距离谁相机的远近及逆行排序，从后往前渲染半透明物体，并且开启深度测试，关闭深度写入 注意：我们如何（2）按距离摄像机的远近进行排序，我们对单个物体级别进行排序，如果存在循环重叠情况，就永远无法得到正确的结果。 解决方法：分割网格，尽量让模型是图面提，或者拆分成多个子物体。 Unity的渲染顺序Unity为了解决渲染顺序问题提供了渲染队列（render queue），使用Queue标签决定我们的模型归于哪个渲染队列，数字越小渲染越早。 透明度测试1234//首先定义标签SubShader{ Tags{&quot;Queue&quot; = &quot;AlphaTest&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;TransparentCutout&quot;}} 这里把渲染队列设置为AlphaTest，并且不受投影器（Projectors）影响，RenderType用于在C#中着色器替换功能。 1234//利用Clip函数进行片元舍弃clip(texColor.a-_Cutoff);//只要参数小于0，就舍弃。//discard指令也可以进行片元舍弃。 透明度混合1.Blend渲染状态 Blend是Unity提供的混合模式的命令，与颜色缓冲进行混合。 2.代码 1234567891011121314//定义标签SubShader{ Tags{&quot;Queue&quot; = &quot;Transparent&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;Transparent&quot;}}Pass{ Tags{&quot;LightMode&quot;=&quot;ForwardBase&quot;} //关闭深度写入 ZWrite Off //开启颜色混合 Blend SrcAlpha OneMinusSrcAlpha //... return fixed4(ambient+diffuse,texColor.a*_AlphaScale);} 注意一旦我们物体有复杂的遮挡关系，就会出现错误的透明效果，这是因为关闭了深度写入造成的，我们就无法对模型进行像素级别的深度排序。 解决方法，开启深入写入的半透明效果使用两个Pass来渲染模型：第一个Pass开启深入写入，但不输出颜色，只是为了把深度值写入深度缓冲。第二个Pass进行正常的透明度混合。 缺点：使用了多个Pass，性能有一定的影响 新的渲染命令ColorMask ColorMask 0表示不会输出任何颜色 Shaderlap的混合命令通过混合操作和混合因子命令，可以得到一些类似PhotoShop的混合效果 双面渲染的透明效果1.透密度测试的双面渲染 直接Cull Off，关闭剔除功能 2.透明度混合的双面渲染 分为两个Pass，第一个Pass只渲染背面，第二个Pass只渲染正面，这样就能保证背面总是在正面之前渲染。 Unity的渲染路径1.向前渲染路径(Forward Rendering Path) 2.延迟渲染路径(Deferred Rending Path) 我们可以用给每个Pass使用标签来指定该Pass的渲染路径 123Pass{ Tags{&quot;LightMode&quot;=&quot;ForwardBase&quot;}} 使用渲染路径的原因：告知Unity去准备相关的光照属性，否则光照变量不一定会被正确赋值。 前向渲染路径原理 我们需要渲染该对象的渲染图元，并计算颜色，深度缓冲区的信息，如果片元可见，就更新缓冲区信息。 假如场景有N个物体，每个物体受M个光源的影响，那么渲染整个场景就需要N*M个Pass。 Unity中的前向渲染（P186未解决）在Unity中，前向渲染路径有3中处理光照（即照亮物体）的方式：逐顶点处理，逐像素处理，球谐函数（SH）处理 Unity会根据各个光源的设置以及对物体的影响程度，进行重要度排序 一定数目按逐像素处理，最多4个光源逐顶点，剩下光源SH处理 判断规则： 延迟渲染路径原理延迟渲染路径包含了两个Pass，第一个Pass，不进行任何光照计算，仅仅计算哪些片元可见，就把相关信息存储到G缓冲区。第二个Pass，利用G缓冲区的各个片元信息，进行光照计算。 总结：延迟渲染的效率不依赖场景的复杂度，而是和屏幕空间大小有关 Unity的延迟渲染优点：适合场景中光源数目很多，并且延迟渲染中每个光源都可以逐像素处理。 缺点：不支持真正的抗锯齿功能。不能处理半透明物体。对显卡有一定要求 当我们使用延迟渲染时，Unity要求我们提供两个Pass Unity的光源类型1.平行光 2.点光源 3.聚光灯 在前向渲染中处理不同光源类型我们需要在Unity shader中访问5个属性：位置，方向，颜色，强度以及衰减 BasePass（1）我们需要#pragma multi_compile_fwdbase指令保证光照变量能被正确赋值。 （2）环境光只在BasePass计算一次，这样就不用再后面的Additional Pass再次计算，类似的还有物体自发光。 （3）BasePass处理的逐像素光源一定是平行光。_WorldSpaceLightPos0获取平行光方向， _LightColor0获取颜色和强度。 （4）平行光是没有衰减的。 Additional Pass这个Pass为了其他逐像素光源计算的。 （1）定义好渲染路径和标签 （2）这个Pass处理的光源类型可能是平行光，点光源或者是聚光灯，所以要及进行区分 区分方向 区分衰减 首先获取光源空间下的坐标，然后利用该坐标对衰减纹理采样获得衰减值，这里利用了一张纹理作为查找表LUT Unity的光照衰减用于光照衰减的纹理Unity使用一张纹理_LightTexture0作为查找表作为逐像素光照的衰减，如果该光源使用了cookie，那么就是 _LightTextureB0。 好处：不依赖数学的复杂性，只需要一个参数去纹理中采样就可以了 缺点：需要预处理得到采样纹理，纹理的大小会影响衰减精度。 不直观，而且无法使用其他数学公式计算衰减值 （1）需要将顶点从世界空间变换到光源空间。 （2）进行衰减纹理的采样 还要使用UNITY_ATTEN_CHANNEL获得衰减值所在分量，得到真正的衰减值 数学公式计算衰减 但是效果有时候不尽人意，比如离开光源的照明范围会发生突变。 Unity的阴影如何在Unity中物体向其他物体投射阴影，以及接受其他物体的阴影。 阴影的实现Unity使用了一种ShadowMap的技术，原理就是在光源位置放一台摄像机，那么阴影区域就是摄像机看不到的地方。 Unity会使用LightMode为ShadowCaster的Pass专门更新更新光源的shadowmap，如果没有找到该Pass，该物体就无法向其他物体投射阴影。 传统的阴影映射纹理在正常渲染的Pass将顶点位置变换到光源空间下，利用xy分量进行shadowmap的采样，得到该位置的深度信息，然后进行比较，如果小于采样得到的深度值，就是在阴影中 屏幕空间的阴影映射技术（Screenspace Shadow Map）原本是延迟渲染中产生阴影的方式。 （1）首先调用LightMode为ShadowCaster的Pass获取可投影光源的Shadowmap，还有摄像机的深度纹理 （2）根据这两个map获取屏幕空间的阴影图，如果摄像机的表面深度大于转到ShadowMap的深度值，表明此表面虽可见，但还是阴影中，就这样得到屏幕空间的阴影图，但是由于是屏幕空间，所以采样坐标必须是屏幕空间 总结1.如果一个物体就像接受其他物体的阴影，就必须在Shader中对Shadowmap进行采样，最后把光照结果相乘就产生阴影效果。 2.如果物体想向其他物体投射阴影，就必须把物体加入到光源的Shadowmap计算中，这过程可以通过LightMode为ShadowCaster的Pass实现 计算阴影三剑客SHADOW_COORDS：声明一个_ShadowCoord的阴影纹理变量。 TRANSFER_SHADOW：根据平台的不同选择使用的技术。比如如果可以使用屏幕空间的阴影映射就会调用ComputeScreenPos来计算_ShadowCoord。如果不支持，就使用传统的阴影映射。 SHADOW_ATTENUATION：利用得到的阴影纹理坐标进行采样。 注意：TRANSER_SHADOW会使用v.vertex或a.pos进行计算，所以命名要对上 统一管理光照衰减和阴影使用Unity的内置宏实现UNITY_LIGHT_ATTENUATION 1UNITY_LIGHT_ATTENUATION(atten, i, i.pos_world.xyz); 接受三个参数： atten：是计算完结果后的存储参数，i：是v2f结构体，会传递给SHADOW_ATTENUATION，用于计算阴影值。i.pos_world：用于计算光照衰减。 建议用这个宏。 透明度测试物体的阴影需要在LightMode为ShadowCaster的Pass里进行透明度测试的计算，否则会出现错误 解决方法：Fallback 设置为Transparent/Cutout/VertexLit这里的Pass进行了透明度测试。 半透明物体的阴影在Unity中，所有内置的半透明的Shader是不会产生阴影效果的，但是我们可以使用一些trick强制为半透明物体生成阴影。 立方体纹理（P210）反射折射菲涅尔反射 渲染纹理在Unity我们可以使用一种特许的Pass来完成屏幕图像的获取。 注意：GrabPass通常用于渲染透明物体，所以要将渲染队列设置为透明队列（“Queue”=“Transparent”） 使用GrabPass抓取图像，并且存储在_RefractionTex里面 主要思路：使用GrabPass抓取图像，用切线空间下的法线对屏幕纹理坐标进行偏移，然后对屏幕图像进行采样达到折射效果 RenderTexture VS GrabPass抓取屏幕图像的方法： 1.利用渲染纹理 + 额外摄像机的方式 2.利用GrabPass{“_GrabTex”} GrabPass好处在于实现简单，但是从效率上说，渲染纹理的效率要好于GrabPass。RenderTexture可以控制分辨率，GrabPass的分辨率和显示屏幕是一直的，而且会破坏CPU和Gpu的并行性。 程序纹理（P226）纹理动画（230）顶点动画（234）注意：模型空间的顶点动画Shader需要取消Unity的批处理，因为批处理会合并相关模型，那么各自的模型空间就会丢失 河流的顶点动画思路： （1）_Frequency控制正选函数频率， _InvWaveKength控制波长， _Magnitude控制波动幅度，得到最终的位移。 广告牌技术思路：构造3个相互正交的基向量。模拟粒子效果：法线方向时固定的，总是指向视角方向，而指向上的方向可以发生变化。模拟草丛效果：指向上的方向永远不变，法线随视角变化 注意：要对视角方向的法线进行判断，避免法线方向和向上方向平行。 注意事项由于使用了 1Tags{&quot;DisableBatching&quot;=&quot;True&quot;} 取消了批处理，会增加DrawCall，带来性能的影响，所以一般来说我们要避免显式使用模型空间的中心作为描点。一般都是利用顶点颜色存储每个顶点到锚点的距离 注意在投射阴影的时候也要修改”ShadowCaster“的Pass的顶点动画，因为这个Pass会以正常的片元进行渲染。 屏幕后处理1.抓取渲染后的屏幕图像 Unity提供了一个方便的接口——OnRenderImage函数 1OnRenderImage(RenderTexture src,RenderTexture dest) Unity会把渲染得到的图像存储在src，dest对应渲染纹理显示到屏幕上。 2.对渲染纹理的处理 我们通常利用Graphics.Blit函数完成对渲染纹理的处理。 默认情况下，OnRenderImage会在所有的不透明和透明的Pass执行完毕后被调用，以便对场景所有游戏对象产生影响。如果想后处理**不对透明物体产生任何影响，可以在OnRenderImage前添加ImageEffectOpaque达到目的。 3.后处理的通常过程 首先在摄像机添加屏幕后处理脚本，利用OnRenderImage获取当前屏幕的渲染纹理，然后嗲用Graphics.Blit使用特定Shader进行处理，然后把渲染纹理显示到屏幕上。 调整屏幕的亮度，饱和度和对比度1.把脚本的亮度，饱和度，对比度参数传递给Shader 2.设置好渲染状态 关闭深度写入，避免挡住后面渲染的物体，深度测试总是通过，关闭剔除，后处理标配。 3.亮度调整：把原颜色乘以亮度系数_Brightness即可 饱和度调整：对每个颜色分量乘以一个特定的系数再相加，就可以得到一个饱和度为0的颜色值，然后_Saturation进行插值 对比度调整：我们首先创建一个对比度为0的颜色，再使用_Contrast进行插值了 边缘检测原理：利用边缘检测算子对图像进行卷积操作。 卷积操作：使用一个卷积核对图像中每个像素进行一系列操作。 如果相邻像素之间的差值过大，我们就可以得知这个是边缘处 实现： 在顶点函数中准备好使用Sobel算子采样时需要的8个领域纹理坐标 然后在片元函数中，定义水平方向和竖直方向的卷积核Gx，Gy。依次进行采样，并计算亮度值，然后和Gx，Gy的权重相乘，叠加到梯度值上。 高斯模糊同样使用了卷积计算，卷积核为高斯核。高斯核的维数越高，模糊程度越大。高斯方程很好模拟了每个像素对当前像素的影响程度——距离越近，影响越大 注意：注意使用一个NxN的高斯核对图像进行卷积滤波，就需要NxNxWxH次纹理采样，这样采样的次数就很巨大。 一般操作：把二维高斯函数拆分为两个一维函数。采样次数就变成了2xNxWxH采样次数。所以我们先后调用两个Pass，分别进行竖直水平方向的滤波结果，我们还将图像进行缩放提高性能，通过调整高斯滤波的次数来控制模糊程度 实现C#脚本准备好高斯模糊的迭代次数，模糊范围，降采样系数 1.首先降采样，并且把FilterMode改为Bilinera为了有压缩效果。 2.通过For循环，进行高斯滤波的次数。 Bloom步骤：先提取图像中较亮的区域，然后进行高斯模糊迭代处理，最后进行颜色的混合。 运动模糊1.累积缓存：来混合多张连续的图像，快速移动产生多张图像后，取平均值最后的运动模糊图像，但是对性能消耗很大。 2.创建和使用速度缓存：在缓存中存储了各个像素当前的运动速度，然后利用该值决定模糊的方向和大小。 实现1.定义运动模糊的模糊参数，值越大，运动拖尾效果越明显。 2.新建一个Rendertexture的变量，用于保存之前叠加的结果 3.判断这个RenderTexture变量是否和屏幕分辨率一样，不一样就重新创建 4.利用CGINCLUDE 和 ENDCG来定义一系列代码 5.分两个Pass，一个输出RGB，一个P输出A值。 深度纹理存储的是高精度值，范围是【0，1】，通常是非线性分布的 深度值来自于顶点变换后得到的归一化设备坐标NDC，原本范围是【-1，1】的，但是为了存储在纹理里进行了映射 深度纹理由Unity单独的Pass渲染而得，只会渲染渲染队列小于等于2500得物体，使用RenderType寻找到LightMode为ShadowCaster得Pass并进行切换，从而渲染深度纹理。 获取深度纹理（未解决）深度图里存放了[0,1]范围的非线性分布的深度值，这些深度值来自NDC坐标。 第一步：在C#中设置Camera.main.depthTextureMode = DepthTextureMode.Depth; 第二步：在Shader中声明_CameraDepthTexture 1sampler2D _CameraDepthTexture; 第三步：访问深度图 123456789101112131415161718//1.如果是后处理，可以直接用uv访问//vertex//当有多个RenderTarget时，需要自己处理UV翻转问题#if UNITY_UV_STARTS_AT_TOP //DirectX之类的 if(_MainTex_TexelSize.y &lt; 0) //开启了抗锯齿 o.uv.y = 1 - o.uv.y; //满足上面两个条件时uv会翻转，因此需要转回来#endif//fragmentfloat depth = UNITY_SAMPLE_DEPTH(tex2D(_CameraDepthTexture, i.uv)); //2.其他：利用投影纹理采样//vertexo.screenPos = ComputeScreenPos(o.vertex);//fragmentfloat depth = SAMPLE_DEPTH_TEXTURE_PROJ(_CameraDepthTexture, UNITY_PROJ_COORD(i.screenPos));float linear01Depth = Linear01Depth(depth); //转换成[0,1]内的线性变化深度值float linearEyeDepth = LinearEyeDepth(depth); //转换到摄像机空间 Unity的渲染优化技术移动平台的特点overdraw（一个像素被渲染多次），在移动平台容易造成性能的瓶颈。 影响性能的因数 优化 动态批处理如果场景有一些模型共享了同一个材质并且满足一些条件，Unity会自动把他们进行批处理，从而花费一个DrawCall就渲染所有的模型。原理：每一帧把可以批处理的模型网格进行合并（每一帧都会重新合并），合并后模型数据传递个GPU，然后同一材质渲染 限制：能够动态批处理的顶点属性规模要小于900. 可以接受多光源的Pass会中断批处理 代码动态改变材质变量后不算同一个材质，会不参与合批。 静态批处理在运行开始阶段，把需要进行静态批处理的模型合并到一个新网格。 限制：模型就不能移动，需要勾上Static。 需要占用更多的内存辣存储合并后的几何结构 处理其他逐像素光的Pass不会被静态批处理 共享材质如果两个材质只有使用的纹理不同，就把纹理合并到一张更大的纹理中，这就是图集(atlas)。 不同物体上材质上参数微小的变化，就用顶点颜色来存储这些参数。同一个材质，而不是使用了同一种Shader的材质。 优化几何体有时候Unity中显示的数目要多于建模软件中的顶点数，是因为GPU要把一个顶点拆分成两个或更多的顶点。 主要原因： 分离纹理坐标 产生平滑的边界 模型的LOD技术遮挡剔除技术遮挡剔除和摄像机的视锥体剔除不一样，视锥体剔除指挥剔除不在摄像机范围内的对象，但不会判断视野中是否有物体被其他物体挡住。 控制绘制顺序在Unity中渲染队列小于2500的物体总是从前往后绘制。而其他的队列（”Transparent“）是从后往前绘制的。 时刻警惕透明物体因为透明物体是从后往前渲染的，所以肯定会overdraw。 减少实时光照和阴影","link":"/2020/08/23/%E4%BB%80%E4%B9%88%E6%98%AF%E6%B8%B2%E6%9F%93%E6%B5%81%E6%B0%B4%E7%BA%BF/"},{"title":"未命名","text":"C++的内存格局1.全局数据区(data area)静态数据和常量 2.代码区(code area)所有类成员函数和非成员函数代码 3.栈区(stack area) 4.堆区(heap area)自由存储区，我们的类实例化在存储在这里 成员函数的调用由于成员函数是不存在类实例的内存中的，是最终被编译成与对象无关的全局函数。如果成员函数需要调用成员变量，C++会把当前对象的指针传递进去。 123456789101112//编译前void Demo::display(){cout&lt;&lt;a&lt;&lt;endl;cout&lt;&lt;b&lt;&lt;endl;}//编译后void new_function_name(Demo * const p){//通过指针p来访问a、bcout&lt;&lt;p-&gt;a&lt;&lt;endl;cout&lt;&lt;p-&gt;b&lt;&lt;endl;} 函数的重载在实际开发当中，我们需要实现几个功能类似的函数，但是有些细节不同，比如是传递的参数不同，这时候就能用到函数重载。 规则 函数名称必须相同。 参数列表必须不同（个数不同、类型不同、参数排列顺序不同等）。 函数的返回类型可以相同也可以不相同。 仅仅返回类型不同不足以成为函数的重载。 构造函数 一个类必须有构造函数，要么用户定义，要么编译器自动生成。一旦用于自定了构造函数，那么编译器便不会自动生成默认构造函数。 构造函数初始化列表主要目的是为了代码的简洁。 1234//采用初始化列表Student::Student(char *name, int age, float score): m_name(name), m_age(age), m_score(score){ //TODO:} 初始化const成员变量构造函数初始化列表还有一个很重要的作用，就是初始化Const变量。初始化 const 成员变量的唯一方法就是使用初始化列表。 内联函数内联函数适用于函数体较少的函数，可以增加效率，并且完全可以代替#define 宏。 析构函数在销毁对象时使用 执行时机对象销毁时机与所在内存区域有关 在所有函数之外创建的对象是全局对象，它和全局变量类似，位于内存分区中的全局数据区，程序在结束执行时会调用这些对象的析构函数。 在函数内部创建的对象是局部对象，它和局部变量类似，位于栈区，函数执行结束时会调用这些对象的析构函数。 new 创建的对象位于堆区，通过 delete 删除时才会调用析构函数；如果没有 delete，析构函数就不会被执行。 对象数组所谓对象数组，指每一个数组元素都是对象的数组，即若一个类有若干个对象，我们把这一系列的对象用一个数组来存放。对象数组的元素是对象，不仅具有数据成员，而且还有函数成员。 构造函数有0个或1个参数如果构造函数只有1个参数，在定义对象数组时可以直接在等号后面的花括号内提供实参来实现初始化。 构造函数有多个参数如果构造函数有多个参数，在定义对象数组时只需在花括号中分别写出构造函数并指定实参即可实现初始化。 成员对象和封闭类一个类的成员变量如果是另一个类的对象，就称之为“成员对象”。包含成员对象的类叫封闭类（enclosed class）。 初始化列表中的成员变量既可以是成员对象，也可以是基本类型的成员变量。 总之，生成封闭类对象的语句一定要让编译器能够弄明白其成员对象是如何初始化的，否则就会编译错误。 执行顺序封闭类对象生成时，先执行所有成员对象的构造函数，然后才执行封闭类自己的构造函数。 当封闭类对象消亡时，先执行封闭类的析构函数，然后再执行成员对象的析构函数 this指针 this 是 const 指针，它的值是不能被修改的，一切企图修改该指针的操作，如赋值、递增、递减等都是不允许的。 this 只能在成员函数内部使用，用在其他地方没有意义，也是非法的。 只有当对象被创建后 this 才有意义，因此不能在 static 成员函数中使用（后续会讲到 static 成员）。 静态成员变量在多个对象之间共享数据，static 成员变量属于类，不属于某个具体的对象，即使创建多个对象，也只为 m_total 分配一份内存，所有对象使用的都是这份内存中的数据。 初始化时可以赋初值，也可以不赋值。如果不赋值，那么会被默认初始化为 0。全局数据区的变量都有默认的初始值 0，而动态数据区（堆区、栈区）变量的默认值是不确定的，一般认为是垃圾值。 静态成员函数静态成员函数与普通成员函数的根本区别在于：普通成员函数有 this 指针，可以访问类中的任意成员；而静态成员函数没有 this 指针，只能访问静态成员（包括静态成员变量和静态成员函数）。 const成员函数const 成员函数可以使用类中的所有成员变量，但是不能修改它们的值，这种措施主要还是为了保护数据而设置的。const 成员函数也称为常成员函数。 需要强调的是，必须在成员函数的声明和定义处同时加上 const 关键字。 const的位置 函数开头的 const 用来修饰函数的返回值，表示返回值是 const 类型，也就是不能被修改，例如const char * getname()。 函数头部的结尾加上 const 表示常成员函数，这种函数只能读取成员变量的值，而不能修改成员变量的值，例如char * getname() const。 const对象在 C++ 中，const 也可以用来修饰对象，称为常对象。一旦将对象定义为常对象之后，就只能调用类的 const 成员（包括 const 成员变量和 const 成员函数）了 友元函数借助友元（friend），可以使得其他类中的成员函数以及全局范围内的函数访问当前类的 private 成员。 友元函数可以是不属于任何类的非成员函数，也可以是其他类的成员函数。 注意，友元函数不同于类的成员函数，在友元函数中不能直接访问类的成员，必须要借助对象。 将其他类的成员函数声明为友元函数12//将Student类中的成员函数show()声明为友元函数 friend void Student::show(Address *addr); 一个函数可以被多个类声明为友元函数，这样就可以访问多个类中的 private 成员。 友元类类 B 声明为类 A 的友元类，那么类 B 中的所有成员函数都是类 A 的友元函数 友元的关系是单向的而不是双向的。友元的关系不能传递。 C++类的作用域class和struct到底有什么区别C++中的 struct 和 class 基本是通用的，唯有几个细节不同： 使用 class 时，类中的成员默认都是 private 属性的；而使用 struct 时，结构体中的成员默认都是 public 属性的。 class 继承默认是 private 继承，而 struct 继承默认是 public 继承（《C++继承与派生》一章会讲解继承）。 class 可以使用模板，而 struct 不能（《模板、字符串和异常》一章会讲解模板）。 String变量 s2 在定义的同时被初始化为&quot;c plus plus&quot;。与C风格的字符串不同，string 的结尾没有结束标志'\\0'。由于 string 的末尾没有'\\0'字符，所以 length() 返回的是字符串的真实长度，而不是长度 +1。 C++的string内部原理C++引用引用可以看做是数据的一个别名，通过这个别名和原来的名字都能够找到这份数据。 1type &amp;name = data; type 是被引用的数据的类型，name 是引用的名称，data 是被引用的数据。引用必须在定义的同时初始化，并且以后也要从一而终，不能再引用其它数据，这有点类似于常量（const 变量）。 注意，引用在定义时需要添加&amp;，在使用时不能添加&amp;，使用时添加&amp;表示取地址。 引用传参从以上代码的编写中可以发现，按引用传参在使用形式上比指针更加直观。在以后的 C++ 编程中，我鼓励读者大量使用引用，它一般可以代替指针（当然指针在C++中也不可或缺），C++ 标准库也是这样做的。 引用作为函数返回值在将引用作为函数返回值时应该注意一个小问题，就是不能返回局部数据（例如局部变量、局部对象、局部数组等）的引用，因为当函数调用完成后局部数据就会被销毁，有可能在下次使用时数据就不存在了，C++ 编译器检测到该行为时也会给出警告。","link":"/2020/08/23/%E6%9C%AA%E5%91%BD%E5%90%8D/"}],"tags":[{"name":"杂记","slug":"杂记","link":"/tags/%E6%9D%82%E8%AE%B0/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"UE4","slug":"UE4","link":"/tags/UE4/"},{"name":"Unity","slug":"Unity","link":"/tags/Unity/"}],"categories":[{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"UE4","slug":"UE4","link":"/categories/UE4/"},{"name":"Unity","slug":"Unity","link":"/categories/Unity/"}]}